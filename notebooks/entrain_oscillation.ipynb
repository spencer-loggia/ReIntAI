{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Notebook to Demonstrate Gradient Decent Over Intrinsic ###"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Basic Imports\n",
    "from intrinsic.module import PlasticEdges\n",
    "from intrinsic.model import Intrinsic\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T22:09:15.343248Z",
     "start_time": "2024-03-06T22:09:14.215018Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll initialize a fully connected Intrinsic network with 3 state nodes, each with 3 channels and spatial dimmesnions with size 5x5. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "rnet = Intrinsic(num_nodes=3, node_shape=(1, 3, 5, 5), kernel_size=3, edge_module=PlasticEdges, track_activation_history=True, mask=None, inject_noise=True, optimize_weights=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T22:09:16.461254Z",
     "start_time": "2024-03-06T22:09:16.454854Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "First run 1000 iterations of the randomly initialized network with no input to get a sense of what it's internal dynamics are like. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "for i in range(1000):\n",
    "    rnet()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T22:09:18.705306Z",
     "start_time": "2024-03-06T22:09:17.772846Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot the series of states for some unit somewhere in the middle of the run (ideally after the dynamics have largely converged). Here we look at time step 200 - 600 of a unit at spatial location (1, 1) in channel 1 of node 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "history = rnet.past_states\n",
    "history = np.array([s.detach().squeeze().numpy() for s in history])\n",
    "plt.plot(history[200:600, 2, 1, 1, 1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T22:09:20.576157Z",
     "start_time": "2024-03-06T22:09:20.457715Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that there are some semi-repetitive oscillatory dynamics that arise from the structure and local update functions on the random graph. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Now attempt to use gradient decent to alter the dynamics at this unit to match a given temporal pattern (a cosine function, below)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "x = torch.arange(0, 200)\n",
    "target_pattern = 2 * torch.sin((x * 4 * torch.pi) / 60)\n",
    "plt.plot(target_pattern)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-06T22:09:34.493806Z",
     "start_time": "2024-03-06T22:09:34.420271Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "loss_history = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-06T22:09:35.582701Z",
     "start_time": "2024-03-06T22:09:35.574289Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the below training loop, take the time course of unit of interest (2, 1, 1, 1) at each generation and compute the mean square error (mse) relative to the target cosine time series above. This mse is minimized via gradient decent over the initial weight, channel map, and plasticity parameters of the model ~200 parameters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# initialize a sgd optimizer over global parameters\n",
    "optim = torch.optim.Adam(params=rnet.parameters(), eps=1e-6, lr=.001)\n",
    "# we will run 1250 generations with gradient update after each gen\n",
    "for gen in range(2000):\n",
    "    rnet.past_states = []\n",
    "    rnet = rnet.detach(reset_intrinsic=True)\n",
    "    optim.zero_grad()\n",
    "    # will model 200 time steps per generation\n",
    "    for i in range(200):\n",
    "        rnet()\n",
    "    history = torch.stack(rnet.past_states)\n",
    "    node_history = history[:, 2, 1, 1, 1].squeeze()\n",
    "    # compute the mean square error between target time series and observed time series at unit of interest\n",
    "    loss = torch.sqrt(torch.sum((target_pattern - node_history) ** 2))\n",
    "    loss_history.append(loss.detach().cpu().item())\n",
    "    print(\"gen\", gen, \"loss\", loss)\n",
    "    # preform gradient update.\n",
    "    loss.backward()\n",
    "    optim.step()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-07T00:17:00.207823Z",
     "start_time": "2024-03-07T00:03:08.564061Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The loss generally decreases, but is clearly a very complex landscape. Adam optimization (or perhaps gradient decent in general) is not very well suited."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    " from scipy.ndimage import gaussian_filter\n",
    " plt.plot(gaussian_filter(np.array(loss_history), 1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T03:59:42.703925Z",
     "start_time": "2024-03-07T03:59:42.645913Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The time course of the unit of interest now looks like our target cosine time course."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "plt.plot(history[0:, 2, 1, 1, 1].detach().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2024-03-07T04:00:01.535756Z",
     "start_time": "2024-03-07T04:00:01.459268Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we look at units in other nodes / channels they have various oscillatory patterns with similar frequency. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "plt.plot(history[0:, 0, 2, 3, 2].detach().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T04:00:06.894038Z",
     "start_time": "2024-03-07T04:00:06.832777Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now show the plasticity values for each node to node edge. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "plast = rnet.edge.plasticity.detach().numpy()\n",
    "print(plast)\n",
    "# plt.imshow(plast, cmap=\"hot\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T04:00:25.183443Z",
     "start_time": "2024-03-07T04:00:25.159339Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import pickle\n",
    "with open(\"../models/cos_entrained.pkl\", \"wb\") as f:\n",
    "    pickle.dump(rnet, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-05T02:32:55.911264Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(rnet.edge.chan_map.detach().numpy())"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(torch.linalg.inv(rnet.edge.chan_map.detach()).numpy())"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
