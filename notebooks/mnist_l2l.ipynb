{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T13:20:17.686392Z",
     "start_time": "2024-05-02T13:20:16.417124Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torchvision.transforms import PILToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "try:\n",
    "    dataset = MNIST(root=\"/Users/loggiasr/Projects/ReIntAI/tmp\", transform=PILToTensor())\n",
    "except RuntimeError:\n",
    "    dataset = MNIST(root=\"/Users/loggiasr/Projects/ReIntAI/tmp\", download=True, transform=PILToTensor())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T13:20:17.704376Z",
     "start_time": "2024-05-02T13:20:17.687247Z"
    }
   },
   "id": "5c4a280b5a2a55ba"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 9])\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 9])\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 9])\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 9])\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGdCAYAAAAv9mXmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAX/klEQVR4nO3dfXBU9b3H8U8IcnhoWAsaSoYFgq0FEiiQMMqTYsXMjcDIHUoLg5iKnSk2IJjRCxH7ABVWtGXoSIkNwyCWy8P0VpReBRvsBaQ2NQSiiF7Q4pAVRErH7gLOLCY59497u7cRQ3KS/eZw4vs1c/7YM+d4vrPj8J7fns2eNNd1XQEAkGKd/B4AANAxERgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCic3tfsKGhQadPn1ZGRobS0tLa+/IAgDZwXVfnz59XVlaWOnW68hql3QNz+vRphcPh9r4sACCFotGo+vXrd8Vj2j0wGRkZkqTxulOddU17Xx4A0AZ1+lQH9FLy3/IraffA/ONjsc66Rp3TCAwABMr//XplS25xcJMfAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJloVmHXr1ik7O1tdu3ZVXl6eXn311VTPBQAIOM+B2b59uxYtWqSlS5fq8OHDmjBhggoLC1VbW2sxHwAgoDwHZvXq1brvvvv0ve99T0OGDNGaNWsUDodVVlZmMR8AIKA8BebSpUuqrq5WQUFBo/0FBQV67bXXPvecRCKheDzeaAMAdHyeAnPu3DnV19erT58+jfb36dNHZ86c+dxzIpGIQqFQcguHw62fFgAQGK26yf/ZR2W6rtvk4zNLS0sVi8WSWzQabc0lAQAB09nLwdddd53S09MvW62cPXv2slXNPziOI8dxWj8hACCQPK1gunTpory8PFVUVDTaX1FRobFjx6Z0MABAsHlawUhSSUmJ5syZo/z8fI0ZM0bl5eWqra3VvHnzLOYDAASU58B85zvf0d/+9jctX75cH374oXJzc/XSSy9pwIABFvMBAAIqzXVdtz0vGI/HFQqFNFF3qXPaNe15aQBAG9W5n2qvXlAsFlPPnj2veCy/RQYAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBgwnNg9u/fr6lTpyorK0tpaWl6/vnnDcYCAASd58BcvHhR3/jGN7R27VqLeQAAHURnrycUFhaqsLDQYhYAQAfiOTBeJRIJJRKJ5Ot4PG59SQDAVcD8Jn8kElEoFEpu4XDY+pIAgKuAeWBKS0sVi8WSWzQatb4kAOAqYP4RmeM4chzH+jIAgKsMfwcDADDheQVz4cIFvffee8nX77//vmpqatSrVy/1798/pcMBAILLc2AOHjyo2267Lfm6pKREklRUVKRnnnkmZYMBAILNc2AmTpwo13UtZgEAdCDcgwEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJ8ydaws5/nqr2e4RmTTwyw+8RmvXEjf/h9wgtsuCtWX6P0KwXR2zwe4Rm3Tv9fr9HaJZbdcTvEVKCFQwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACY8BSYSiWj06NHKyMhQZmampk2bpmPHjlnNBgAIME+B2bdvn4qLi1VZWamKigrV1dWpoKBAFy9etJoPABBQnh6ZvHv37kavN27cqMzMTFVXV+uWW25J6WAAgGDzFJjPisVikqRevXo1eUwikVAikUi+jsfjbbkkACAgWn2T33VdlZSUaPz48crNzW3yuEgkolAolNzC4XBrLwkACJBWB2b+/Pl68803tXXr1iseV1paqlgsltyi0WhrLwkACJBWfUS2YMEC7dy5U/v371e/fv2ueKzjOHIcp1XDAQCCy1NgXNfVggULtGPHDu3du1fZ2dlWcwEAAs5TYIqLi7Vlyxa98MILysjI0JkzZyRJoVBI3bp1MxkQABBMnu7BlJWVKRaLaeLEierbt29y2759u9V8AICA8vwRGQAALcFvkQEATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMBEq55oiavDiMp7/B6hWTU3P+v3CM26r/Y2v0dokf8a9YzfIzSre9rV/1wot+qI3yN8YbCCAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADAhKfAlJWVafjw4erZs6d69uypMWPGaNeuXVazAQACzFNg+vXrp8cff1wHDx7UwYMH9c1vflN33XWXjh49ajUfACCgPD0yeerUqY1er1ixQmVlZaqsrFROTk5KBwMABJunwPyz+vp6/eY3v9HFixc1ZsyYJo9LJBJKJBLJ1/F4vLWXBAAEiOeb/EeOHNGXvvQlOY6jefPmaceOHRo6dGiTx0ciEYVCoeQWDofbNDAAIBg8B+brX/+6ampqVFlZqfvvv19FRUV6++23mzy+tLRUsVgsuUWj0TYNDAAIBs8fkXXp0kVf/epXJUn5+fmqqqrSL37xC/3qV7/63OMdx5HjOG2bEgAQOG3+OxjXdRvdYwEAQPK4gnnkkUdUWFiocDis8+fPa9u2bdq7d692795tNR8AIKA8Beajjz7SnDlz9OGHHyoUCmn48OHavXu37rjjDqv5AAAB5SkwGzZssJoDANDB8FtkAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMOH5iZa4evSbftTvEZo1RXl+j9ACcb8HaJHup7r4PUKzhmwt9nuEZt2gSr9H+MJgBQMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgIk2BSYSiSgtLU2LFi1K0TgAgI6i1YGpqqpSeXm5hg8fnsp5AAAdRKsCc+HCBc2ePVvr16/Xl7/85VTPBADoAFoVmOLiYk2ePFmTJk1q9thEIqF4PN5oAwB0fJ29nrBt2zYdOnRIVVVVLTo+Eolo2bJlngcDAASbpxVMNBrVwoULtXnzZnXt2rVF55SWlioWiyW3aDTaqkEBAMHiaQVTXV2ts2fPKi8vL7mvvr5e+/fv19q1a5VIJJSent7oHMdx5DhOaqYFAASGp8DcfvvtOnLkSKN99957rwYPHqzFixdfFhcAwBeXp8BkZGQoNze30b4ePXqod+/el+0HAHyx8Zf8AAATnr9F9ll79+5NwRgAgI6GFQwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMtPnXlIGge/l0jd8jtMinrt8TNO+Ghyr9HgFXEVYwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCY8BSYn/zkJ0pLS2u0feUrX7GaDQAQYJ6faJmTk6M9e/YkX6enp6d0IABAx+A5MJ07d2bVAgBolud7MO+++66ysrKUnZ2tmTNn6sSJExZzAQACztMK5qabbtKzzz6rG2+8UR999JEee+wxjR07VkePHlXv3r0/95xEIqFEIpF8HY/H2zYxACAQPK1gCgsLNX36dA0bNkyTJk3Siy++KEnatGlTk+dEIhGFQqHkFg6H2zYxACAQ2vQ15R49emjYsGF69913mzymtLRUsVgsuUWj0bZcEgAQEJ5v8v+zRCKhd955RxMmTGjyGMdx5DhOWy4DAAggTyuYhx56SPv27dP777+vP//5z/rWt76leDyuoqIiq/kAAAHlaQXzwQcfaNasWTp37pyuv/563XzzzaqsrNSAAQOs5gMABJSnwGzbts1qDgBAB8NvkQEATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmGjTEy2BjqDebfB7hBaZ8G/Ffo/QrJAq/R4BVxFWMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMCE58CcOnVKd999t3r37q3u3btrxIgRqq6utpgNABBgnh449vHHH2vcuHG67bbbtGvXLmVmZuovf/mLrr32WqPxAABB5Skwq1atUjgc1saNG5P7Bg4cmOqZAAAdgKePyHbu3Kn8/HzNmDFDmZmZGjlypNavX281GwAgwDwF5sSJEyorK9PXvvY1vfzyy5o3b54eeOABPfvss02ek0gkFI/HG20AgI7P00dkDQ0Nys/P18qVKyVJI0eO1NGjR1VWVqZ77rnnc8+JRCJatmxZ2ycFAASKpxVM3759NXTo0Eb7hgwZotra2ibPKS0tVSwWS27RaLR1kwIAAsXTCmbcuHE6duxYo33Hjx/XgAEDmjzHcRw5jtO66QAAgeVpBfPggw+qsrJSK1eu1HvvvactW7aovLxcxcXFVvMBAALKU2BGjx6tHTt2aOvWrcrNzdVPf/pTrVmzRrNnz7aaDwAQUJ4+IpOkKVOmaMqUKRazAAA6EH6LDABggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADAhOef6we8mP3fH/g9QrMa5Po9QouE/r3S7xEAT1jBAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBgwlNgBg4cqLS0tMu24uJiq/kAAAHl6YmWVVVVqq+vT75+6623dMcdd2jGjBkpHwwAEGyeAnP99dc3ev3444/rhhtu0K233prSoQAAwecpMP/s0qVL2rx5s0pKSpSWltbkcYlEQolEIvk6Ho+39pIAgABp9U3+559/Xn//+9/13e9+94rHRSIRhUKh5BYOh1t7SQBAgLQ6MBs2bFBhYaGysrKueFxpaalisVhyi0ajrb0kACBAWvUR2cmTJ7Vnzx4999xzzR7rOI4cx2nNZQAAAdaqFczGjRuVmZmpyZMnp3oeAEAH4TkwDQ0N2rhxo4qKitS5c6u/IwAA6OA8B2bPnj2qra3V3LlzLeYBAHQQnpcgBQUFcl3XYhYAQAfCb5EBAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABA90galZGR/5PUKz/uWdf/V7hBbprFq/RwA8YQUDADBBYAAAJggMAMAEgQEAmCAwAAATBAYAYILAAABMEBgAgAkCAwAwQWAAACYIDADABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJT4Gpq6vTo48+quzsbHXr1k2DBg3S8uXL1dDQYDUfACCgPD3RctWqVXr66ae1adMm5eTk6ODBg7r33nsVCoW0cOFCqxkBAAHkKTB/+tOfdNddd2ny5MmSpIEDB2rr1q06ePCgyXAAgODy9BHZ+PHj9corr+j48eOSpDfeeEMHDhzQnXfe2eQ5iURC8Xi80QYA6Pg8rWAWL16sWCymwYMHKz09XfX19VqxYoVmzZrV5DmRSETLli1r86AAgGDxtILZvn27Nm/erC1btujQoUPatGmTfvazn2nTpk1NnlNaWqpYLJbcotFom4cGAFz9PK1gHn74YS1ZskQzZ86UJA0bNkwnT55UJBJRUVHR557jOI4cx2n7pACAQPG0gvnkk0/UqVPjU9LT0/maMgDgMp5WMFOnTtWKFSvUv39/5eTk6PDhw1q9erXmzp1rNR8AIKA8Beapp57SD3/4Q/3gBz/Q2bNnlZWVpe9///v60Y9+ZDUfACCgPAUmIyNDa9as0Zo1a4zGAQB0FPwWGQDABIEBAJggMAAAEwQGAGCCwAAATBAYAIAJAgMAMEFgAAAmCAwAwASBAQCYIDAAABMEBgBgwtOPXaaC67qSpDp9KrntfXW0t/j5q/9ZQXUXE36P0DLup35PAPzvv936/3/LryTNbclRKfTBBx8oHA635yUBACkWjUbVr1+/Kx7T7oFpaGjQ6dOnlZGRobS0tDb/9+LxuMLhsKLRqHr27JmCCb+YeB9Tg/cxdXgvUyPV76Prujp//ryysrIue8LxZ7X7R2SdOnVqtnqt0bNnT/4nTAHex9TgfUwd3svUSOX7GAqFWnQcN/kBACYIDADAROAD4ziOfvzjH8txHL9HCTTex9TgfUwd3svU8PN9bPeb/ACAL4bAr2AAAFcnAgMAMEFgAAAmCAwAwETgA7Nu3TplZ2era9euysvL06uvvur3SIESiUQ0evRoZWRkKDMzU9OmTdOxY8f8HivwIpGI0tLStGjRIr9HCZxTp07p7rvvVu/evdW9e3eNGDFC1dXVfo8VKHV1dXr00UeVnZ2tbt26adCgQVq+fLkaGtr3twEDHZjt27dr0aJFWrp0qQ4fPqwJEyaosLBQtbW1fo8WGPv27VNxcbEqKytVUVGhuro6FRQU6OLFi36PFlhVVVUqLy/X8OHD/R4lcD7++GONGzdO11xzjXbt2qW3335bP//5z3Xttdf6PVqgrFq1Sk8//bTWrl2rd955R0888YSefPJJPfXUU+06R6C/pnzTTTdp1KhRKisrS+4bMmSIpk2bpkgk4uNkwfXXv/5VmZmZ2rdvn2655Ra/xwmcCxcuaNSoUVq3bp0ee+wxjRgxQmvWrPF7rMBYsmSJ/vjHP/JJRBtNmTJFffr00YYNG5L7pk+fru7du+vXv/51u80R2BXMpUuXVF1drYKCgkb7CwoK9Nprr/k0VfDFYjFJUq9evXyeJJiKi4s1efJkTZo0ye9RAmnnzp3Kz8/XjBkzlJmZqZEjR2r9+vV+jxU448eP1yuvvKLjx49Lkt544w0dOHBAd955Z7vO0e4/dpkq586dU319vfr06dNof58+fXTmzBmfpgo213VVUlKi8ePHKzc31+9xAmfbtm06dOiQqqqq/B4lsE6cOKGysjKVlJTokUce0euvv64HHnhAjuPonnvu8Xu8wFi8eLFisZgGDx6s9PR01dfXa8WKFZo1a1a7zhHYwPzDZ3/y33XdlDwG4Ito/vz5evPNN3XgwAG/RwmcaDSqhQsX6ve//726du3q9ziB1dDQoPz8fK1cuVKSNHLkSB09elRlZWUExoPt27dr8+bN2rJli3JyclRTU6NFixYpKytLRUVF7TZHYANz3XXXKT09/bLVytmzZy9b1aB5CxYs0M6dO7V//36Txyl0dNXV1Tp79qzy8vKS++rr67V//36tXbtWiURC6enpPk4YDH379tXQoUMb7RsyZIh++9vf+jRRMD388MNasmSJZs6cKUkaNmyYTp48qUgk0q6BCew9mC5duigvL08VFRWN9ldUVGjs2LE+TRU8rutq/vz5eu655/SHP/xB2dnZfo8USLfffruOHDmimpqa5Jafn6/Zs2erpqaGuLTQuHHjLvua/PHjxzVgwACfJgqmTz755LKHgaWnp7f715QDu4KRpJKSEs2ZM0f5+fkaM2aMysvLVVtbq3nz5vk9WmAUFxdry5YteuGFF5SRkZFcEYZCIXXr1s3n6YIjIyPjsvtWPXr0UO/evbmf5cGDDz6osWPHauXKlfr2t7+t119/XeXl5SovL/d7tECZOnWqVqxYof79+ysnJ0eHDx/W6tWrNXfu3PYdxA24X/7yl+6AAQPcLl26uKNGjXL37dvn90iBIulzt40bN/o9WuDdeuut7sKFC/0eI3B+97vfubm5ua7jOO7gwYPd8vJyv0cKnHg87i5cuNDt37+/27VrV3fQoEHu0qVL3UQi0a5zBPrvYAAAV6/A3oMBAFzdCAwAwASBAQCYIDAAABMEBgBggsAAAEwQGACACQIDADBBYAAAJggMAMAEgQEAmCAwAAAT/wPl3KwfcredvwAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 9])\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pool = torch.nn.MaxPool2d(3)\n",
    "data_load = DataLoader(dataset, shuffle=True, batch_size=1)\n",
    "for i, (batch, labels) in enumerate(data_load):\n",
    "    if i < 20:\n",
    "        continue\n",
    "    if i > 40:\n",
    "        break\n",
    "    if labels in [3, 7]:\n",
    "        batch = torch.from_numpy(np.array(batch)).float()\n",
    "        batch = pool(batch.reshape((1, 1, batch.shape[-1], -1))).squeeze()\n",
    "        batch = (batch - batch.mean()) / batch.std()\n",
    "        plt.imshow(batch)\n",
    "        print(batch.shape)\n",
    "        plt.pause(.05)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T13:20:18.499926Z",
     "start_time": "2024-05-02T13:20:17.908631Z"
    }
   },
   "id": "f7d7664d2735f93f"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# loss function that just wants each step better than the discounted average of the last few. \n",
    "def l2l_loss(logits, targets, lfxn, classes=3, power=2, window=3):\n",
    "    \"\"\"\n",
    "    :param logits: (examples, classes)\n",
    "    :param targets: (examples)\n",
    "    :param classes: num classes\n",
    "    :param power: higher powers encourage larger step changes\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    targets = torch.Tensor(targets).long()\n",
    "    conv_1d = torch.nn.Conv1d(in_channels=1, out_channels=1, kernel_size=window, padding=1, padding_mode=\"replicate\")\n",
    "    conv_1d.weight = torch.nn.Parameter(torch.ones_like(conv_1d.weight) / window)\n",
    "    conv_1d.bias = torch.nn.Parameter(torch.zeros_like(conv_1d.bias))\n",
    "    ce_loss = lfxn(logits, targets).view((-1,)) #\n",
    "    print(ce_loss)\n",
    "    filt_ce_loss = conv_1d(ce_loss.view((1, 1, -1))).flatten()\n",
    "    ce_loss = filt_ce_loss[1:] - filt_ce_loss[:-1].detach()\n",
    "    ce_loss = ce_loss + torch.relu(ce_loss) * 4\n",
    "    print(ce_loss)\n",
    "    loss = torch.sum(ce_loss) #+ torch.pow(chance_ce - ce_loss[0], 2)\n",
    "    print(loss)\n",
    "    return loss\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T13:20:18.911542Z",
     "start_time": "2024-05-02T13:20:18.892118Z"
    }
   },
   "id": "69f2add186b3ea77"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from intrinsic.model import Intrinsic\n",
    "class Decoder:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = Intrinsic(num_nodes=5, node_shape=(1, 3, 9, 9), kernel_size=6, input_mode=\"overwrite\")\n",
    "        self.train_labels = [3, 7]\n",
    "        self.decoder = torch.nn.Linear(in_features=9**2, out_features=len(self.train_labels))\n",
    "        self.optim = torch.optim.Adam(params=[self.model.resistance,\n",
    "                                              self.model.edge.init_weight,\n",
    "                                              self.model.edge.plasticity,\n",
    "                                              self.model.edge.chan_map] + list(self.decoder.parameters()), lr=1e-5)\n",
    "\n",
    "        self.history = []\n",
    "        \n",
    "    def forward(self, X, y):\n",
    "        pool = torch.nn.MaxPool2d(3)\n",
    "        img = X.float()\n",
    "        img = pool(img.reshape((1, 1, img.shape[-1], -1))).squeeze()\n",
    "        img = (img - img.mean()) / img.std()\n",
    "        in_states = torch.zeros_like(self.model.states)\n",
    "        mask = in_states.bool()\n",
    "        for i in range(4):\n",
    "            with torch.no_grad():\n",
    "                in_states[0, 0, :, :] = img.detach()\n",
    "                mask[0, 0, :, :] = True\n",
    "            self.model(in_states.detach(), mask.detach())\n",
    "        in_features = self.model.states[2, 0, :, :]\n",
    "        logits = self.decoder(in_features.view(1, 1, -1)).flatten()\n",
    "        correct = (torch.argmax(logits) == y).float() * .2 - .1\n",
    "        for i in range(2):\n",
    "            # in_states = torch.zeros_like(self.model.states)\n",
    "            # mask = in_states.bool()\n",
    "            in_states[1, 0, :, :] = correct\n",
    "            mask[1, 0, :, :] = True\n",
    "            self.model(in_states, mask.detach())\n",
    "        for i in range(1):\n",
    "            self.model()\n",
    "        return logits\n",
    "    \n",
    "    def _fit(self, data, label_map, iter=100):\n",
    "        all_logits = []\n",
    "        all_labels = []\n",
    "        count = 0\n",
    "        for img, label in data:\n",
    "            if label not in label_map:\n",
    "                continue\n",
    "            if count > iter:\n",
    "                break\n",
    "            label = label_map.index(label)\n",
    "            logits = self.forward(img, label)\n",
    "            all_logits.append(logits.clone())\n",
    "            all_labels.append(label)\n",
    "            count += 1\n",
    "        return torch.stack(all_logits, dim=0), torch.Tensor(all_labels).long()\n",
    "        \n",
    "            \n",
    "    def l2l_fit(self, data, epochs=1000, batch_size=100):\n",
    "        l_fxn = torch.nn.CrossEntropyLoss(reduce=False)\n",
    "        data = DataLoader(data, shuffle=True, batch_size=1)\n",
    "        for epoch in range(epochs):\n",
    "            self.optim.zero_grad()\n",
    "            if (epoch % 10) == 0:\n",
    "                self.model.detach(reset_intrinsic=True)\n",
    "            else:\n",
    "                self.model.detach(reset_intrinsic=False)\n",
    "            logits, labels = self._fit(data, self.train_labels, batch_size)\n",
    "            # loss = torch.sum(logits)\n",
    "            loss = l2l_loss(logits, labels, l_fxn) # + .33 * torch.mean(l_fxn(logits, labels)) # \n",
    "            reg = torch.sum(torch.abs(self.model.edge.chan_map))\n",
    "            self.history.append(loss.detach().cpu().item())\n",
    "            print(\"Epoch\", epoch, \"loss is\", self.history[-1])\n",
    "            loss = loss + .001 * reg\n",
    "            print('REG', .001 * reg)\n",
    "            #init_plast = self.model.edge.chan_map.clone()\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "            #print(\"change:\", init_plast - self.model.edge.chan_map.clone())\n",
    "\n",
    "            \n",
    "    def forward_fit(self, data, iter, use_labels=None):\n",
    "        self.model.detach(reset_intrinsic=True)\n",
    "        if use_labels is None:\n",
    "            use_labels = self.train_labels\n",
    "        l_fxn = torch.nn.CrossEntropyLoss()\n",
    "        data = DataLoader(data, shuffle=True, batch_size=1)\n",
    "        with torch.no_grad():\n",
    "            logits, labels = self._fit(data, use_labels, iter)\n",
    "            # loss = l2l_loss(logits, labels, l_fxn)\n",
    "        #print(\"Self Learn Loss:\", loss.detach().item())\n",
    "        \n",
    "    def evaluate(self, data, iter, use_labels=None):\n",
    "        if use_labels is None:\n",
    "            use_labels = self.train_labels\n",
    "        l_fxn = torch.nn.CrossEntropyLoss()\n",
    "        data = DataLoader(data, shuffle=True, batch_size=1)\n",
    "        with torch.no_grad():\n",
    "            logits, labels = self._fit(data, use_labels, iter)\n",
    "        labels = torch.Tensor(labels).long()\n",
    "        avg_loss = l_fxn(logits, labels)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = torch.count_nonzero(preds == labels) / len(labels)\n",
    "        print(iter, \"Iterations, avg CE:\", avg_loss.detach().item(), \"acc:\", acc.detach().item())\n",
    "        \n",
    "                "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T14:19:27.997200Z",
     "start_time": "2024-05-02T14:19:27.958132Z"
    }
   },
   "id": "33c39960fbf4a297"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "with open(\"/Users/loggiasr/Projects/ReIntAI/models/mnist_models/new_pool3_l2l.pkl\", \"rb\") as f:\n",
    "    decoder = pickle.load(f)\n",
    "decoder.optim = torch.optim.Adam(params=[decoder.model.resistance,\n",
    "                                              decoder.model.edge.init_weight,\n",
    "                                              decoder.model.edge.plasticity,\n",
    "                                              decoder.model.edge.chan_map] + list(decoder.decoder.parameters()), lr=1e-4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T14:20:46.606852Z",
     "start_time": "2024-05-02T14:20:46.555837Z"
    }
   },
   "id": "87224d55b0bf5f76"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9666, 0.8284, 0.6234, 0.6475, 0.7209, 0.7180, 0.7083, 0.6770, 0.7216,\n",
      "        0.7948, 0.7612], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1144, -0.1064, -0.0358,  0.1578,  0.1013, -0.0147,  0.0060,  0.1442,\n",
      "         0.1404,  0.0660], grad_fn=<AddBackward0>)\n",
      "tensor(0.3444, grad_fn=<SumBackward0>)\n",
      "Epoch 0 loss is 0.3444116711616516\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6178, 0.5579, 0.7987, 0.5422, 0.8371, 0.6420, 0.5706, 0.8672, 0.7835,\n",
      "        0.6091, 0.5731], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.3015, -0.0252,  0.4654, -0.0522,  0.0474,  0.0501,  0.2359,  0.0641,\n",
      "        -0.0980, -0.0701], grad_fn=<AddBackward0>)\n",
      "tensor(0.9188, grad_fn=<SumBackward0>)\n",
      "Epoch 1 loss is 0.9187983870506287\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9004, 0.5136, 0.8548, 0.8666, 0.8440, 0.8497, 0.5567, 0.8397, 0.5245,\n",
      "        0.9025, 0.5330], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0152, -0.0113,  0.5506, -0.0017, -0.1033, -0.0014, -0.1084,  0.5764,\n",
      "        -0.1022,  0.0142], grad_fn=<AddBackward0>)\n",
      "tensor(0.7976, grad_fn=<SumBackward0>)\n",
      "Epoch 2 loss is 0.7975995540618896\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8855, 0.5163, 0.5171, 0.5674, 0.5303, 0.5292, 0.8809, 0.8817, 0.8782,\n",
      "        0.8744, 0.8456], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1228, -0.1060,  0.0233,  0.0202,  0.5226,  0.5856,  0.5816, -0.0022,\n",
      "        -0.0120, -0.0109], grad_fn=<AddBackward0>)\n",
      "tensor(1.4793, grad_fn=<SumBackward0>)\n",
      "Epoch 3 loss is 1.4792736768722534\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9600, 0.9272, 0.5248, 0.4912, 0.5067, 0.5084, 0.5453, 0.4956, 0.5119,\n",
      "        0.8956, 0.5640], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1451, -0.1563, -0.1402, -0.0055,  0.0903, -0.0037,  0.0060,  0.5838,\n",
      "         0.1140,  0.0867], grad_fn=<AddBackward0>)\n",
      "tensor(0.4300, grad_fn=<SumBackward0>)\n",
      "Epoch 4 loss is 0.43004924058914185\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9649, 0.9152, 0.9307, 0.9063, 0.8887, 0.8991, 0.5167, 0.5025, 0.9550,\n",
      "        0.4781, 0.5153], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0114, -0.0195, -0.0088, -0.0105, -0.1299, -0.1287,  0.0932, -0.0129,\n",
      "         0.0214, -0.1466], grad_fn=<AddBackward0>)\n",
      "tensor(-0.3537, grad_fn=<SumBackward0>)\n",
      "Epoch 5 loss is -0.3536747694015503\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9861, 0.4547, 0.4898, 0.4562, 0.4674, 0.9320, 0.4804, 0.4810, 0.9648,\n",
      "        0.4801, 0.9906], grad_fn=<ViewBackward0>)\n",
      "tensor([-1.6543e-01, -1.7663e-01,  2.1244e-02,  7.3696e-01,  4.0319e-02,\n",
      "         2.2593e-02,  5.4763e-02, -9.1910e-05,  8.4940e-01,  4.2967e-02],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(1.4261, grad_fn=<SumBackward0>)\n",
      "Epoch 6 loss is 1.4261001348495483\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4428, 0.4798, 0.4535, 1.0249, 0.9587, 0.4947, 0.9587, 0.4822, 0.9496,\n",
      "        0.4531, 0.4693], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0179,  0.9702,  0.7981,  0.0686, -0.0221, -0.1588,  0.7583, -0.1685,\n",
      "        -0.0043, -0.1601], grad_fn=<AddBackward0>)\n",
      "tensor(2.0992, grad_fn=<SumBackward0>)\n",
      "Epoch 7 loss is 2.0991744995117188\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.0128, 1.0250, 0.4475, 0.4566, 0.5045, 0.4880, 0.9332, 0.9991, 1.0017,\n",
      "        0.9660, 0.9334], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1884, -0.1854, -0.1735,  0.0675,  0.7944,  0.8243,  0.8560,  0.0546,\n",
      "        -0.0219, -0.0227], grad_fn=<AddBackward0>)\n",
      "tensor(2.0050, grad_fn=<SumBackward0>)\n",
      "Epoch 8 loss is 2.004953384399414\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4788, 0.9722, 0.9425, 0.9321, 0.4385, 0.9452, 0.5140, 0.4652, 0.5240,\n",
      "        0.4605, 0.9371], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.7729,  0.7555, -0.1779,  0.0045, -0.1394,  0.0444, -0.1404, -0.0179,\n",
      "         0.7866,  0.6885], grad_fn=<AddBackward0>)\n",
      "tensor(2.5769, grad_fn=<SumBackward0>)\n",
      "Epoch 9 loss is 2.5769355297088623\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.3523, 0.6198, 0.8600, 0.5392, 0.4925, 0.4894, 0.5387, 0.8887, 0.9010,\n",
      "        0.5079, 0.5606], grad_fn=<ViewBackward0>)\n",
      "tensor([ 8.4608e-01,  3.1149e-01, -4.2422e-02, -1.2351e-01, -1.8394e-04,\n",
      "         6.6031e-01,  6.8588e-01, -1.0259e-02, -1.0935e-01, -1.1344e-01],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(2.1046, grad_fn=<SumBackward0>)\n",
      "Epoch 10 loss is 2.1045989990234375\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8444, 0.5123, 0.5324, 0.4987, 0.9308, 0.5432, 0.5258, 0.9157, 0.5388,\n",
      "        0.8913, 0.8656], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1040, -0.1152,  0.6976,  0.0181,  0.0452, -0.0050, -0.0015,  0.6092,\n",
      "        -0.0167,  0.5446], grad_fn=<AddBackward0>)\n",
      "tensor(1.6722, grad_fn=<SumBackward0>)\n",
      "Epoch 11 loss is 1.672170877456665\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8429, 0.5604, 0.5924, 0.8356, 0.5297, 0.9052, 0.8679, 0.5394, 0.8643,\n",
      "        0.5557, 0.5222], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0835, -0.0024, -0.0102,  0.5213,  0.0539,  0.0162, -0.0136, -0.1041,\n",
      "        -0.0057, -0.1140], grad_fn=<AddBackward0>)\n",
      "tensor(0.2578, grad_fn=<SumBackward0>)\n",
      "Epoch 12 loss is 0.2578049302101135\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5617, 0.8012, 0.6042, 0.6171, 0.5816, 0.6100, 0.5838, 0.8002, 0.8053,\n",
      "        0.5831, 0.6293], grad_fn=<ViewBackward0>)\n",
      "tensor([ 7.0827e-02,  9.2335e-02, -7.3194e-02,  9.6250e-03, -1.1122e-02,\n",
      "         3.6430e-01,  3.2560e-01, -2.1207e-04, -5.6957e-02, -5.8689e-02],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.6625, grad_fn=<SumBackward0>)\n",
      "Epoch 13 loss is 0.662521243095398\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5869, 0.7365, 0.6018, 0.6276, 0.7706, 0.7916, 0.7838, 0.6798, 0.7630,\n",
      "        0.7972, 0.8095], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0248,  0.0678,  0.0568,  0.3163,  0.2603, -0.0303, -0.0095,  0.0224,\n",
      "         0.2162,  0.0775], grad_fn=<AddBackward0>)\n",
      "tensor(1.0023, grad_fn=<SumBackward0>)\n",
      "Epoch 14 loss is 1.0023406744003296\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6331, 0.7300, 0.6191, 0.8026, 0.7565, 0.7655, 0.7944, 0.6130, 0.7768,\n",
      "        0.7704, 0.7036], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0046,  0.2826,  0.0442,  0.2440, -0.0028, -0.0478,  0.0188, -0.0080,\n",
      "         0.1510, -0.0244], grad_fn=<AddBackward0>)\n",
      "tensor(0.6530, grad_fn=<SumBackward0>)\n",
      "Epoch 15 loss is 0.6530395746231079\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6537, 0.6732, 0.6863, 0.6972, 0.6533, 0.6587, 0.7089, 0.6898, 0.7154,\n",
      "        0.6807, 0.7069], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0544,  0.0725, -0.0066, -0.0092,  0.0195,  0.0608,  0.0946, -0.0094,\n",
      "         0.0284, -0.0028], grad_fn=<AddBackward0>)\n",
      "tensor(0.3021, grad_fn=<SumBackward0>)\n",
      "Epoch 16 loss is 0.30207061767578125\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7226, 0.7346, 0.7715, 0.7096, 0.7265, 0.6413, 0.6484, 0.7488, 0.6136,\n",
      "        0.6463, 0.6935], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0815, -0.0044, -0.0027, -0.0434, -0.0204,  0.0371, -0.0092, -0.0007,\n",
      "        -0.0184,  0.1332], grad_fn=<AddBackward0>)\n",
      "tensor(0.1526, grad_fn=<SumBackward0>)\n",
      "Epoch 17 loss is 0.1525862216949463\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7070, 0.6475, 0.6336, 0.7517, 0.6572, 0.6647, 0.6653, 0.6304, 0.6087,\n",
      "        0.8184, 0.7005], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0245,  0.0744,  0.0162,  0.0518, -0.0288, -0.0089, -0.0187,  0.2551,\n",
      "         0.1167,  0.1530], grad_fn=<AddBackward0>)\n",
      "tensor(0.5864, grad_fn=<SumBackward0>)\n",
      "Epoch 18 loss is 0.5864463448524475\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6527, 0.7522, 0.7750, 0.5955, 0.5883, 0.6270, 0.7771, 0.6258, 0.6364,\n",
      "        0.6281, 0.6054], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2037, -0.0191, -0.0547, -0.0493,  0.3027,  0.0625,  0.0156, -0.0497,\n",
      "        -0.0068, -0.0103], grad_fn=<AddBackward0>)\n",
      "tensor(0.3947, grad_fn=<SumBackward0>)\n",
      "Epoch 19 loss is 0.39466238021850586\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7709, 0.5144, 0.8581, 0.8517, 0.5725, 0.8300, 0.5653, 0.8495, 0.5868,\n",
      "        0.5868, 0.8330], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1454,  0.1348,  0.0968, -0.0094, -0.0955,  0.4618, -0.0811,  0.0357,\n",
      "        -0.0055,  0.4104], grad_fn=<AddBackward0>)\n",
      "tensor(1.0936, grad_fn=<SumBackward0>)\n",
      "Epoch 20 loss is 1.093562364578247\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5473, 0.5367, 0.5464, 0.5059, 0.5540, 0.8530, 0.8517, 0.5436, 0.8685,\n",
      "        0.8688, 0.5275], grad_fn=<ViewBackward0>)\n",
      "tensor([-2.8342e-04, -1.3791e-02,  2.8749e-02,  5.1087e-01,  5.7624e-01,\n",
      "        -3.4400e-03,  2.5835e-02,  2.8634e-02, -5.3712e-03, -1.1364e-01],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(1.0338, grad_fn=<SumBackward0>)\n",
      "Epoch 21 loss is 1.0337963104248047\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5979, 0.5619, 0.8942, 0.9312, 0.9226, 0.5153, 0.5062, 0.9123, 0.8429,\n",
      "        0.5646, 0.5147], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4937,  0.5555,  0.6012, -0.1263, -0.1417, -0.0034,  0.5460,  0.0974,\n",
      "        -0.1325, -0.1094], grad_fn=<AddBackward0>)\n",
      "tensor(1.7804, grad_fn=<SumBackward0>)\n",
      "Epoch 22 loss is 1.7804052829742432\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8949, 0.8689, 0.8920, 0.5355, 0.5292, 0.5191, 0.8974, 0.5407, 0.5333,\n",
      "        0.8536, 0.8409], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0010, -0.1198, -0.1132, -0.1243,  0.6032,  0.0193,  0.0238, -0.0146,\n",
      "         0.5003,  0.5127], grad_fn=<AddBackward0>)\n",
      "tensor(1.2863, grad_fn=<SumBackward0>)\n",
      "Epoch 23 loss is 1.2862577438354492\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7715, 0.8845, 0.5235, 0.9068, 0.5553, 0.8872, 0.5403, 0.8749, 0.8967,\n",
      "        0.9516, 0.5051], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0827,  0.2255, -0.1097,  0.6062, -0.1222,  0.5326,  0.0159,  0.6856,\n",
      "        -0.1233, -0.1305], grad_fn=<AddBackward0>)\n",
      "tensor(1.4973, grad_fn=<SumBackward0>)\n",
      "Epoch 24 loss is 1.497340440750122\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8500, 0.5503, 0.8481, 0.9757, 0.8203, 0.9003, 0.5312, 0.8187, 0.8601,\n",
      "        0.5413, 0.8383], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0006,  0.2095,  0.4500,  0.0870, -0.1482, -0.0005, -0.0134,  0.0169,\n",
      "         0.0327, -0.0073], grad_fn=<AddBackward0>)\n",
      "tensor(0.6261, grad_fn=<SumBackward0>)\n",
      "Epoch 25 loss is 0.6260586977005005\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4979, 0.7549, 1.9989, 2.0940, 2.0760, 2.0624, 2.1102, 2.0133, 0.1194,\n",
      "        0.1409, 2.5478], grad_fn=<ViewBackward0>)\n",
      "tensor([ 2.5017,  2.6602,  2.2018,  0.1058,  0.0269, -0.0209, -0.6476, -0.6564,\n",
      "         0.8908,  4.0472], grad_fn=<AddBackward0>)\n",
      "tensor(11.1096, grad_fn=<SumBackward0>)\n",
      "Epoch 26 loss is 11.109603881835938\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.8407, 1.7186, 0.1787, 0.2876, 0.2927, 0.2544, 1.3673, 1.3758, 1.4432,\n",
      "        1.5126, 1.6119], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.5540, -0.5177, -0.4753,  0.1262,  1.7994,  1.8053,  1.9813,  0.2422,\n",
      "         0.3935,  0.2813], grad_fn=<AddBackward0>)\n",
      "tensor(5.0822, grad_fn=<SumBackward0>)\n",
      "Epoch 27 loss is 5.082180023193359\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5149, 0.8198, 0.8424, 0.7099, 0.6743, 0.6395, 0.6667, 0.6721, 0.6552,\n",
      "        0.7369, 0.7572], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.5459,  0.3250, -0.0485, -0.0676, -0.0144, -0.0007,  0.0262,  0.1170,\n",
      "         0.1418,  0.1700], grad_fn=<AddBackward0>)\n",
      "tensor(1.1946, grad_fn=<SumBackward0>)\n",
      "Epoch 28 loss is 1.1946266889572144\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5918, 0.6229, 0.7534, 0.6267, 0.6138, 0.5911, 0.6130, 0.7337, 0.7256,\n",
      "        0.7429, 0.7323], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2694,  0.0581, -0.0030, -0.0541, -0.0045,  0.1999,  0.2243,  0.2165,\n",
      "        -0.0005,  0.0111], grad_fn=<AddBackward0>)\n",
      "tensor(0.9172, grad_fn=<SumBackward0>)\n",
      "Epoch 29 loss is 0.9171536564826965\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.1562, 0.6998, 0.6338, 0.7817, 0.7837, 0.6087, 0.7649, 0.8329, 0.5957,\n",
      "        0.8372, 0.5717], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1741, -0.1248,  0.1399, -0.0083, -0.0056,  0.0819, -0.0044,  0.1205,\n",
      "        -0.0870, -0.0080], grad_fn=<AddBackward0>)\n",
      "tensor(-0.0700, grad_fn=<SumBackward0>)\n",
      "Epoch 30 loss is -0.07002270221710205\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8779, 0.8605, 0.5403, 0.8158, 0.5634, 0.5617, 0.5516, 0.8412, 0.5383,\n",
      "        0.8809, 0.5602], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1125, -0.0207, -0.0991,  0.0357, -0.0881,  0.4630, -0.0078,  0.5488,\n",
      "        -0.0937,  0.0365], grad_fn=<AddBackward0>)\n",
      "tensor(0.6622, grad_fn=<SumBackward0>)\n",
      "Epoch 31 loss is 0.6621513962745667\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5394, 0.9359, 0.4899, 0.5160, 0.4987, 0.9313, 0.5213, 0.8218, 0.8833,\n",
      "        0.8753, 0.8432], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0165, -0.0078, -0.1457,  0.7356,  0.0088,  0.5384, -0.0160,  0.5899,\n",
      "         0.0357, -0.0134], grad_fn=<AddBackward0>)\n",
      "tensor(1.7090, grad_fn=<SumBackward0>)\n",
      "Epoch 32 loss is 1.70900559425354\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9635, 0.4782, 0.9698, 0.9458, 0.9753, 0.9447, 0.9742, 0.4835, 0.5145,\n",
      "        0.4950, 0.4620], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0106, -0.0059,  0.8285, -0.0084,  0.0473, -0.1639, -0.1434, -0.1598,\n",
      "        -0.0072, -0.0175], grad_fn=<AddBackward0>)\n",
      "tensor(0.3803, grad_fn=<SumBackward0>)\n",
      "Epoch 33 loss is 0.38033777475357056\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.0349, 0.4814, 0.9843, 1.0427, 0.9634, 0.4436, 0.4194, 0.9877, 0.4551,\n",
      "        0.4285, 1.0463], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0169,  0.0129,  0.8033, -0.1802, -0.2078,  0.0405,  0.0192,  0.0153,\n",
      "         0.0977,  0.9853], grad_fn=<AddBackward0>)\n",
      "tensor(1.5694, grad_fn=<SumBackward0>)\n",
      "Epoch 34 loss is 1.569434642791748\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.0187, 0.9935, 0.4902, 0.9719, 0.4897, 0.9634, 0.4847, 1.0135, 0.4521,\n",
      "        0.4679, 0.4369], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1762, -0.0156, -0.1679,  0.7887, -0.1624,  0.8731, -0.1704, -0.0056,\n",
      "        -0.1922, -0.0051], grad_fn=<AddBackward0>)\n",
      "tensor(0.7663, grad_fn=<SumBackward0>)\n",
      "Epoch 35 loss is 0.7663119435310364\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4639, 1.0294, 1.0272, 0.4516, 0.4501, 0.9689, 0.5184, 0.4679, 0.4099,\n",
      "        0.4165, 1.0227], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.9388, -0.0041, -0.1931, -0.0194,  0.1114,  0.0297, -0.1863, -0.0340,\n",
      "         0.9248,  1.0214], grad_fn=<AddBackward0>)\n",
      "tensor(2.5891, grad_fn=<SumBackward0>)\n",
      "Epoch 36 loss is 2.589081287384033\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4345, 0.4231, 1.0618, 1.0512, 0.9936, 0.9897, 0.9983, 0.4469, 0.4746,\n",
      "        0.4605, 1.0039], grad_fn=<ViewBackward0>)\n",
      "tensor([ 1.0455,  1.0278,  0.9508, -0.0241, -0.0176, -0.1822, -0.1717, -0.1793,\n",
      "         0.9282,  0.8821], grad_fn=<AddBackward0>)\n",
      "tensor(4.2596, grad_fn=<SumBackward0>)\n",
      "Epoch 37 loss is 4.259641170501709\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9710, 0.9782, 0.5157, 0.4303, 0.9727, 0.4798, 0.5271, 0.9837, 0.4295,\n",
      "        0.4470, 0.4548], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1518, -0.1803, -0.0018, -0.0120,  0.1613,  0.0183, -0.0168, -0.0267,\n",
      "        -0.1763,  0.0423], grad_fn=<AddBackward0>)\n",
      "tensor(-0.3437, grad_fn=<SumBackward0>)\n",
      "Epoch 38 loss is -0.3436812162399292\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.0254, 1.0120, 0.4579, 1.0089, 0.9997, 0.4689, 0.4285, 0.9671, 0.4968,\n",
      "        0.4703, 1.0001], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1892, -0.0055, -0.0041,  0.0183, -0.1935, -0.0109,  0.0466,  0.0697,\n",
      "         0.0550,  0.8387], grad_fn=<AddBackward0>)\n",
      "tensor(0.6252, grad_fn=<SumBackward0>)\n",
      "Epoch 39 loss is 0.6252355575561523\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.4078, 0.5512, 0.8837, 0.5076, 0.9573, 0.4604, 0.4864, 0.4970, 0.4924,\n",
      "        0.5022, 0.9448], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1747, -0.3000,  0.6768, -0.1411, -0.0071, -0.1534,  0.0534,  0.0265,\n",
      "         0.7464,  0.7540], grad_fn=<AddBackward0>)\n",
      "tensor(1.4807, grad_fn=<SumBackward0>)\n",
      "Epoch 40 loss is 1.4806735515594482\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9737, 0.9375, 0.9702, 0.9770, 0.9560, 0.4881, 0.9790, 0.4896, 0.9796,\n",
      "        0.4875, 0.4522], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0012,  0.0054,  0.0308, -0.1607,  0.0034, -0.1555,  0.8191, -0.1638,\n",
      "        -0.0124, -0.1758], grad_fn=<AddBackward0>)\n",
      "tensor(0.1893, grad_fn=<SumBackward0>)\n",
      "Epoch 41 loss is 0.1892734169960022\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9903, 0.9772, 0.9380, 0.5195, 0.9537, 0.8925, 0.9366, 0.5116, 0.5024,\n",
      "        0.4780, 0.9440], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0174, -0.1570, -0.0078, -0.0152,  0.6952, -0.1474, -0.1301, -0.1529,\n",
      "         0.7207,  0.7361], grad_fn=<AddBackward0>)\n",
      "tensor(1.5243, grad_fn=<SumBackward0>)\n",
      "Epoch 42 loss is 1.5243308544158936\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4827, 0.9373, 0.9501, 0.4976, 0.9501, 0.9442, 0.5092, 0.5548, 0.8814,\n",
      "        0.4863, 0.4997], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.7790,  0.0249,  0.0213, -0.0020,  0.0192, -0.1317, -0.0209, -0.0076,\n",
      "        -0.0184, -0.1272], grad_fn=<AddBackward0>)\n",
      "tensor(0.5366, grad_fn=<SumBackward0>)\n",
      "Epoch 43 loss is 0.5365602374076843\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4763, 0.4307, 0.8750, 0.8824, 0.8648, 0.5325, 0.5479, 0.4960, 0.5602,\n",
      "        0.5140, 0.5011], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.6645,  0.6769,  0.7236, -0.1142, -0.1115, -0.1230,  0.0461, -0.0113,\n",
      "         0.0086, -0.0197], grad_fn=<AddBackward0>)\n",
      "tensor(1.7401, grad_fn=<SumBackward0>)\n",
      "Epoch 44 loss is 1.7401232719421387\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4818, 0.8730, 0.8736, 0.8967, 0.4949, 0.9141, 0.5223, 0.9250, 0.8663,\n",
      "        0.8495, 0.8649], grad_fn=<ViewBackward0>)\n",
      "tensor([ 6.5300e-01,  6.9144e-01, -1.2603e-01,  6.7464e-02, -1.2478e-01,\n",
      "         7.1681e-01, -1.5908e-02,  5.4540e-01, -2.0034e-02, -4.7255e-04],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(2.3869, grad_fn=<SumBackward0>)\n",
      "Epoch 45 loss is 2.3868846893310547\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4874, 0.5315, 0.5332, 0.8203, 0.5894, 0.6261, 0.7998, 0.8627, 0.8458,\n",
      "        0.8088, 0.5917], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0764,  0.5549,  0.0964,  0.1548, -0.0068,  0.4556,  0.3662,  0.0149,\n",
      "        -0.0904, -0.0847], grad_fn=<AddBackward0>)\n",
      "tensor(1.5373, grad_fn=<SumBackward0>)\n",
      "Epoch 46 loss is 1.5373098850250244\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8211, 0.8575, 0.8185, 0.5881, 0.5663, 0.5755, 0.8363, 0.8533, 0.5974,\n",
      "        0.7823, 0.5810], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0009, -0.0776, -0.0971, -0.0810,  0.4137,  0.4785,  0.0365, -0.0180,\n",
      "        -0.0908, -0.0054], grad_fn=<AddBackward0>)\n",
      "tensor(0.5579, grad_fn=<SumBackward0>)\n",
      "Epoch 47 loss is 0.5578795075416565\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8003, 0.7711, 0.6924, 0.7925, 0.7787, 0.7615, 0.6369, 0.5911, 0.7973,\n",
      "        0.6173, 0.5650], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0360, -0.0026,  0.0128,  0.1153, -0.0519, -0.0626,  0.0596, -0.0065,\n",
      "        -0.0087, -0.0774], grad_fn=<AddBackward0>)\n",
      "tensor(-0.0580, grad_fn=<SumBackward0>)\n",
      "Epoch 48 loss is -0.05801266431808472\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5819, 0.6036, 0.7297, 0.7393, 0.7729, 0.6559, 0.7384, 0.7162, 0.6504,\n",
      "        0.6814, 0.6431], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2463,  0.2623,  0.2821, -0.0246, -0.0003, -0.0189, -0.0018, -0.0190,\n",
      "        -0.0244, -0.0024], grad_fn=<AddBackward0>)\n",
      "tensor(0.6993, grad_fn=<SumBackward0>)\n",
      "Epoch 49 loss is 0.6992985010147095\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.0439, 0.5988, 0.8557, 0.7147, 0.7044, 0.6372, 0.6789, 0.6521, 0.7062,\n",
      "        0.6422, 0.6493], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0628, -0.1098,  0.1760, -0.0728, -0.0119, -0.0174,  0.1150, -0.0122,\n",
      "        -0.0010, -0.0190], grad_fn=<AddBackward0>)\n",
      "tensor(-0.0158, grad_fn=<SumBackward0>)\n",
      "Epoch 50 loss is -0.015785694122314453\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6588, 0.6870, 0.6934, 0.6862, 0.6529, 0.6496, 0.7017, 0.7687, 0.6746,\n",
      "        0.7012, 0.7075], grad_fn=<ViewBackward0>)\n",
      "tensor([ 5.7589e-02,  4.5653e-02, -1.1390e-02, -1.4583e-02,  2.5824e-02,\n",
      "         1.9307e-01,  4.1596e-02, -1.8406e-04, -2.0397e-02,  5.4829e-02],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.3720, grad_fn=<SumBackward0>)\n",
      "Epoch 51 loss is 0.3720055818557739\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7126, 0.6816, 0.6992, 0.7085, 0.7133, 0.7432, 0.6458, 0.6566, 0.6184,\n",
      "        0.6771, 0.7018], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0045, -0.0014,  0.0528,  0.0733, -0.0209, -0.0189, -0.0416,  0.0521,\n",
      "         0.0753,  0.1391], grad_fn=<AddBackward0>)\n",
      "tensor(0.3055, grad_fn=<SumBackward0>)\n",
      "Epoch 52 loss is 0.3054697513580322\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7093, 0.7182, 0.6449, 0.7224, 0.7025, 0.6773, 0.7133, 0.6381, 0.7133,\n",
      "        0.7678, 0.7196], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0215,  0.0218, -0.0052,  0.0541, -0.0030, -0.0214,  0.0599,  0.0908,\n",
      "         0.1358,  0.0106], grad_fn=<AddBackward0>)\n",
      "tensor(0.3219, grad_fn=<SumBackward0>)\n",
      "Epoch 53 loss is 0.3218594789505005\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6919, 0.7457, 0.7386, 0.6508, 0.7287, 0.7408, 0.6541, 0.7318, 0.7404,\n",
      "        0.6653, 0.6554], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0778, -0.0137, -0.0057,  0.0038,  0.0055,  0.0052, -0.0002,  0.0186,\n",
      "        -0.0255, -0.0283], grad_fn=<AddBackward0>)\n",
      "tensor(0.0376, grad_fn=<SumBackward0>)\n",
      "Epoch 54 loss is 0.037593841552734375\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6752, 0.6547, 0.7114, 0.7147, 0.7363, 0.6811, 0.6540, 0.8023, 0.7602,\n",
      "        0.7086, 0.6565], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0602,  0.0657,  0.1359, -0.0101, -0.0202,  0.1101,  0.1318,  0.0910,\n",
      "        -0.0486, -0.0346], grad_fn=<AddBackward0>)\n",
      "tensor(0.4812, grad_fn=<SumBackward0>)\n",
      "Epoch 55 loss is 0.481209933757782\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6225, 0.7221, 0.6758, 0.6568, 0.6908, 0.6262, 0.6458, 0.6617, 0.7028,\n",
      "        0.6959, 0.6932], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0887,  0.0572, -0.0104, -0.0165, -0.0037, -0.0097,  0.1276,  0.0837,\n",
      "         0.0526, -0.0032], grad_fn=<AddBackward0>)\n",
      "tensor(0.3662, grad_fn=<SumBackward0>)\n",
      "Epoch 56 loss is 0.36619871854782104\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6680, 0.6717, 0.6930, 0.6911, 0.6324, 0.6636, 0.7370, 0.6730, 0.7095,\n",
      "        0.6877, 0.6298], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0417,  0.0386, -0.0131, -0.0098,  0.0764,  0.0676,  0.0765, -0.0164,\n",
      "        -0.0144, -0.0266], grad_fn=<AddBackward0>)\n",
      "tensor(0.2207, grad_fn=<SumBackward0>)\n",
      "Epoch 57 loss is 0.22067612409591675\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8011, 0.6966, 0.7126, 0.7581, 0.6947, 0.6551, 0.7610, 0.6457, 0.7377,\n",
      "        0.6192, 0.7328], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0295, -0.0144, -0.0006, -0.0192,  0.0049, -0.0163,  0.1377, -0.0473,\n",
      "         0.1451, -0.0016], grad_fn=<AddBackward0>)\n",
      "tensor(0.1588, grad_fn=<SumBackward0>)\n",
      "Epoch 58 loss is 0.15875208377838135\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8143, 0.6085, 0.7610, 0.6645, 0.7280, 0.7576, 0.7308, 0.7482, 0.6585,\n",
      "        0.7820, 0.6758], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0178, -0.0499,  0.1992, -0.0011,  0.1104,  0.0336, -0.0330,  0.0853,\n",
      "        -0.0241,  0.0288], grad_fn=<AddBackward0>)\n",
      "tensor(0.3313, grad_fn=<SumBackward0>)\n",
      "Epoch 59 loss is 0.3313315510749817\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.1034, 0.7861, 0.6677, 0.6432, 0.7616, 0.7596, 0.6170, 0.6318, 0.6195,\n",
      "        0.6113, 0.6328], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1452, -0.1534, -0.0082,  0.1532, -0.0087, -0.0433, -0.0467, -0.0019,\n",
      "         0.0017,  0.0221], grad_fn=<AddBackward0>)\n",
      "tensor(-0.2304, grad_fn=<SumBackward0>)\n",
      "Epoch 60 loss is -0.2304157018661499\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8092, 0.8096, 0.8099, 0.6064, 0.7920, 0.5512, 0.7951, 0.6106, 0.5852,\n",
      "        0.7783, 0.6090], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0012, -0.0676, -0.0058, -0.0863,  0.3144, -0.0605,  0.0567, -0.0056,\n",
      "        -0.0005,  0.0397], grad_fn=<AddBackward0>)\n",
      "tensor(0.1857, grad_fn=<SumBackward0>)\n",
      "Epoch 61 loss is 0.18566584587097168\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8495, 0.8167, 0.7939, 0.7928, 0.7750, 0.8176, 0.8089, 0.5880, 0.5598,\n",
      "        0.5718, 0.8250], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0185, -0.0189, -0.0139,  0.0396,  0.0270, -0.0623, -0.0860, -0.0790,\n",
      "         0.3949,  0.4420], grad_fn=<AddBackward0>)\n",
      "tensor(0.6248, grad_fn=<SumBackward0>)\n",
      "Epoch 62 loss is 0.6247891783714294\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8290, 0.8182, 0.8058, 0.8345, 0.8568, 0.5992, 0.5860, 0.8021, 0.7915,\n",
      "        0.6028, 0.6180], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0077,  0.0093,  0.0643, -0.0688, -0.0828, -0.0182,  0.3205,  0.0279,\n",
      "        -0.0614, -0.0578], grad_fn=<AddBackward0>)\n",
      "tensor(0.1251, grad_fn=<SumBackward0>)\n",
      "Epoch 63 loss is 0.12513786554336548\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7844, 0.6129, 0.7805, 0.5586, 0.5686, 0.5635, 0.6714, 0.8094, 0.5906,\n",
      "        0.7921, 0.7354], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0013, -0.0753, -0.0148, -0.0723,  0.1880,  0.4014,  0.0452,  0.2011,\n",
      "        -0.0247,  0.2413], grad_fn=<AddBackward0>)\n",
      "tensor(0.8887, grad_fn=<SumBackward0>)\n",
      "Epoch 64 loss is 0.8886619210243225\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8394, 0.7911, 0.5944, 0.7848, 0.5664, 0.5696, 0.8263, 0.5432, 0.7753,\n",
      "        0.8583, 0.5470], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0817, -0.0182, -0.0749, -0.0082,  0.0691, -0.0077,  0.3428,  0.0534,\n",
      "         0.0064, -0.0761], grad_fn=<AddBackward0>)\n",
      "tensor(0.2048, grad_fn=<SumBackward0>)\n",
      "Epoch 65 loss is 0.20476466417312622\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8551, 0.6008, 0.6086, 0.6176, 0.6004, 0.8404, 0.6241, 0.7624, 0.6006,\n",
      "        0.6145, 0.6183], grad_fn=<ViewBackward0>)\n",
      "tensor([-8.2173e-02, -7.9171e-02, -1.4323e-04,  3.8639e-01,  1.0865e-02,\n",
      "         2.7004e-01, -7.9937e-02, -3.2132e-03, -4.8022e-02,  2.9515e-02],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.4042, grad_fn=<SumBackward0>)\n",
      "Epoch 66 loss is 0.40415090322494507\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8359, 0.8138, 0.7997, 0.7916, 0.7946, 0.7727, 0.6242, 0.7753, 0.5688,\n",
      "        0.7860, 0.7480], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0121, -0.0148, -0.0064, -0.0090, -0.0558, -0.0064, -0.0680,  0.2698,\n",
      "        -0.0091,  0.2987], grad_fn=<AddBackward0>)\n",
      "tensor(0.3869, grad_fn=<SumBackward0>)\n",
      "Epoch 67 loss is 0.3869328498840332\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8147, 0.8030, 0.5817, 0.7678, 0.6264, 0.7310, 0.7980, 0.7083, 0.6914,\n",
      "        0.5917, 0.6098], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0777, -0.0156, -0.0588,  0.2488,  0.0504,  0.1364, -0.0132, -0.0688,\n",
      "        -0.0328, -0.0272], grad_fn=<AddBackward0>)\n",
      "tensor(0.1414, grad_fn=<SumBackward0>)\n",
      "Epoch 68 loss is 0.14139938354492188\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6291, 0.7781, 0.6438, 0.6238, 0.7383, 0.7449, 0.7642, 0.6138, 0.5959,\n",
      "        0.7959, 0.7910], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0246, -0.0018, -0.0133,  0.1684,  0.2340, -0.0415, -0.0497,  0.0527,\n",
      "         0.2953,  0.3252], grad_fn=<AddBackward0>)\n",
      "tensor(0.9940, grad_fn=<SumBackward0>)\n",
      "Epoch 69 loss is 0.9939897656440735\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9913, 0.6601, 0.7323, 0.7215, 0.6013, 0.7538, 0.7271, 0.6234, 0.6974,\n",
      "        0.7456, 0.7034], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0863, -0.0899, -0.0196,  0.0359,  0.0094,  0.0368, -0.0188,  0.0307,\n",
      "         0.1333,  0.0099], grad_fn=<AddBackward0>)\n",
      "tensor(0.0414, grad_fn=<SumBackward0>)\n",
      "Epoch 70 loss is 0.04141157865524292\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7158, 0.6917, 0.6919, 0.6680, 0.7119, 0.6901, 0.6873, 0.6720, 0.6554,\n",
      "        0.7109, 0.6778], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0080, -0.0159,  0.0337, -0.0006,  0.0321, -0.0133, -0.0116,  0.0393,\n",
      "         0.0097,  0.0373], grad_fn=<AddBackward0>)\n",
      "tensor(0.1027, grad_fn=<SumBackward0>)\n",
      "Epoch 71 loss is 0.1026884913444519\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7301, 0.6929, 0.7374, 0.6676, 0.6509, 0.7024, 0.7821, 0.6616, 0.6914,\n",
      "        0.6915, 0.7692], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0122, -0.0208, -0.0140, -0.0117,  0.1908,  0.0179, -0.0037, -0.0302,\n",
      "         0.1793,  0.1296], grad_fn=<AddBackward0>)\n",
      "tensor(0.4494, grad_fn=<SumBackward0>)\n",
      "Epoch 72 loss is 0.4494265913963318\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6373, 0.6502, 0.7558, 0.7671, 0.6052, 0.6931, 0.6924, 0.6378, 0.6565,\n",
      "        0.6590, 0.7495], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1975,  0.2164, -0.0150, -0.0209, -0.0249,  0.0543, -0.0122, -0.0111,\n",
      "         0.1861,  0.1551], grad_fn=<AddBackward0>)\n",
      "tensor(0.7253, grad_fn=<SumBackward0>)\n",
      "Epoch 73 loss is 0.7252519726753235\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7220, 0.6103, 0.7978, 0.7782, 0.7721, 0.6411, 0.6524, 0.6110, 0.6201,\n",
      "        0.6207, 0.6991], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1263,  0.0936,  0.2697, -0.0523, -0.0419, -0.0537, -0.0070, -0.0106,\n",
      "         0.1468,  0.1316], grad_fn=<AddBackward0>)\n",
      "tensor(0.6026, grad_fn=<SumBackward0>)\n",
      "Epoch 74 loss is 0.6026326417922974\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7418, 0.7633, 0.6136, 0.8001, 0.5934, 0.6142, 0.5730, 0.7750, 0.7758,\n",
      "        0.6029, 0.7714], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0427,  0.0971, -0.0566,  0.0010, -0.0757,  0.3026,  0.2692,  0.0499,\n",
      "        -0.0012, -0.0014], grad_fn=<AddBackward0>)\n",
      "tensor(0.5421, grad_fn=<SumBackward0>)\n",
      "Epoch 75 loss is 0.5421184301376343\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6458, 0.6174, 0.7619, 0.6145, 0.7870, 0.7570, 0.6511, 0.6273, 0.5956,\n",
      "        0.6097, 0.8141], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1935, -0.0105,  0.2826, -0.0016,  0.0611, -0.0532, -0.0538, -0.0138,\n",
      "         0.3114,  0.3642], grad_fn=<AddBackward0>)\n",
      "tensor(1.0798, grad_fn=<SumBackward0>)\n",
      "Epoch 76 loss is 1.0798307657241821\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6228, 0.7818, 0.7394, 0.5711, 0.8257, 0.5669, 0.6020, 0.7827, 0.5853,\n",
      "        0.8480, 0.7585], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1944, -0.0172,  0.0733, -0.0575,  0.0515, -0.0143,  0.0308,  0.4100,\n",
      "        -0.0080,  0.2887], grad_fn=<AddBackward0>)\n",
      "tensor(0.9514, grad_fn=<SumBackward0>)\n",
      "Epoch 77 loss is 0.9514488577842712\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6803, 0.6230, 0.6280, 0.7535, 0.7624, 0.5638, 0.5377, 0.8133, 0.8240,\n",
      "        0.5969, 0.7913], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0175,  0.1219,  0.2324, -0.0214, -0.0719,  0.0847,  0.4337,  0.0988,\n",
      "        -0.0073, -0.0109], grad_fn=<AddBackward0>)\n",
      "tensor(0.8425, grad_fn=<SumBackward0>)\n",
      "Epoch 78 loss is 0.8424639701843262\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7450, 0.6026, 0.6189, 0.8091, 0.8455, 0.8649, 0.8191, 0.8394, 0.6120,\n",
      "        0.5823, 0.8507], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0420,  0.1070,  0.4048,  0.4100,  0.0167, -0.0020, -0.0843, -0.0789,\n",
      "         0.0188,  0.3978], grad_fn=<AddBackward0>)\n",
      "tensor(1.1478, grad_fn=<SumBackward0>)\n",
      "Epoch 79 loss is 1.1477515697479248\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8570, 0.5115, 0.5632, 0.7810, 0.6054, 0.6330, 0.5752, 0.7847, 0.7784,\n",
      "        0.7789, 0.5891], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0979, -0.0253,  0.1565,  0.1162, -0.0686,  0.2988,  0.2424,  0.3396,\n",
      "        -0.0652, -0.0631], grad_fn=<AddBackward0>)\n",
      "tensor(0.8333, grad_fn=<SumBackward0>)\n",
      "Epoch 80 loss is 0.8333475589752197\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6518, 0.8043, 0.5952, 0.7993, 0.5998, 0.6239, 0.7634, 0.6158, 0.8182,\n",
      "        0.6144, 0.6417], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0188,  0.2458, -0.0682,  0.0478, -0.0119,  0.0266,  0.3237, -0.0497,\n",
      "         0.0432, -0.0588], grad_fn=<AddBackward0>)\n",
      "tensor(0.4797, grad_fn=<SumBackward0>)\n",
      "Epoch 81 loss is 0.4797295331954956\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7080, 0.6018, 0.8371, 0.7809, 0.6163, 0.6256, 0.8289, 0.8287, 0.8309,\n",
      "        0.7873, 0.7403], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2152,  0.1215,  0.0241, -0.0705,  0.0800,  0.3541,  0.3422, -0.0139,\n",
      "        -0.0295, -0.0302], grad_fn=<AddBackward0>)\n",
      "tensor(0.9931, grad_fn=<SumBackward0>)\n",
      "Epoch 82 loss is 0.9930557608604431\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7070, 0.7375, 0.6132, 0.7753, 0.7209, 0.6915, 0.7015, 0.7449, 0.7864,\n",
      "        0.6284, 0.7314], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0313,  0.1138, -0.0056,  0.1305, -0.0246,  0.0401,  0.1582, -0.0243,\n",
      "        -0.0045, -0.0183], grad_fn=<AddBackward0>)\n",
      "tensor(0.3339, grad_fn=<SumBackward0>)\n",
      "Epoch 83 loss is 0.33393216133117676\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7351, 0.6820, 0.7191, 0.6322, 0.7280, 0.7007, 0.6694, 0.7635, 0.6354,\n",
      "        0.6543, 0.7314], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0053, -0.0343,  0.0767, -0.0061,  0.0621,  0.0591, -0.0218, -0.0050,\n",
      "        -0.0107,  0.1600], grad_fn=<AddBackward0>)\n",
      "tensor(0.2746, grad_fn=<SumBackward0>)\n",
      "Epoch 84 loss is 0.2745940089225769\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7371, 0.6603, 0.6919, 0.6571, 0.6161, 0.6819, 0.6869, 0.7342, 0.6654,\n",
      "        0.6828, 0.7131], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0151, -0.0267, -0.0147, -0.0034,  0.0497,  0.1968, -0.0055, -0.0014,\n",
      "        -0.0070,  0.0794], grad_fn=<AddBackward0>)\n",
      "tensor(0.2521, grad_fn=<SumBackward0>)\n",
      "Epoch 85 loss is 0.2521333694458008\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7529, 0.7167, 0.6495, 0.7702, 0.6746, 0.6803, 0.6497, 0.6492, 0.6810,\n",
      "        0.7163, 0.6668], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0345,  0.0289, -0.0140,  0.0513, -0.0402, -0.0085,  0.0012,  0.1109,\n",
      "         0.0293, -0.0047], grad_fn=<AddBackward0>)\n",
      "tensor(0.1197, grad_fn=<SumBackward0>)\n",
      "Epoch 86 loss is 0.11974811553955078\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7506, 0.7425, 0.7823, 0.7083, 0.6897, 0.6300, 0.6987, 0.6573, 0.6594,\n",
      "        0.5971, 0.8008], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0527, -0.0141, -0.0176, -0.0508, -0.0032, -0.0108,  0.0489, -0.0339,\n",
      "         0.2391,  0.2357], grad_fn=<AddBackward0>)\n",
      "tensor(0.4462, grad_fn=<SumBackward0>)\n",
      "Epoch 87 loss is 0.44622164964675903\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7910, 0.7392, 0.6975, 0.7492, 0.6500, 0.7562, 0.5827, 0.7113, 0.7748,\n",
      "        0.7870, 0.6300], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0312, -0.0139, -0.0297,  0.0978, -0.0555,  0.1021,  0.0309,  0.3406,\n",
      "        -0.0271, -0.0483], grad_fn=<AddBackward0>)\n",
      "tensor(0.3657, grad_fn=<SumBackward0>)\n",
      "Epoch 88 loss is 0.3657190203666687\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6022, 0.5800, 0.5919, 0.7675, 0.7851, 0.5846, 0.7663, 0.8294, 0.6373,\n",
      "        0.6547, 0.7539], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0034,  0.2755,  0.3419, -0.0024, -0.0004,  0.0738,  0.0879, -0.0372,\n",
      "        -0.0252,  0.1943], grad_fn=<AddBackward0>)\n",
      "tensor(0.9048, grad_fn=<SumBackward0>)\n",
      "Epoch 89 loss is 0.9047779440879822\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.0704, 0.7035, 0.6196, 0.5842, 0.5992, 0.7824, 0.6048, 0.7424, 0.7723,\n",
      "        0.6274, 0.5850], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1502, -0.1621, -0.0348,  0.2713,  0.0343,  0.2387, -0.0034,  0.0377,\n",
      "        -0.0525, -0.0624], grad_fn=<AddBackward0>)\n",
      "tensor(0.1167, grad_fn=<SumBackward0>)\n",
      "Epoch 90 loss is 0.11667042970657349\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5505, 0.5853, 0.5593, 0.5549, 0.7980, 0.8049, 0.6196, 0.5828, 0.7935,\n",
      "        0.8017, 0.5598], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0147,  0.0074,  0.3544,  0.4093,  0.1079, -0.0717, -0.0038,  0.3035,\n",
      "        -0.0077, -0.0779], grad_fn=<AddBackward0>)\n",
      "tensor(1.0360, grad_fn=<SumBackward0>)\n",
      "Epoch 91 loss is 1.0360019207000732\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8636, 0.5719, 0.8323, 0.5528, 0.8046, 0.7989, 0.7767, 0.8297, 0.5971,\n",
      "        0.8034, 0.8446], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0104, -0.1036,  0.3878, -0.0111,  0.3732,  0.0419, -0.0673,  0.0445,\n",
      "         0.0249,  0.4124], grad_fn=<AddBackward0>)\n",
      "tensor(1.0922, grad_fn=<SumBackward0>)\n",
      "Epoch 92 loss is 1.0922483205795288\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8567, 0.6020, 0.8205, 0.8080, 0.8122, 0.5415, 0.7847, 0.8034, 0.5598,\n",
      "        0.8458, 0.8480], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0121, -0.0163,  0.3503, -0.0930, -0.0077, -0.0029,  0.0306,  0.1018,\n",
      "         0.0742,  0.4803], grad_fn=<AddBackward0>)\n",
      "tensor(0.9052, grad_fn=<SumBackward0>)\n",
      "Epoch 93 loss is 0.9051965475082397\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5546, 0.6014, 0.7915, 0.6327, 0.6565, 0.7776, 0.5978, 0.5996, 0.8020,\n",
      "        0.7585, 0.6067], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.3948,  0.1301,  0.0918, -0.0046, -0.0116, -0.0190,  0.0406,  0.2678,\n",
      "         0.0118, -0.0651], grad_fn=<AddBackward0>)\n",
      "tensor(0.8365, grad_fn=<SumBackward0>)\n",
      "Epoch 94 loss is 0.8365471363067627\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8326, 0.5911, 0.6535, 0.7843, 0.7086, 0.6618, 0.7800, 0.6375, 0.6612,\n",
      "        0.6178, 0.7715], grad_fn=<ViewBackward0>)\n",
      "tensor([-5.9693e-02, -1.6083e-02,  1.9570e-01,  1.3846e-02, -1.4514e-03,\n",
      "        -2.3688e-02, -2.0230e-04, -5.4079e-02,  2.2330e-01,  1.8378e-01],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.4614, grad_fn=<SumBackward0>)\n",
      "Epoch 95 loss is 0.4614282250404358\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6121, 0.6239, 0.6623, 0.7466, 0.6908, 0.5781, 0.7694, 0.6361, 0.6940,\n",
      "        0.7619, 0.6306], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0836,  0.2241,  0.1115, -0.0281,  0.0381, -0.0182,  0.1932, -0.0025,\n",
      "        -0.0018, -0.0211], grad_fn=<AddBackward0>)\n",
      "tensor(0.5788, grad_fn=<SumBackward0>)\n",
      "Epoch 96 loss is 0.5787773132324219\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7929, 0.6205, 0.6009, 0.7280, 0.7529, 0.7617, 0.6396, 0.6390, 0.6536,\n",
      "        0.6755, 0.6630], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0640, -0.0216,  0.2207,  0.2679, -0.0295, -0.0380, -0.0360,  0.0598,\n",
      "         0.0400,  0.0157], grad_fn=<AddBackward0>)\n",
      "tensor(0.4150, grad_fn=<SumBackward0>)\n",
      "Epoch 97 loss is 0.41503673791885376\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7500, 0.7337, 0.7222, 0.7037, 0.6238, 0.6709, 0.6529, 0.7489, 0.6022,\n",
      "        0.6353, 0.6954], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0093, -0.0155, -0.0366, -0.0171, -0.0169,  0.2085, -0.0229, -0.0059,\n",
      "        -0.0178,  0.1555], grad_fn=<AddBackward0>)\n",
      "tensor(0.2220, grad_fn=<SumBackward0>)\n",
      "Epoch 98 loss is 0.22195899486541748\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7255, 0.6817, 0.6426, 0.7027, 0.7178, 0.6768, 0.6904, 0.6697, 0.6091,\n",
      "        0.7529, 0.6609], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0276, -0.0076,  0.0601,  0.0569, -0.0041, -0.0160, -0.0225,  0.1043,\n",
      "        -0.0030,  0.0862], grad_fn=<AddBackward0>)\n",
      "tensor(0.2267, grad_fn=<SumBackward0>)\n",
      "Epoch 99 loss is 0.22667664289474487\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4057, 0.7306, 0.7083, 0.7018, 0.6521, 0.6936, 0.6537, 0.6672, 0.7234,\n",
      "        0.7396, 0.7221], grad_fn=<ViewBackward0>)\n",
      "tensor([ 5.0431e-01,  4.9347e-01, -2.6155e-02, -4.8913e-03, -1.6024e-02,\n",
      "         2.5133e-02,  4.9664e-02,  1.4323e-01,  9.1448e-02, -4.3917e-04],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(1.2597, grad_fn=<SumBackward0>)\n",
      "Epoch 100 loss is 1.2597483396530151\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6266, 0.7822, 0.7453, 0.7210, 0.6483, 0.7080, 0.7414, 0.6638, 0.6807,\n",
      "        0.7118, 0.7685], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1978,  0.1575, -0.0446, -0.0124,  0.0340,  0.0259, -0.0091, -0.0099,\n",
      "         0.1744,  0.1462], grad_fn=<AddBackward0>)\n",
      "tensor(0.6598, grad_fn=<SumBackward0>)\n",
      "Epoch 101 loss is 0.6597564220428467\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6267, 0.6824, 0.6583, 0.6667, 0.6683, 0.6366, 0.7307, 0.7342, 0.6432,\n",
      "        0.6790, 0.7312], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0527,  0.0666, -0.0047, -0.0072,  0.1067,  0.1099,  0.0110, -0.0172,\n",
      "        -0.0010,  0.1466], grad_fn=<AddBackward0>)\n",
      "tensor(0.4634, grad_fn=<SumBackward0>)\n",
      "Epoch 102 loss is 0.46343672275543213\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6626, 0.7225, 0.6953, 0.6637, 0.6864, 0.7151, 0.7188, 0.6894, 0.7017,\n",
      "        0.6711, 0.7574], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0545,  0.0018, -0.0120,  0.0331,  0.0918,  0.0050, -0.0045, -0.0159,\n",
      "         0.1133,  0.0928], grad_fn=<AddBackward0>)\n",
      "tensor(0.3598, grad_fn=<SumBackward0>)\n",
      "Epoch 103 loss is 0.35977375507354736\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6208, 0.6856, 0.7147, 0.6498, 0.7066, 0.6936, 0.7430, 0.6590, 0.6586,\n",
      "        0.6578, 0.7101], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1564,  0.0483,  0.0351, -0.0070,  0.1553, -0.0159, -0.0117, -0.0284,\n",
      "         0.0853,  0.0859], grad_fn=<AddBackward0>)\n",
      "tensor(0.5033, grad_fn=<SumBackward0>)\n",
      "Epoch 104 loss is 0.5032802224159241\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7325, 0.7016, 0.6796, 0.6702, 0.6911, 0.6623, 0.6868, 0.6157, 0.6392,\n",
      "        0.6914, 0.6492], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0177, -0.0208, -0.0035, -0.0058,  0.0277, -0.0251, -0.0077,  0.0076,\n",
      "         0.0559,  0.0168], grad_fn=<AddBackward0>)\n",
      "tensor(0.0274, grad_fn=<SumBackward0>)\n",
      "Epoch 105 loss is 0.027437031269073486\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7170, 0.6789, 0.6539, 0.7711, 0.7119, 0.7021, 0.6176, 0.6145, 0.6079,\n",
      "        0.6548, 0.7756], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0210,  0.0902,  0.0550,  0.0802, -0.0512, -0.0325, -0.0314,  0.0619,\n",
      "         0.2685,  0.2795], grad_fn=<AddBackward0>)\n",
      "tensor(0.6993, grad_fn=<SumBackward0>)\n",
      "Epoch 106 loss is 0.6993082165718079\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7005, 0.6450, 0.7439, 0.5852, 0.6263, 0.7191, 0.7742, 0.7466, 0.7429,\n",
      "        0.6527, 0.7189], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0723, -0.0385, -0.0062, -0.0083,  0.3150,  0.2005,  0.0396, -0.0405,\n",
      "        -0.0092, -0.0080], grad_fn=<AddBackward0>)\n",
      "tensor(0.5167, grad_fn=<SumBackward0>)\n",
      "Epoch 107 loss is 0.5166997313499451\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6970, 0.7387, 0.6248, 0.7667, 0.7675, 0.6243, 0.7707, 0.6143, 0.7891,\n",
      "        0.7178, 0.7592], grad_fn=<ViewBackward0>)\n",
      "tensor([-2.4048e-02,  1.1626e-01,  4.7891e-02, -1.6582e-04,  6.5860e-03,\n",
      "        -5.1062e-02,  2.7459e-01, -1.7638e-02,  2.4146e-01, -9.9803e-03],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.5839, grad_fn=<SumBackward0>)\n",
      "Epoch 108 loss is 0.5838984251022339\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7000, 0.7616, 0.6545, 0.7390, 0.7272, 0.7235, 0.6070, 0.6343, 0.7640,\n",
      "        0.8108, 0.5951], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0151,  0.0651, -0.0114,  0.1149, -0.0440, -0.0310,  0.0675,  0.3397,\n",
      "        -0.0131, -0.0563], grad_fn=<AddBackward0>)\n",
      "tensor(0.4162, grad_fn=<SumBackward0>)\n",
      "Epoch 109 loss is 0.41623616218566895\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5059, 0.5634, 0.8082, 0.7468, 0.6101, 0.6552, 0.7388, 0.8061, 0.6360,\n",
      "        0.6970, 0.6984], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.5038,  0.4015,  0.0779, -0.0510, -0.0027,  0.3266, -0.0064, -0.0139,\n",
      "        -0.0359,  0.1039], grad_fn=<AddBackward0>)\n",
      "tensor(1.3040, grad_fn=<SumBackward0>)\n",
      "Epoch 110 loss is 1.3039638996124268\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6243, 0.6865, 0.6786, 0.6659, 0.6557, 0.6389, 0.7637, 0.7497, 0.7022,\n",
      "        0.6498, 0.7488], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0905,  0.0694, -0.0103, -0.0132,  0.1629,  0.1568,  0.1055, -0.0379,\n",
      "        -0.0003,  0.0776], grad_fn=<AddBackward0>)\n",
      "tensor(0.6009, grad_fn=<SumBackward0>)\n",
      "Epoch 111 loss is 0.6009441018104553\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7085, 0.6743, 0.6887, 0.6698, 0.6364, 0.6750, 0.6771, 0.6941, 0.7201,\n",
      "        0.7349, 0.6325], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0066, -0.0129, -0.0126, -0.0046,  0.0121,  0.0961,  0.0750,  0.0964,\n",
      "        -0.0205, -0.0292], grad_fn=<AddBackward0>)\n",
      "tensor(0.1932, grad_fn=<SumBackward0>)\n",
      "Epoch 112 loss is 0.19315779209136963\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5893, 0.6364, 0.7004, 0.7211, 0.7024, 0.6696, 0.6649, 0.7434, 0.7630,\n",
      "        0.7370, 0.6712], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1852,  0.2197,  0.1099, -0.0103, -0.0187,  0.0684,  0.1557,  0.1202,\n",
      "        -0.0241, -0.0306], grad_fn=<AddBackward0>)\n",
      "tensor(0.7754, grad_fn=<SumBackward0>)\n",
      "Epoch 113 loss is 0.7754123210906982\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7327, 0.6102, 0.6815, 0.7257, 0.6715, 0.7010, 0.6798, 0.7144, 0.7214,\n",
      "        0.6765, 0.6755], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0171, -0.0023,  0.1021,  0.0324, -0.0153,  0.0716,  0.0339, -0.0011,\n",
      "        -0.0130, -0.0153], grad_fn=<AddBackward0>)\n",
      "tensor(0.1760, grad_fn=<SumBackward0>)\n",
      "Epoch 114 loss is 0.1760074496269226\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7429, 0.6480, 0.6601, 0.6664, 0.7092, 0.7142, 0.6735, 0.6805, 0.6821,\n",
      "        0.6643, 0.7037], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0276, -0.0255,  0.1020,  0.0902,  0.0119, -0.0096, -0.0107, -0.0031,\n",
      "         0.0387,  0.0361], grad_fn=<AddBackward0>)\n",
      "tensor(0.2023, grad_fn=<SumBackward0>)\n",
      "Epoch 115 loss is 0.20230746269226074\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7332, 0.6427, 0.6048, 0.6600, 0.6371, 0.7000, 0.6811, 0.6901, 0.6279,\n",
      "        0.6916, 0.6419], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0428, -0.0244, -0.0019,  0.1588,  0.0352,  0.0884, -0.0240,  0.0174,\n",
      "        -0.0161,  0.0233], grad_fn=<AddBackward0>)\n",
      "tensor(0.2138, grad_fn=<SumBackward0>)\n",
      "Epoch 116 loss is 0.2138388752937317\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7972, 0.5862, 0.6641, 0.6704, 0.6278, 0.7461, 0.7023, 0.6289, 0.7614,\n",
      "        0.6971, 0.7223], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0444, -0.0423,  0.0693,  0.1367,  0.0532,  0.0018,  0.0254, -0.0018,\n",
      "         0.1558, -0.0130], grad_fn=<AddBackward0>)\n",
      "tensor(0.3408, grad_fn=<SumBackward0>)\n",
      "Epoch 117 loss is 0.340822696685791\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8010, 0.8032, 0.7586, 0.6784, 0.7165, 0.6367, 0.7535, 0.7253, 0.6495,\n",
      "        0.7581, 0.7742], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0141, -0.0409, -0.0289, -0.0406,  0.1250,  0.0147,  0.0213,  0.0077,\n",
      "         0.0814,  0.2078], grad_fn=<AddBackward0>)\n",
      "tensor(0.3334, grad_fn=<SumBackward0>)\n",
      "Epoch 118 loss is 0.3334352970123291\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8004, 0.5967, 0.8026, 0.6861, 0.7319, 0.7145, 0.7212, 0.7005, 0.7081,\n",
      "        0.6600, 0.7279], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0036, -0.0381,  0.2253, -0.0294,  0.0585, -0.0105, -0.0021, -0.0204,\n",
      "         0.0458,  0.0330], grad_fn=<AddBackward0>)\n",
      "tensor(0.2657, grad_fn=<SumBackward0>)\n",
      "Epoch 119 loss is 0.26572471857070923\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4245, 0.7144, 0.7193, 0.6780, 0.6597, 0.6139, 0.6360, 0.7117, 0.6834,\n",
      "        0.6373, 0.7482], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4913,  0.4225, -0.0183, -0.0351, -0.0140,  0.0867,  0.1158,  0.0022,\n",
      "         0.0608,  0.1080], grad_fn=<AddBackward0>)\n",
      "tensor(1.2198, grad_fn=<SumBackward0>)\n",
      "Epoch 120 loss is 1.2198411226272583\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6742, 0.6615, 0.7024, 0.7665, 0.7445, 0.7466, 0.6547, 0.6496, 0.7214,\n",
      "        0.7010, 0.6452], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0470,  0.1539,  0.1383,  0.0737, -0.0373, -0.0316, -0.0084,  0.0772,\n",
      "        -0.0015, -0.0254], grad_fn=<AddBackward0>)\n",
      "tensor(0.3859, grad_fn=<SumBackward0>)\n",
      "Epoch 121 loss is 0.3858715891838074\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7405, 0.6516, 0.6314, 0.6545, 0.7059, 0.7314, 0.7355, 0.7239, 0.6966,\n",
      "        0.7403, 0.6756], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0364, -0.0287,  0.0904,  0.1668,  0.1350,  0.0300, -0.0116,  0.0080,\n",
      "        -0.0161, -0.0070], grad_fn=<AddBackward0>)\n",
      "tensor(0.3305, grad_fn=<SumBackward0>)\n",
      "Epoch 122 loss is 0.3304540514945984\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7473, 0.6454, 0.7043, 0.6972, 0.6776, 0.6836, 0.6935, 0.6948, 0.6412,\n",
      "        0.7063, 0.7215], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0144, -0.0167,  0.0537, -0.0069, -0.0012,  0.0288, -0.0141,  0.0213,\n",
      "         0.0444,  0.1338], grad_fn=<AddBackward0>)\n",
      "tensor(0.2286, grad_fn=<SumBackward0>)\n",
      "Epoch 123 loss is 0.22864794731140137\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7584, 0.6232, 0.7116, 0.7201, 0.7084, 0.6167, 0.6778, 0.6504, 0.7251,\n",
      "        0.7027, 0.6872], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0156, -0.0127,  0.1421, -0.0316, -0.0141, -0.0193,  0.1806,  0.0415,\n",
      "         0.0613, -0.0126], grad_fn=<AddBackward0>)\n",
      "tensor(0.3195, grad_fn=<SumBackward0>)\n",
      "Epoch 124 loss is 0.3195350766181946\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6090, 0.7632, 0.7086, 0.6616, 0.6823, 0.6760, 0.6147, 0.6616, 0.6756,\n",
      "        0.6478, 0.6635], grad_fn=<ViewBackward0>)\n",
      "tensor([ 1.6599e-01,  8.7662e-02, -2.6968e-02, -1.0858e-02, -1.5625e-02,\n",
      "        -6.8945e-03, -1.2958e-04,  5.5211e-02,  3.2875e-03, -4.0234e-03],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.2476, grad_fn=<SumBackward0>)\n",
      "Epoch 125 loss is 0.24764889478683472\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6158, 0.6392, 0.6947, 0.7726, 0.7216, 0.7466, 0.6851, 0.6878, 0.6668,\n",
      "        0.7256, 0.7250], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1314,  0.2613,  0.1374,  0.0866, -0.0292, -0.0113, -0.0266,  0.0674,\n",
      "         0.0620,  0.0971], grad_fn=<AddBackward0>)\n",
      "tensor(0.7762, grad_fn=<SumBackward0>)\n",
      "Epoch 126 loss is 0.7761540412902832\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6132, 0.7133, 0.7245, 0.6676, 0.7001, 0.6748, 0.6651, 0.7174, 0.6361,\n",
      "        0.6755, 0.6843], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1855,  0.0907, -0.0044, -0.0166, -0.0008,  0.0288, -0.0129,  0.0172,\n",
      "        -0.0110,  0.0804], grad_fn=<AddBackward0>)\n",
      "tensor(0.3568, grad_fn=<SumBackward0>)\n",
      "Epoch 127 loss is 0.3567515015602112\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6954, 0.7002, 0.6238, 0.7790, 0.6914, 0.6872, 0.6959, 0.6142, 0.6332,\n",
      "        0.7197, 0.6641], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0238,  0.1394, -0.0029,  0.1056, -0.0277, -0.0258, -0.0180,  0.0395,\n",
      "         0.0832,  0.0515], grad_fn=<AddBackward0>)\n",
      "tensor(0.3211, grad_fn=<SumBackward0>)\n",
      "Epoch 128 loss is 0.32112622261047363\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6515, 0.6664, 0.6063, 0.6290, 0.6267, 0.7046, 0.7400, 0.6588, 0.6832,\n",
      "        0.7281, 0.6445], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0150, -0.0075, -0.0132,  0.1637,  0.1849,  0.0534, -0.0071, -0.0040,\n",
      "        -0.0048, -0.0129], grad_fn=<AddBackward0>)\n",
      "tensor(0.3376, grad_fn=<SumBackward0>)\n",
      "Epoch 129 loss is 0.3375524878501892\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8837, 0.5293, 0.6130, 0.6302, 0.7399, 0.7356, 0.7641, 0.6672, 0.6228,\n",
      "        0.5938, 0.7760], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0902, -0.0845,  0.3510,  0.2043,  0.2232, -0.0242, -0.0376, -0.0568,\n",
      "         0.1813,  0.2553], grad_fn=<AddBackward0>)\n",
      "tensor(0.9218, grad_fn=<SumBackward0>)\n",
      "Epoch 130 loss is 0.9218155145645142\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7133, 0.8219, 0.6143, 0.6350, 0.7373, 0.7503, 0.6086, 0.7249, 0.5755,\n",
      "        0.7499, 0.6107], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0330, -0.0261, -0.0282,  0.2267, -0.0088, -0.0041, -0.0583,  0.2355,\n",
      "        -0.0380,  0.0588], grad_fn=<AddBackward0>)\n",
      "tensor(0.3244, grad_fn=<SumBackward0>)\n",
      "Epoch 131 loss is 0.3243783116340637\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7038, 0.7458, 0.7216, 0.7466, 0.8246, 0.6238, 0.6064, 0.8059, 0.6078,\n",
      "        0.8046, 0.7736], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0297,  0.0713,  0.1314, -0.0326, -0.0467, -0.0062, -0.0053,  0.3303,\n",
      "        -0.0108,  0.2763], grad_fn=<AddBackward0>)\n",
      "tensor(0.7374, grad_fn=<SumBackward0>)\n",
      "Epoch 132 loss is 0.7373642921447754\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6939, 0.7437, 0.6202, 0.7525, 0.6376, 0.6013, 0.6343, 0.6047, 0.5337,\n",
      "        0.6034, 0.7731], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0245,  0.0977, -0.0354, -0.0063, -0.0394, -0.0110, -0.0225, -0.0103,\n",
      "         0.2807,  0.3991], grad_fn=<AddBackward0>)\n",
      "tensor(0.6280, grad_fn=<SumBackward0>)\n",
      "Epoch 133 loss is 0.6279691457748413\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6608, 0.7488, 0.6148, 0.8110, 0.6061, 0.6174, 0.6058, 0.6230, 0.6068,\n",
      "        0.6241, 0.6237], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0153,  0.2503, -0.0476,  0.0042, -0.0684,  0.0283, -0.0035,  0.0305,\n",
      "         0.0010,  0.0282], grad_fn=<AddBackward0>)\n",
      "tensor(0.2076, grad_fn=<SumBackward0>)\n",
      "Epoch 134 loss is 0.20763349533081055\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6864, 0.7299, 0.6328, 0.7877, 0.6092, 0.5905, 0.6030, 0.5974, 0.5845,\n",
      "        0.7330, 0.7440], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0179,  0.1689, -0.0402, -0.0141, -0.0616, -0.0039, -0.0020,  0.2166,\n",
      "         0.2444,  0.2659], grad_fn=<AddBackward0>)\n",
      "tensor(0.7561, grad_fn=<SumBackward0>)\n",
      "Epoch 135 loss is 0.7561047077178955\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6508, 0.6329, 0.5993, 0.8223, 0.6297, 0.7065, 0.7646, 0.7158, 0.7568,\n",
      "        0.8162, 0.5906], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0172,  0.2859, -0.0011,  0.1787, -0.0192,  0.1435,  0.0838,  0.0859,\n",
      "        -0.0417, -0.0554], grad_fn=<AddBackward0>)\n",
      "tensor(0.6432, grad_fn=<SumBackward0>)\n",
      "Epoch 136 loss is 0.643203616142273\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6580, 0.6276, 0.7474, 0.6305, 0.7408, 0.6032, 0.5924, 0.5830, 0.7693,\n",
      "        0.5846, 0.6256], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1492, -0.0092,  0.1887, -0.0481, -0.0127, -0.0526,  0.2769, -0.0026,\n",
      "         0.0711, -0.0479], grad_fn=<AddBackward0>)\n",
      "tensor(0.5128, grad_fn=<SumBackward0>)\n",
      "Epoch 137 loss is 0.5127694010734558\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6589, 0.7054, 0.6061, 0.6039, 0.6543, 0.7700, 0.7821, 0.6247, 0.7455,\n",
      "        0.7869, 0.6223], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0176, -0.0183, -0.0170,  0.2732,  0.2970, -0.0099, -0.0082,  0.0080,\n",
      "        -0.0008, -0.0411], grad_fn=<AddBackward0>)\n",
      "tensor(0.4653, grad_fn=<SumBackward0>)\n",
      "Epoch 138 loss is 0.4653005003929138\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6186, 0.6118, 0.5880, 0.6284, 0.7629, 0.5887, 0.7816, 0.8001, 0.6101,\n",
      "        0.6197, 0.8217], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0102,  0.0163,  0.2519,  0.0011,  0.2553,  0.0620,  0.0356, -0.0540,\n",
      "         0.0360,  0.3527], grad_fn=<AddBackward0>)\n",
      "tensor(0.9469, grad_fn=<SumBackward0>)\n",
      "Epoch 139 loss is 0.9468639492988586\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8373, 0.8935, 0.8172, 0.7835, 0.8035, 0.6387, 0.6230, 0.7974, 0.6184,\n",
      "        0.6225, 0.6068], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0067, -0.0179, -0.0300, -0.0595, -0.0535, -0.0020, -0.0068, -0.0001,\n",
      "        -0.0635, -0.0039], grad_fn=<AddBackward0>)\n",
      "tensor(-0.2440, grad_fn=<SumBackward0>)\n",
      "Epoch 140 loss is -0.24404752254486084\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6892, 0.7081, 0.6214, 0.6197, 0.5918, 0.6640, 0.7396, 0.7368, 0.6045,\n",
      "        0.6298, 0.6545], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0226, -0.0232, -0.0388,  0.0709,  0.1997,  0.2417, -0.0198, -0.0366,\n",
      "        -0.0274,  0.0833], grad_fn=<AddBackward0>)\n",
      "tensor(0.4272, grad_fn=<SumBackward0>)\n",
      "Epoch 141 loss is 0.42722606658935547\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7677, 0.7117, 0.7432, 0.7420, 0.7836, 0.6417, 0.6324, 0.7131, 0.6490,\n",
      "        0.7156, 0.7737], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0082, -0.0086,  0.1197, -0.0338, -0.0365, -0.0235,  0.0122,  0.1386,\n",
      "         0.1009,  0.2078], grad_fn=<AddBackward0>)\n",
      "tensor(0.4686, grad_fn=<SumBackward0>)\n",
      "Epoch 142 loss is 0.46861952543258667\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6704, 0.7854, 0.7396, 0.6200, 0.7244, 0.7536, 0.8058, 0.6327, 0.5887,\n",
      "        0.6067, 0.7221], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1153, -0.0168, -0.0203,  0.0233,  0.3096, -0.0305, -0.0550, -0.0664,\n",
      "         0.1490,  0.2224], grad_fn=<AddBackward0>)\n",
      "tensor(0.6305, grad_fn=<SumBackward0>)\n",
      "Epoch 143 loss is 0.6305447220802307\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6750, 0.7388, 0.6314, 0.6055, 0.7158, 0.6475, 0.6284, 0.6699, 0.8010,\n",
      "        0.6479, 0.6620], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0146, -0.0232, -0.0076,  0.0270,  0.0382, -0.0153,  0.2558,  0.0325,\n",
      "        -0.0026, -0.0463], grad_fn=<AddBackward0>)\n",
      "tensor(0.2438, grad_fn=<SumBackward0>)\n",
      "Epoch 144 loss is 0.24384784698486328\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6409, 0.6927, 0.6941, 0.6220, 0.6324, 0.6294, 0.7672, 0.7499, 0.6061,\n",
      "        0.6237, 0.6590], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0887, -0.0063, -0.0201, -0.0216,  0.2420,  0.1959, -0.0078, -0.0478,\n",
      "        -0.0303,  0.0882], grad_fn=<AddBackward0>)\n",
      "tensor(0.4809, grad_fn=<SumBackward0>)\n",
      "Epoch 145 loss is 0.4809491038322449\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7201, 0.7712, 0.7028, 0.7485, 0.6312, 0.5927, 0.7894, 0.7397, 0.6453,\n",
      "        0.7655, 0.7801], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0058,  0.0473, -0.0467, -0.0367,  0.0681,  0.1808,  0.0876, -0.0080,\n",
      "         0.0673,  0.2246], grad_fn=<AddBackward0>)\n",
      "tensor(0.5787, grad_fn=<SumBackward0>)\n",
      "Epoch 146 loss is 0.57867431640625\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7074, 0.6688, 0.7503, 0.6551, 0.6490, 0.6390, 0.6538, 0.6432, 0.6982,\n",
      "        0.6399, 0.6837], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0715, -0.0174, -0.0066, -0.0371, -0.0004, -0.0019,  0.0988, -0.0046,\n",
      "         0.0676, -0.0048], grad_fn=<AddBackward0>)\n",
      "tensor(0.1649, grad_fn=<SumBackward0>)\n",
      "Epoch 147 loss is 0.16491669416427612\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6370, 0.6445, 0.7202, 0.7043, 0.6939, 0.7188, 0.6945, 0.6932, 0.6759,\n",
      "        0.6439, 0.6238], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1387,  0.1121,  0.0824, -0.0005, -0.0033, -0.0003, -0.0143, -0.0169,\n",
      "        -0.0231, -0.0173], grad_fn=<AddBackward0>)\n",
      "tensor(0.2576, grad_fn=<SumBackward0>)\n",
      "Epoch 148 loss is 0.25760018825531006\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6607, 0.6557, 0.6965, 0.6591, 0.6634, 0.7036, 0.6523, 0.6576, 0.7175,\n",
      "        0.7057, 0.6983], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0597, -0.0006,  0.0128,  0.0118, -0.0023, -0.0019,  0.0231,  0.0889,\n",
      "         0.0679, -0.0064], grad_fn=<AddBackward0>)\n",
      "tensor(0.2530, grad_fn=<SumBackward0>)\n",
      "Epoch 149 loss is 0.2530354857444763\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4486, 0.6174, 0.7495, 0.6849, 0.7200, 0.7108, 0.7311, 0.6790, 0.6632,\n",
      "        0.7168, 0.6500], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.5015,  0.3938,  0.1711, -0.0129,  0.0771, -0.0137, -0.0159, -0.0048,\n",
      "        -0.0096, -0.0044], grad_fn=<AddBackward0>)\n",
      "tensor(1.0823, grad_fn=<SumBackward0>)\n",
      "Epoch 150 loss is 1.0823134183883667\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6351, 0.6257, 0.6833, 0.5798, 0.7360, 0.6703, 0.7311, 0.7552, 0.7330,\n",
      "        0.6615, 0.6777], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0803, -0.0184,  0.1837, -0.0043,  0.2522,  0.0321,  0.1046, -0.0232,\n",
      "        -0.0258, -0.0184], grad_fn=<AddBackward0>)\n",
      "tensor(0.5626, grad_fn=<SumBackward0>)\n",
      "Epoch 151 loss is 0.5626357793807983\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7610, 0.6620, 0.6978, 0.7173, 0.6788, 0.7073, 0.6709, 0.7204, 0.7148,\n",
      "        0.7286, 0.6654], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0211, -0.0146,  0.0279,  0.0158, -0.0154,  0.0694,  0.0125,  0.0961,\n",
      "        -0.0184, -0.0165], grad_fn=<AddBackward0>)\n",
      "tensor(0.1358, grad_fn=<SumBackward0>)\n",
      "Epoch 152 loss is 0.13581013679504395\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6328, 0.7384, 0.6606, 0.6783, 0.6858, 0.7195, 0.6686, 0.7107, 0.6757,\n",
      "        0.7126, 0.6536], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0463,  0.0758, -0.0175,  0.0982, -0.0032,  0.0415, -0.0146,  0.0733,\n",
      "        -0.0190, -0.0074], grad_fn=<AddBackward0>)\n",
      "tensor(0.2733, grad_fn=<SumBackward0>)\n",
      "Epoch 153 loss is 0.27329021692276\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6251, 0.6011, 0.7335, 0.7338, 0.6217, 0.7238, 0.7300, 0.7542, 0.6813,\n",
      "        0.7416, 0.7878], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1808,  0.1812,  0.0342, -0.0032, -0.0013,  0.2209, -0.0142,  0.0192,\n",
      "         0.0561,  0.1775], grad_fn=<AddBackward0>)\n",
      "tensor(0.8512, grad_fn=<SumBackward0>)\n",
      "Epoch 154 loss is 0.8512144088745117\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5923, 0.7607, 0.6438, 0.6082, 0.7120, 0.6480, 0.7316, 0.7367, 0.7053,\n",
      "        0.6951, 0.7450], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0857,  0.0264, -0.0162,  0.0070,  0.2056,  0.0411,  0.0956, -0.0122,\n",
      "         0.0138,  0.0661], grad_fn=<AddBackward0>)\n",
      "tensor(0.5130, grad_fn=<SumBackward0>)\n",
      "Epoch 155 loss is 0.5130374431610107\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6136, 0.6361, 0.6943, 0.6822, 0.6659, 0.7139, 0.6642, 0.7018, 0.7059,\n",
      "        0.7293, 0.7097], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1345,  0.1144,  0.0496,  0.0326, -0.0060,  0.0599, -0.0026,  0.1086,\n",
      "         0.0132,  0.0063], grad_fn=<AddBackward0>)\n",
      "tensor(0.5104, grad_fn=<SumBackward0>)\n",
      "Epoch 156 loss is 0.5104402303695679\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7351, 0.6117, 0.6735, 0.6853, 0.7290, 0.6829, 0.6764, 0.7293, 0.6942,\n",
      "        0.6683, 0.6739], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0205, -0.0166,  0.1954,  0.0157, -0.0030,  0.0006,  0.0188, -0.0027,\n",
      "        -0.0185, -0.0068], grad_fn=<AddBackward0>)\n",
      "tensor(0.1625, grad_fn=<SumBackward0>)\n",
      "Epoch 157 loss is 0.1625109314918518\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6479, 0.6133, 0.7097, 0.6714, 0.7224, 0.7035, 0.7023, 0.7086, 0.6993,\n",
      "        0.7197, 0.7230], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1029,  0.0391,  0.1819, -0.0021,  0.0514, -0.0046, -0.0014,  0.0290,\n",
      "         0.0240,  0.0396], grad_fn=<AddBackward0>)\n",
      "tensor(0.4599, grad_fn=<SumBackward0>)\n",
      "Epoch 158 loss is 0.45993131399154663\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6641, 0.6699, 0.6567, 0.6665, 0.6660, 0.7006, 0.6970, 0.6942, 0.7111,\n",
      "        0.6875, 0.6863], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0025,  0.0040, -0.0013,  0.0732,  0.0507,  0.0470,  0.0174, -0.0031,\n",
      "        -0.0026, -0.0082], grad_fn=<AddBackward0>)\n",
      "tensor(0.1746, grad_fn=<SumBackward0>)\n",
      "Epoch 159 loss is 0.17462807893753052\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9942, 0.5672, 0.7786, 0.6862, 0.6783, 0.6824, 0.6943, 0.6485, 0.6707,\n",
      "        0.6674, 0.6969], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0718, -0.1027,  0.1852, -0.0321,  0.0136, -0.0099, -0.0039, -0.0090,\n",
      "         0.0807,  0.0438], grad_fn=<AddBackward0>)\n",
      "tensor(0.0938, grad_fn=<SumBackward0>)\n",
      "Epoch 160 loss is 0.09382718801498413\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7433, 0.6349, 0.7224, 0.6750, 0.6767, 0.6934, 0.6641, 0.7066, 0.6501,\n",
      "        0.6886, 0.6826], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0070, -0.0228,  0.0696, -0.0097, -0.0036,  0.0499, -0.0144,  0.0407,\n",
      "        -0.0080,  0.0541], grad_fn=<AddBackward0>)\n",
      "tensor(0.1488, grad_fn=<SumBackward0>)\n",
      "Epoch 161 loss is 0.1487833857536316\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7147, 0.6845, 0.7008, 0.6860, 0.6923, 0.6396, 0.6913, 0.5887, 0.7066,\n",
      "        0.7086, 0.6181], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0046, -0.0096,  0.0130, -0.0204,  0.0088, -0.0345,  0.1117,  0.0288,\n",
      "         0.0491, -0.0295], grad_fn=<AddBackward0>)\n",
      "tensor(0.1127, grad_fn=<SumBackward0>)\n",
      "Epoch 162 loss is 0.1127362847328186\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7424, 0.6575, 0.7375, 0.7608, 0.6332, 0.6313, 0.6344, 0.6081, 0.6635,\n",
      "        0.7069, 0.6401], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0016,  0.0307, -0.0081, -0.0354, -0.0421, -0.0084,  0.0537,  0.1208,\n",
      "         0.0533, -0.0078], grad_fn=<AddBackward0>)\n",
      "tensor(0.1550, grad_fn=<SumBackward0>)\n",
      "Epoch 163 loss is 0.15503638982772827\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6880, 0.7731, 0.7065, 0.6369, 0.7284, 0.7184, 0.6478, 0.6411, 0.6397,\n",
      "        0.6578, 0.6353], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0309, -0.0170, -0.0149,  0.0198,  0.0182, -0.0291, -0.0262,  0.0166,\n",
      "        -0.0019, -0.0014], grad_fn=<AddBackward0>)\n",
      "tensor(-0.0052, grad_fn=<SumBackward0>)\n",
      "Epoch 164 loss is -0.005164623260498047\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6671, 0.6806, 0.7576, 0.6724, 0.7106, 0.7401, 0.7611, 0.7496, 0.7354,\n",
      "        0.6124, 0.6231], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1508,  0.0087,  0.0499, -0.0058,  0.1478,  0.0651, -0.0016, -0.0495,\n",
      "        -0.0422, -0.0374], grad_fn=<AddBackward0>)\n",
      "tensor(0.2858, grad_fn=<SumBackward0>)\n",
      "Epoch 165 loss is 0.28581953048706055\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6881, 0.6795, 0.8108, 0.7000, 0.7586, 0.7995, 0.7373, 0.6260, 0.6615,\n",
      "        0.7680, 0.8015], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2046,  0.0200,  0.1318, -0.0038,  0.0621, -0.0442, -0.0460,  0.0511,\n",
      "         0.2926,  0.2334], grad_fn=<AddBackward0>)\n",
      "tensor(0.9016, grad_fn=<SumBackward0>)\n",
      "Epoch 166 loss is 0.901616096496582\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6812, 0.6504, 0.7443, 0.7548, 0.7068, 0.7029, 0.7910, 0.6141, 0.7659,\n",
      "        0.7465, 0.6887], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1051,  0.1226,  0.0939, -0.0138,  0.0603, -0.0309,  0.1050, -0.0148,\n",
      "         0.1243, -0.0257], grad_fn=<AddBackward0>)\n",
      "tensor(0.5261, grad_fn=<SumBackward0>)\n",
      "Epoch 167 loss is 0.5261245369911194\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6380, 0.7367, 0.6696, 0.7369, 0.6713, 0.6470, 0.7351, 0.6744, 0.6620,\n",
      "        0.6631, 0.7055], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0527,  0.1648, -0.0218, -0.0075, -0.0006,  0.0053,  0.0250, -0.0240,\n",
      "         0.0518,  0.0726], grad_fn=<AddBackward0>)\n",
      "tensor(0.3183, grad_fn=<SumBackward0>)\n",
      "Epoch 168 loss is 0.3183355927467346\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7556, 0.6926, 0.6409, 0.7001, 0.7427, 0.7100, 0.6641, 0.7392, 0.7394,\n",
      "        0.6643, 0.6856], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0382, -0.0185,  0.0836,  0.1151, -0.0120, -0.0012,  0.0489,  0.0004,\n",
      "        -0.0179, -0.0179], grad_fn=<AddBackward0>)\n",
      "tensor(0.1423, grad_fn=<SumBackward0>)\n",
      "Epoch 169 loss is 0.14227813482284546\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4243, 0.7290, 0.6930, 0.7135, 0.6338, 0.6354, 0.7764, 0.6854, 0.7726,\n",
      "        0.6856, 0.7240], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4478,  0.4820, -0.0317, -0.0192,  0.1049,  0.0860,  0.2288, -0.0303,\n",
      "         0.0644, -0.0162], grad_fn=<AddBackward0>)\n",
      "tensor(1.3164, grad_fn=<SumBackward0>)\n",
      "Epoch 170 loss is 1.3164061307907104\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6200, 0.6168, 0.7575, 0.6940, 0.6635, 0.5723, 0.5982, 0.6853, 0.6931,\n",
      "        0.6382, 0.7981], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2291,  0.1233,  0.0778, -0.0617, -0.0319,  0.0364,  0.2013,  0.0668,\n",
      "         0.1880,  0.1750], grad_fn=<AddBackward0>)\n",
      "tensor(1.0041, grad_fn=<SumBackward0>)\n",
      "Epoch 171 loss is 1.0041029453277588\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8451, 0.7790, 0.6443, 0.7629, 0.7684, 0.6290, 0.6012, 0.7667, 0.5865,\n",
      "        0.6615, 0.6458], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0669, -0.0274, -0.0035, -0.0051, -0.0539, -0.0006, -0.0142,  0.1005,\n",
      "        -0.0403,  0.0989], grad_fn=<AddBackward0>)\n",
      "tensor(-0.0124, grad_fn=<SumBackward0>)\n",
      "Epoch 172 loss is -0.012425661087036133\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8357, 0.5912, 0.8146, 0.8213, 0.5988, 0.7726, 0.8046, 0.5751, 0.7651,\n",
      "        0.5689, 0.6351], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0070, -0.0048,  0.0126, -0.0140, -0.0055, -0.0079, -0.0025, -0.0786,\n",
      "         0.1001, -0.0433], grad_fn=<AddBackward0>)\n",
      "tensor(-0.0510, grad_fn=<SumBackward0>)\n",
      "Epoch 173 loss is -0.05103015899658203\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8279, 0.6018, 0.5765, 0.7634, 0.5969, 0.8121, 0.8078, 0.5477, 0.9100,\n",
      "        0.5915, 0.6128], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0838, -0.0215, -0.0016,  0.3926,  0.0740, -0.0164,  0.1631, -0.0721,\n",
      "         0.1084, -0.0991], grad_fn=<AddBackward0>)\n",
      "tensor(0.4437, grad_fn=<SumBackward0>)\n",
      "Epoch 174 loss is 0.4436691999435425\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5453, 0.8138, 0.5825, 0.5403, 0.8476, 0.8082, 0.7827, 0.6206, 0.8182,\n",
      "        0.5610, 0.8378], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0620, -0.0017,  0.0564,  0.3762,  0.4040, -0.0757,  0.0167, -0.0739,\n",
      "         0.3620,  0.0326], grad_fn=<AddBackward0>)\n",
      "tensor(1.1587, grad_fn=<SumBackward0>)\n",
      "Epoch 175 loss is 1.1586800813674927\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5226, 0.8322, 0.8371, 0.8629, 0.5546, 0.5664, 0.5864, 0.5701, 0.8519,\n",
      "        0.5615, 0.5707], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.5241,  0.5671, -0.0926, -0.0902, -0.0922,  0.0258,  0.4757, -0.0083,\n",
      "         0.0010, -0.0937], grad_fn=<AddBackward0>)\n",
      "tensor(1.2169, grad_fn=<SumBackward0>)\n",
      "Epoch 176 loss is 1.2168524265289307\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8492, 0.8734, 0.7875, 0.7648, 0.5809, 0.8534, 0.5690, 0.5491, 0.9041,\n",
      "        0.8563, 0.8270], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0206, -0.0282, -0.0975,  0.1098, -0.0653, -0.0106,  0.0845,  0.4789,\n",
      "         0.4633, -0.0257], grad_fn=<AddBackward0>)\n",
      "tensor(0.8887, grad_fn=<SumBackward0>)\n",
      "Epoch 177 loss is 0.8886938095092773\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8419, 0.5701, 0.5679, 0.8449, 0.5911, 0.8405, 0.8435, 0.7884, 0.8200,\n",
      "        0.8327, 0.5666], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0913,  0.0051,  0.0351,  0.4545, -0.0005,  0.3289, -0.0069, -0.0036,\n",
      "        -0.0739, -0.0844], grad_fn=<AddBackward0>)\n",
      "tensor(0.5629, grad_fn=<SumBackward0>)\n",
      "Epoch 178 loss is 0.5628665685653687\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8847, 0.5463, 0.5066, 0.5344, 0.5809, 0.5502, 0.8335, 0.5755, 0.5516,\n",
      "        0.8269, 0.5453], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1261, -0.1168,  0.0577,  0.0727,  0.4986, -0.0018,  0.0024, -0.0022,\n",
      "        -0.0101, -0.0021], grad_fn=<AddBackward0>)\n",
      "tensor(0.3723, grad_fn=<SumBackward0>)\n",
      "Epoch 179 loss is 0.3722918629646301\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.1688, 0.6600, 0.6101, 0.5474, 0.8303, 0.8236, 0.7946, 0.8051, 0.8213,\n",
      "        0.8236, 0.5496], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1862, -0.2071,  0.2838,  0.3559,  0.4120, -0.0084, -0.0008,  0.0482,\n",
      "        -0.0852, -0.0906], grad_fn=<AddBackward0>)\n",
      "tensor(0.5216, grad_fn=<SumBackward0>)\n",
      "Epoch 180 loss is 0.5216304659843445\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8217, 0.5498, 0.8070, 0.7555, 0.8263, 0.5949, 0.8017, 0.5900, 0.5779,\n",
      "        0.6292, 0.6061], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0049, -0.0221,  0.4608, -0.0707,  0.0770, -0.0788, -0.0057, -0.0575,\n",
      "         0.0269,  0.0470], grad_fn=<AddBackward0>)\n",
      "tensor(0.3720, grad_fn=<SumBackward0>)\n",
      "Epoch 181 loss is 0.3720458149909973\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8333, 0.8437, 0.5331, 0.5454, 0.5336, 0.8372, 0.7949, 0.5812, 0.8622,\n",
      "        0.5659, 0.7965], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1001, -0.0960, -0.1034,  0.5069,  0.4158,  0.0794,  0.0416, -0.0763,\n",
      "         0.3589, -0.0219], grad_fn=<AddBackward0>)\n",
      "tensor(1.0050, grad_fn=<SumBackward0>)\n",
      "Epoch 182 loss is 1.0049840211868286\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8337, 0.5455, 0.5815, 0.5899, 0.5765, 0.6146, 0.6278, 0.6286, 0.7866,\n",
      "        0.7707, 0.7997], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0841, -0.0813,  0.0518,  0.0552,  0.0632,  0.0868,  0.2868,  0.2382,\n",
      "         0.2852,  0.0218], grad_fn=<AddBackward0>)\n",
      "tensor(0.9236, grad_fn=<SumBackward0>)\n",
      "Epoch 183 loss is 0.9235690236091614\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8079, 0.7800, 0.7949, 0.5983, 0.7471, 0.6322, 0.6061, 0.7636, 0.6055,\n",
      "        0.8039, 0.6569], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0043, -0.0699, -0.0110, -0.0543,  0.0131,  0.0276, -0.0089,  0.3297,\n",
      "        -0.0356,  0.0856], grad_fn=<AddBackward0>)\n",
      "tensor(0.2721, grad_fn=<SumBackward0>)\n",
      "Epoch 184 loss is 0.27208876609802246\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5615, 0.7998, 0.7712, 0.7435, 0.6458, 0.7324, 0.7384, 0.6342, 0.6409,\n",
      "        0.7552, 0.7702], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.3495,  0.3033, -0.0513, -0.0129, -0.0017, -0.0039, -0.0305,  0.0280,\n",
      "         0.2267,  0.2154], grad_fn=<AddBackward0>)\n",
      "tensor(1.0225, grad_fn=<SumBackward0>)\n",
      "Epoch 185 loss is 1.0225250720977783\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5810, 0.7423, 0.7889, 0.6137, 0.7096, 0.6490, 0.7323, 0.7831, 0.7788,\n",
      "        0.8004, 0.6281], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.3464,  0.0545, -0.0109, -0.0466,  0.1976,  0.1225,  0.2163,  0.1134,\n",
      "        -0.0517, -0.0502], grad_fn=<AddBackward0>)\n",
      "tensor(0.8914, grad_fn=<SumBackward0>)\n",
      "Epoch 186 loss is 0.8913561105728149\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7481, 0.6678, 0.7131, 0.7157, 0.6615, 0.6714, 0.6328, 0.7092, 0.6388,\n",
      "        0.7798, 0.6130], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0117, -0.0108, -0.0021, -0.0139, -0.0277,  0.0796, -0.0109,  0.2451,\n",
      "        -0.0321, -0.0086], grad_fn=<AddBackward0>)\n",
      "tensor(0.2070, grad_fn=<SumBackward0>)\n",
      "Epoch 187 loss is 0.20701885223388672\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7805, 0.7120, 0.7384, 0.7674, 0.6650, 0.7324, 0.6884, 0.7227, 0.7616,\n",
      "        0.7353, 0.7014], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0140, -0.0044, -0.0157, -0.0020, -0.0263,  0.0961,  0.0487,  0.0782,\n",
      "        -0.0071, -0.0201], grad_fn=<AddBackward0>)\n",
      "tensor(0.1334, grad_fn=<SumBackward0>)\n",
      "Epoch 188 loss is 0.13337552547454834\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6253, 0.6519, 0.6744, 0.6844, 0.6628, 0.6516, 0.6670, 0.6486, 0.6611,\n",
      "        0.6989, 0.6596], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0819,  0.0985,  0.0181, -0.0076, -0.0058, -0.0048,  0.0158,  0.0532,\n",
      "         0.0184, -0.0005], grad_fn=<AddBackward0>)\n",
      "tensor(0.2673, grad_fn=<SumBackward0>)\n",
      "Epoch 189 loss is 0.2672739028930664\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9602, 0.8216, 0.7356, 0.6715, 0.6404, 0.7320, 0.6531, 0.6664, 0.7425,\n",
      "        0.7185, 0.6725], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0749, -0.0962, -0.0604, -0.0012, -0.0061,  0.0433,  0.0175,  0.1090,\n",
      "         0.0102, -0.0233], grad_fn=<AddBackward0>)\n",
      "tensor(-0.0822, grad_fn=<SumBackward0>)\n",
      "Epoch 190 loss is -0.08215939998626709\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6398, 0.6826, 0.6862, 0.6941, 0.7020, 0.6854, 0.7939, 0.7135, 0.7620,\n",
      "        0.6401, 0.6958], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0773,  0.0905,  0.0323, -0.0003,  0.1664,  0.0192,  0.1277, -0.0513,\n",
      "        -0.0059, -0.0221], grad_fn=<AddBackward0>)\n",
      "tensor(0.4339, grad_fn=<SumBackward0>)\n",
      "Epoch 191 loss is 0.4338616132736206\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6181, 0.6568, 0.6382, 0.6957, 0.6207, 0.7769, 0.6518, 0.7370, 0.6305,\n",
      "        0.7121, 0.6168], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0336,  0.1294, -0.0120,  0.2311, -0.0146,  0.1939, -0.0488,  0.1004,\n",
      "        -0.0401, -0.0046], grad_fn=<AddBackward0>)\n",
      "tensor(0.5684, grad_fn=<SumBackward0>)\n",
      "Epoch 192 loss is 0.56839519739151\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7123, 0.6896, 0.6664, 0.7429, 0.6870, 0.7429, 0.6942, 0.6586, 0.6695,\n",
      "        0.6527, 0.7294], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0153,  0.0510, -0.0009,  0.1275, -0.0162, -0.0095, -0.0245, -0.0138,\n",
      "         0.1181,  0.0999], grad_fn=<AddBackward0>)\n",
      "tensor(0.3163, grad_fn=<SumBackward0>)\n",
      "Epoch 193 loss is 0.31631535291671753\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6863, 0.6717, 0.6191, 0.7237, 0.7403, 0.7134, 0.7086, 0.6936, 0.7144,\n",
      "        0.6693, 0.6337], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0224,  0.0623,  0.1145,  0.1573, -0.0050, -0.0156,  0.0016, -0.0131,\n",
      "        -0.0199, -0.0269], grad_fn=<AddBackward0>)\n",
      "tensor(0.2327, grad_fn=<SumBackward0>)\n",
      "Epoch 194 loss is 0.23267507553100586\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6721, 0.6790, 0.6716, 0.6498, 0.6745, 0.6893, 0.6277, 0.7119, 0.7229,\n",
      "        0.6949, 0.6309], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0002, -0.0074, -0.0015,  0.0295, -0.0074,  0.0623,  0.0560,  0.1120,\n",
      "        -0.0270, -0.0307], grad_fn=<AddBackward0>)\n",
      "tensor(0.1857, grad_fn=<SumBackward0>)\n",
      "Epoch 195 loss is 0.18569576740264893\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6845, 0.7317, 0.6416, 0.7354, 0.6500, 0.7346, 0.6004, 0.6138, 0.6428,\n",
      "        0.7021, 0.6256], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0143,  0.0848, -0.0272,  0.1550, -0.0450, -0.0121, -0.0306,  0.1695,\n",
      "         0.0198, -0.0057], grad_fn=<AddBackward0>)\n",
      "tensor(0.2941, grad_fn=<SumBackward0>)\n",
      "Epoch 196 loss is 0.2941190004348755\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6780, 0.6695, 0.6677, 0.6567, 0.7418, 0.6795, 0.6978, 0.6916, 0.6708,\n",
      "        0.7370, 0.7067], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0035, -0.0071,  0.1205,  0.0198,  0.0685, -0.0168, -0.0029,  0.0653,\n",
      "         0.0252,  0.0598], grad_fn=<AddBackward0>)\n",
      "tensor(0.3289, grad_fn=<SumBackward0>)\n",
      "Epoch 197 loss is 0.3288968801498413\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7438, 0.7280, 0.7590, 0.6635, 0.7503, 0.7012, 0.7355, 0.6945, 0.6837,\n",
      "        0.6913, 0.7611], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0254, -0.0267,  0.0371, -0.0192,  0.1200, -0.0186, -0.0059, -0.0147,\n",
      "         0.1110,  0.1291], grad_fn=<AddBackward0>)\n",
      "tensor(0.3374, grad_fn=<SumBackward0>)\n",
      "Epoch 198 loss is 0.3373578190803528\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7168, 0.7202, 0.6743, 0.6806, 0.7281, 0.6744, 0.7056, 0.6416, 0.6121,\n",
      "        0.7229, 0.7005], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0142, -0.0121,  0.0132,  0.0002,  0.0416, -0.0288, -0.0208,  0.0289,\n",
      "         0.0982,  0.1474], grad_fn=<AddBackward0>)\n",
      "tensor(0.2537, grad_fn=<SumBackward0>)\n",
      "Epoch 199 loss is 0.25374484062194824\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9796, 0.7845, 0.7627, 0.7098, 0.6508, 0.6603, 0.7070, 0.7556, 0.6805,\n",
      "        0.6737, 0.6710], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0723, -0.0899, -0.0446, -0.0341, -0.0009,  0.1746,  0.0336, -0.0111,\n",
      "        -0.0282, -0.0032], grad_fn=<AddBackward0>)\n",
      "tensor(-0.0761, grad_fn=<SumBackward0>)\n",
      "Epoch 200 loss is -0.07605314254760742\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6912, 0.7366, 0.6698, 0.6722, 0.6814, 0.6757, 0.7291, 0.7293, 0.6759,\n",
      "        0.6542, 0.6185], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0071, -0.0063, -0.0184,  0.0098,  0.0949,  0.0798,  0.0003, -0.0250,\n",
      "        -0.0369, -0.0192], grad_fn=<AddBackward0>)\n",
      "tensor(0.0718, grad_fn=<SumBackward0>)\n",
      "Epoch 201 loss is 0.07182222604751587\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7655, 0.7805, 0.6652, 0.7370, 0.7162, 0.7454, 0.5977, 0.6267, 0.7285,\n",
      "        0.7143, 0.6534], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0334, -0.0095, -0.0214,  0.1337, -0.0464, -0.0298, -0.0056,  0.1944,\n",
      "         0.0445, -0.0250], grad_fn=<AddBackward0>)\n",
      "tensor(0.2013, grad_fn=<SumBackward0>)\n",
      "Epoch 202 loss is 0.20133715867996216\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6281, 0.7458, 0.7019, 0.6451, 0.7354, 0.6770, 0.6874, 0.6924, 0.7047,\n",
      "        0.7374, 0.6135], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1229,  0.0284, -0.0035, -0.0083,  0.0705, -0.0143,  0.0462,  0.0833,\n",
      "        -0.0263, -0.0304], grad_fn=<AddBackward0>)\n",
      "tensor(0.2685, grad_fn=<SumBackward0>)\n",
      "Epoch 203 loss is 0.26853638887405396\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6467, 0.6575, 0.7005, 0.7242, 0.6653, 0.6338, 0.6981, 0.6743, 0.7298,\n",
      "        0.6456, 0.6597], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0897,  0.1292,  0.0131, -0.0223, -0.0087,  0.0150,  0.1600, -0.0175,\n",
      "        -0.0049, -0.0233], grad_fn=<AddBackward0>)\n",
      "tensor(0.3303, grad_fn=<SumBackward0>)\n",
      "Epoch 204 loss is 0.33032017946243286\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6421, 0.7350, 0.7461, 0.6438, 0.5890, 0.6730, 0.7249, 0.7599, 0.7521,\n",
      "        0.7758, 0.5950], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1734,  0.0030, -0.0487, -0.0244,  0.1350,  0.2848,  0.1319,  0.0850,\n",
      "        -0.0550, -0.0524], grad_fn=<AddBackward0>)\n",
      "tensor(0.6326, grad_fn=<SumBackward0>)\n",
      "Epoch 205 loss is 0.6326133012771606\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7562, 0.6246, 0.6104, 0.7369, 0.6885, 0.6463, 0.7217, 0.6431, 0.6688,\n",
      "        0.6460, 0.6426], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0486, -0.0064,  0.1066,  0.0598, -0.0051, -0.0152,  0.0375, -0.0252,\n",
      "        -0.0002, -0.0087], grad_fn=<AddBackward0>)\n",
      "tensor(0.0946, grad_fn=<SumBackward0>)\n",
      "Epoch 206 loss is 0.09457123279571533\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6391, 0.7283, 0.7245, 0.7192, 0.6849, 0.7266, 0.6942, 0.6355, 0.7244,\n",
      "        0.7272, 0.6384], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1423,  0.1334, -0.0145,  0.0035, -0.0083, -0.0165, -0.0007,  0.0550,\n",
      "         0.0049, -0.0287], grad_fn=<AddBackward0>)\n",
      "tensor(0.2705, grad_fn=<SumBackward0>)\n",
      "Epoch 207 loss is 0.2705215811729431\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6430, 0.6658, 0.7222, 0.7541, 0.7095, 0.6890, 0.6640, 0.6665, 0.6735,\n",
      "        0.6729, 0.7186], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1319,  0.1851,  0.0728, -0.0111, -0.0300, -0.0143, -0.0052,  0.0147,\n",
      "         0.0869,  0.0752], grad_fn=<AddBackward0>)\n",
      "tensor(0.5060, grad_fn=<SumBackward0>)\n",
      "Epoch 208 loss is 0.5060471296310425\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7888, 0.6636, 0.7103, 0.6933, 0.6674, 0.6932, 0.6551, 0.7225, 0.6941,\n",
      "        0.7006, 0.7018], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0262, -0.0318,  0.0063, -0.0057, -0.0128,  0.0918,  0.0015,  0.0759,\n",
      "        -0.0069,  0.0128], grad_fn=<AddBackward0>)\n",
      "tensor(0.1050, grad_fn=<SumBackward0>)\n",
      "Epoch 209 loss is 0.10496920347213745\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4586, 0.5658, 0.7297, 0.6840, 0.6984, 0.6871, 0.6833, 0.7110, 0.7132,\n",
      "        0.6528, 0.6640], grad_fn=<ViewBackward0>)\n",
      "tensor([ 4.5186e-01,  3.7559e-01,  2.2101e-01, -1.4224e-02, -2.1660e-04,\n",
      "         2.0908e-02,  4.3547e-02, -1.0167e-02, -1.5659e-02, -1.6394e-02],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(1.0563, grad_fn=<SumBackward0>)\n",
      "Epoch 210 loss is 1.0562517642974854\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6160, 0.7394, 0.7394, 0.6757, 0.6702, 0.6920, 0.6319, 0.6399, 0.7032,\n",
      "        0.6887, 0.7038], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2057,  0.0994, -0.0231, -0.0158, -0.0146, -0.0101,  0.0187,  0.0947,\n",
      "         0.1064,  0.0009], grad_fn=<AddBackward0>)\n",
      "tensor(0.4623, grad_fn=<SumBackward0>)\n",
      "Epoch 211 loss is 0.4622708559036255\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6454, 0.7019, 0.7372, 0.7864, 0.7771, 0.6425, 0.7542, 0.7226, 0.6509,\n",
      "        0.7465, 0.6056], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1531,  0.2350,  0.1254, -0.0316, -0.0107, -0.0182,  0.0140, -0.0026,\n",
      "        -0.0390, -0.0151], grad_fn=<AddBackward0>)\n",
      "tensor(0.4103, grad_fn=<SumBackward0>)\n",
      "Epoch 212 loss is 0.41034823656082153\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7160, 0.7237, 0.7304, 0.7225, 0.7046, 0.6662, 0.6666, 0.6685, 0.6507,\n",
      "        0.7099, 0.7286], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0241,  0.0108, -0.0064, -0.0214, -0.0186, -0.0120, -0.0052,  0.0722,\n",
      "         0.1001,  0.1298], grad_fn=<AddBackward0>)\n",
      "tensor(0.2734, grad_fn=<SumBackward0>)\n",
      "Epoch 213 loss is 0.27339309453964233\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6709, 0.6900, 0.6839, 0.6674, 0.6679, 0.7155, 0.7013, 0.6795, 0.6684,\n",
      "        0.6948, 0.7111], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0217, -0.0012, -0.0074,  0.0527,  0.0565,  0.0193, -0.0157, -0.0022,\n",
      "         0.0526,  0.0711], grad_fn=<AddBackward0>)\n",
      "tensor(0.2475, grad_fn=<SumBackward0>)\n",
      "Epoch 214 loss is 0.24749523401260376\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7567, 0.5991, 0.6262, 0.6678, 0.6869, 0.6729, 0.6961, 0.6516, 0.6638,\n",
      "        0.7230, 0.7171], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0435, -0.0296,  0.1464,  0.0778,  0.0471, -0.0118, -0.0030,  0.0448,\n",
      "         0.1092,  0.0888], grad_fn=<AddBackward0>)\n",
      "tensor(0.4261, grad_fn=<SumBackward0>)\n",
      "Epoch 215 loss is 0.4260951280593872\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7737, 0.7095, 0.6952, 0.7182, 0.6948, 0.6848, 0.7192, 0.6569, 0.7120,\n",
      "        0.6685, 0.6996], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0262, -0.0185, -0.0049, -0.0035,  0.0017, -0.0126,  0.0453, -0.0169,\n",
      "         0.0711, -0.0041], grad_fn=<AddBackward0>)\n",
      "tensor(0.0315, grad_fn=<SumBackward0>)\n",
      "Epoch 216 loss is 0.031459271907806396\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6462, 0.7063, 0.6916, 0.7292, 0.7348, 0.7157, 0.6622, 0.6301, 0.6114,\n",
      "        0.6708, 0.7281], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0756,  0.1384,  0.0474,  0.0403, -0.0223, -0.0349, -0.0348,  0.0144,\n",
      "         0.1633,  0.1946], grad_fn=<AddBackward0>)\n",
      "tensor(0.5818, grad_fn=<SumBackward0>)\n",
      "Epoch 217 loss is 0.5818224549293518\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5496, 0.6308, 0.6634, 0.7729, 0.6087, 0.6114, 0.7328, 0.7363, 0.7124,\n",
      "        0.6014, 0.7960], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1898,  0.3723, -0.0074, -0.0173, -0.0134,  0.2128,  0.1683, -0.0438,\n",
      "         0.0995,  0.1393], grad_fn=<AddBackward0>)\n",
      "tensor(1.1001, grad_fn=<SumBackward0>)\n",
      "Epoch 218 loss is 1.1000772714614868\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7761, 0.5936, 0.5890, 0.7711, 0.7666, 0.7462, 0.6248, 0.6745, 0.6701,\n",
      "        0.6153, 0.7657], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0624, -0.0017,  0.2883,  0.2620, -0.0488, -0.0307, -0.0254, -0.0031,\n",
      "         0.1521,  0.1593], grad_fn=<AddBackward0>)\n",
      "tensor(0.6897, grad_fn=<SumBackward0>)\n",
      "Epoch 219 loss is 0.689713716506958\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.1125, 0.6656, 0.7085, 0.6550, 0.6902, 0.6472, 0.6316, 0.7603, 0.6034,\n",
      "        0.7477, 0.7431], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1347, -0.1525,  0.0410, -0.0204, -0.0078,  0.1168, -0.0146,  0.1935,\n",
      "        -0.0057,  0.2327], grad_fn=<AddBackward0>)\n",
      "tensor(0.2483, grad_fn=<SumBackward0>)\n",
      "Epoch 220 loss is 0.24833279848098755\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6136, 0.7650, 0.7917, 0.6263, 0.7990, 0.7961, 0.6370, 0.7358, 0.6645,\n",
      "        0.6527, 0.6778], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2968,  0.0212,  0.0566,  0.0074,  0.0178, -0.0211, -0.0439,  0.0262,\n",
      "        -0.0193,  0.0221], grad_fn=<AddBackward0>)\n",
      "tensor(0.3639, grad_fn=<SumBackward0>)\n",
      "Epoch 221 loss is 0.36392396688461304\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7911, 0.5864, 0.7713, 0.6039, 0.6177, 0.6895, 0.6800, 0.5579, 0.5846,\n",
      "        0.7467, 0.7819], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0066, -0.0624,  0.0521, -0.0273,  0.1269, -0.0199, -0.0350,  0.1112,\n",
      "         0.3734,  0.3289], grad_fn=<AddBackward0>)\n",
      "tensor(0.8413, grad_fn=<SumBackward0>)\n",
      "Epoch 222 loss is 0.8412550091743469\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6000, 0.7810, 0.7852, 0.5945, 0.6168, 0.6161, 0.7452, 0.6125, 0.7842,\n",
      "        0.7874, 0.5909], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.3087, -0.0018, -0.0547, -0.0564,  0.2512, -0.0014,  0.2802,  0.0703,\n",
      "        -0.0072, -0.0645], grad_fn=<AddBackward0>)\n",
      "tensor(0.7243, grad_fn=<SumBackward0>)\n",
      "Epoch 223 loss is 0.7243421077728271\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8273, 0.6166, 0.7694, 0.5884, 0.6696, 0.6973, 0.7714, 0.6569, 0.7214,\n",
      "        0.7821, 0.5781], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0193, -0.0796,  0.0882, -0.0240,  0.3049, -0.0042,  0.0401,  0.0179,\n",
      "        -0.0263, -0.0477], grad_fn=<AddBackward0>)\n",
      "tensor(0.2500, grad_fn=<SumBackward0>)\n",
      "Epoch 224 loss is 0.24996304512023926\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8032, 0.7725, 0.7470, 0.7636, 0.7415, 0.6192, 0.5730, 0.7684, 0.7677,\n",
      "        0.6081, 0.7948], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0187, -0.0132, -0.0103, -0.0426, -0.0635,  0.0447,  0.2476,  0.0586,\n",
      "         0.0441,  0.0451], grad_fn=<AddBackward0>)\n",
      "tensor(0.2917, grad_fn=<SumBackward0>)\n",
      "Epoch 225 loss is 0.29170989990234375\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7976, 0.6301, 0.7544, 0.8091, 0.5780, 0.7745, 0.7575, 0.5971, 0.6374,\n",
      "        0.7489, 0.6171], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0144,  0.0192, -0.0174,  0.0335, -0.0172,  0.0319, -0.0457, -0.0029,\n",
      "         0.0333, -0.0068], grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, grad_fn=<SumBackward0>)\n",
      "Epoch 226 loss is 0.01356416940689087\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5917, 0.5617, 0.7562, 0.6407, 0.7465, 0.6539, 0.7231, 0.7108, 0.6365,\n",
      "        0.5850, 0.7175], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2742,  0.0816,  0.3080, -0.0341,  0.1375, -0.0119, -0.0058, -0.0460,\n",
      "         0.0111,  0.1350], grad_fn=<AddBackward0>)\n",
      "tensor(0.8493, grad_fn=<SumBackward0>)\n",
      "Epoch 227 loss is 0.8493131995201111\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5712, 0.7173, 0.6474, 0.6231, 0.6926, 0.7367, 0.6994, 0.7218, 0.7019,\n",
      "        0.6736, 0.6982], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1270,  0.0864, -0.0082,  0.1487,  0.1272,  0.0487, -0.0116, -0.0086,\n",
      "        -0.0079, -0.0012], grad_fn=<AddBackward0>)\n",
      "tensor(0.5005, grad_fn=<SumBackward0>)\n",
      "Epoch 228 loss is 0.5005133748054504\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6206, 0.6826, 0.6349, 0.6975, 0.6896, 0.6596, 0.7534, 0.7214, 0.6565,\n",
      "        0.7090, 0.6765], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0238,  0.1281,  0.0116,  0.0412,  0.0932,  0.0530, -0.0010, -0.0148,\n",
      "        -0.0150,  0.0333], grad_fn=<AddBackward0>)\n",
      "tensor(0.3534, grad_fn=<SumBackward0>)\n",
      "Epoch 229 loss is 0.3533516526222229\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4566, 0.7912, 0.6298, 0.7353, 0.6769, 0.6941, 0.6621, 0.6724, 0.7542,\n",
      "        0.7322, 0.6387], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2886,  0.4646, -0.0381,  0.1072, -0.0244, -0.0015,  0.1003,  0.1167,\n",
      "        -0.0112, -0.0385], grad_fn=<AddBackward0>)\n",
      "tensor(0.9636, grad_fn=<SumBackward0>)\n",
      "Epoch 230 loss is 0.9635669589042664\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6560, 0.6030, 0.6950, 0.7357, 0.6795, 0.7027, 0.7317, 0.6994, 0.6578,\n",
      "        0.7436, 0.6967], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0649,  0.1328,  0.1276,  0.0128, -0.0013,  0.0331, -0.0150,  0.0197,\n",
      "        -0.0009,  0.0648], grad_fn=<AddBackward0>)\n",
      "tensor(0.4386, grad_fn=<SumBackward0>)\n",
      "Epoch 231 loss is 0.4385678768157959\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6034, 0.6991, 0.6843, 0.6757, 0.6722, 0.7259, 0.7032, 0.7030, 0.6663,\n",
      "        0.7023, 0.7009], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1348,  0.1206, -0.0090,  0.0693,  0.0458,  0.0513, -0.0199, -0.0003,\n",
      "        -0.0007,  0.0576], grad_fn=<AddBackward0>)\n",
      "tensor(0.4497, grad_fn=<SumBackward0>)\n",
      "Epoch 232 loss is 0.4496954083442688\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7593, 0.6687, 0.6659, 0.6788, 0.6880, 0.7211, 0.7003, 0.7765, 0.6070,\n",
      "        0.6776, 0.6982], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0311, -0.0268,  0.0321,  0.0920,  0.0358,  0.1475, -0.0380, -0.0075,\n",
      "        -0.0261,  0.1520], grad_fn=<AddBackward0>)\n",
      "tensor(0.3298, grad_fn=<SumBackward0>)\n",
      "Epoch 233 loss is 0.3298256993293762\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6722, 0.6778, 0.6082, 0.7528, 0.8123, 0.7793, 0.7414, 0.6592, 0.6121,\n",
      "        0.7334, 0.7795], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0214,  0.1342,  0.2242,  0.2852, -0.0038, -0.0510, -0.0557, -0.0027,\n",
      "         0.2005,  0.2790], grad_fn=<AddBackward0>)\n",
      "tensor(0.9885, grad_fn=<SumBackward0>)\n",
      "Epoch 234 loss is 0.988539457321167\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7758, 0.7445, 0.7798, 0.7827, 0.6372, 0.6036, 0.5789, 0.7800, 0.6257,\n",
      "        0.7885, 0.5958], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0067,  0.0115, -0.0358, -0.0587, -0.0679,  0.2380,  0.0369,  0.3492,\n",
      "        -0.0614, -0.0100], grad_fn=<AddBackward0>)\n",
      "tensor(0.4084, grad_fn=<SumBackward0>)\n",
      "Epoch 235 loss is 0.4084388017654419\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6956, 0.7369, 0.5687, 0.8004, 0.8366, 0.7881, 0.5952, 0.7716, 0.6029,\n",
      "        0.7791, 0.7864], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0423,  0.1747,  0.1662,  0.3657, -0.0684, -0.0217, -0.0618,  0.3065,\n",
      "         0.0247,  0.3059], grad_fn=<AddBackward0>)\n",
      "tensor(1.1496, grad_fn=<SumBackward0>)\n",
      "Epoch 236 loss is 1.1495542526245117\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7235, 0.7645, 0.8115, 0.5807, 0.7596, 0.7470, 0.7935, 0.5679, 0.5622,\n",
      "        0.5683, 0.5731], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1465, -0.0476, -0.0016, -0.0215,  0.3547, -0.0639, -0.0616, -0.0751,\n",
      "         0.0086,  0.0181], grad_fn=<AddBackward0>)\n",
      "tensor(0.2566, grad_fn=<SumBackward0>)\n",
      "Epoch 237 loss is 0.2565957307815552\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6714, 0.6080, 0.5852, 0.7887, 0.5999, 0.5753, 0.8382, 0.5756, 0.6376,\n",
      "        0.8123, 0.5807], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0287,  0.1955, -0.0027, -0.0033,  0.0826, -0.0081,  0.1037, -0.0087,\n",
      "         0.0086, -0.0189], grad_fn=<AddBackward0>)\n",
      "tensor(0.3199, grad_fn=<SumBackward0>)\n",
      "Epoch 238 loss is 0.31993567943573\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7391, 0.5628, 0.8441, 0.7966, 0.7607, 0.8268, 0.5788, 0.8342, 0.8569,\n",
      "        0.5455, 0.7968], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1750,  0.0959,  0.3299, -0.0057, -0.0726,  0.1224,  0.0502, -0.0111,\n",
      "        -0.0125, -0.0201], grad_fn=<AddBackward0>)\n",
      "tensor(0.6514, grad_fn=<SumBackward0>)\n",
      "Epoch 239 loss is 0.6514444947242737\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8471, 0.9446, 0.5500, 0.5926, 0.5830, 0.8004, 0.5795, 0.5745, 0.5751,\n",
      "        0.8946, 0.8142], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0990, -0.0848, -0.1205,  0.4174, -0.0044, -0.0028, -0.0751,  0.5252,\n",
      "         0.3995,  0.3985], grad_fn=<AddBackward0>)\n",
      "tensor(1.3539, grad_fn=<SumBackward0>)\n",
      "Epoch 240 loss is 1.353868842124939\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6354, 0.8062, 0.8498, 0.7931, 0.7823, 0.6148, 0.5971, 0.6007, 0.5801,\n",
      "        0.7941, 0.6151], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.3572,  0.2627, -0.0080, -0.0783, -0.0653, -0.0605, -0.0116,  0.3284,\n",
      "         0.0240,  0.0584], grad_fn=<AddBackward0>)\n",
      "tensor(0.8071, grad_fn=<SumBackward0>)\n",
      "Epoch 241 loss is 0.8071050643920898\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7508, 0.7944, 0.6149, 0.7952, 0.7330, 0.5829, 0.7358, 0.7715, 0.7651,\n",
      "        0.6132, 0.6299], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0453,  0.0740, -0.0205, -0.0106, -0.0198,  0.0643,  0.3036, -0.0409,\n",
      "        -0.0472, -0.0450], grad_fn=<AddBackward0>)\n",
      "tensor(0.2125, grad_fn=<SumBackward0>)\n",
      "Epoch 242 loss is 0.2125210165977478\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7342, 0.6268, 0.7795, 0.7982, 0.6011, 0.7063, 0.7247, 0.6326, 0.7543,\n",
      "        0.7619, 0.6238], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0756,  0.1067, -0.0085, -0.0244, -0.0245,  0.0525,  0.0801,  0.0620,\n",
      "        -0.0030, -0.0435], grad_fn=<AddBackward0>)\n",
      "tensor(0.2729, grad_fn=<SumBackward0>)\n",
      "Epoch 243 loss is 0.27292585372924805\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6644, 0.6724, 0.6132, 0.6226, 0.7558, 0.8002, 0.6064, 0.7474, 0.6300,\n",
      "        0.7109, 0.7488], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0171, -0.0139,  0.1390,  0.3117, -0.0054, -0.0028, -0.0567,  0.1742,\n",
      "         0.0023,  0.1980], grad_fn=<AddBackward0>)\n",
      "tensor(0.7292, grad_fn=<SumBackward0>)\n",
      "Epoch 244 loss is 0.7292394042015076\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6902, 0.7189, 0.6731, 0.7023, 0.6865, 0.6805, 0.6798, 0.6923, 0.7354,\n",
      "        0.6374, 0.6817], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0057,  0.0203, -0.0108,  0.0123, -0.0075,  0.0097,  0.0915, -0.0141,\n",
      "        -0.0035, -0.0179], grad_fn=<AddBackward0>)\n",
      "tensor(0.0743, grad_fn=<SumBackward0>)\n",
      "Epoch 245 loss is 0.07425367832183838\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7773, 0.7412, 0.6804, 0.6765, 0.7402, 0.6910, 0.6635, 0.7026, 0.7412,\n",
      "        0.6851, 0.7567], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0323, -0.0336, -0.0003,  0.0178, -0.0043, -0.0125,  0.0836,  0.0360,\n",
      "         0.0902,  0.0259], grad_fn=<AddBackward0>)\n",
      "tensor(0.1704, grad_fn=<SumBackward0>)\n",
      "Epoch 246 loss is 0.17040735483169556\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7557, 0.6960, 0.6844, 0.6616, 0.7074, 0.6545, 0.6112, 0.7172, 0.6409,\n",
      "        0.6696, 0.7253], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0238, -0.0314,  0.0191, -0.0100, -0.0168,  0.0163, -0.0045,  0.0973,\n",
      "         0.0135,  0.1407], grad_fn=<AddBackward0>)\n",
      "tensor(0.2006, grad_fn=<SumBackward0>)\n",
      "Epoch 247 loss is 0.20057636499404907\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5509, 0.7877, 0.6287, 0.7324, 0.6640, 0.6317, 0.7655, 0.6337, 0.7455,\n",
      "        0.6149, 0.7406], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1297,  0.3025, -0.0413,  0.0050,  0.0552, -0.0101,  0.1896, -0.0502,\n",
      "         0.1782, -0.0016], grad_fn=<AddBackward0>)\n",
      "tensor(0.7571, grad_fn=<SumBackward0>)\n",
      "Epoch 248 loss is 0.757081925868988\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6192, 0.5817, 0.7926, 0.7450, 0.5875, 0.6022, 0.5639, 0.6072, 0.5950,\n",
      "        0.6206, 0.5871], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2890,  0.2097,  0.0095, -0.0635, -0.0604,  0.0329, -0.0024,  0.0946,\n",
      "        -0.0067, -0.0026], grad_fn=<AddBackward0>)\n",
      "tensor(0.5002, grad_fn=<SumBackward0>)\n",
      "Epoch 249 loss is 0.5001853108406067\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.3189, 0.7323, 0.7309, 0.7915, 0.8384, 0.5412, 0.5976, 0.5416, 0.8386,\n",
      "        0.6229, 0.8862], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.6866,  0.7876,  0.1768, -0.0632, -0.0646, -0.0989,  0.4957,  0.0422,\n",
      "         0.5742,  0.0793], grad_fn=<AddBackward0>)\n",
      "tensor(2.6157, grad_fn=<SumBackward0>)\n",
      "Epoch 250 loss is 2.615671157836914\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5323, 0.8485, 0.5627, 0.8514, 0.8629, 0.8392, 0.5590, 0.8882, 0.4939,\n",
      "        0.5280, 0.5545], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0506,  0.5318,  0.0239,  0.4609, -0.0975,  0.0423, -0.1151, -0.0104,\n",
      "        -0.1113,  0.1009], grad_fn=<AddBackward0>)\n",
      "tensor(0.8763, grad_fn=<SumBackward0>)\n",
      "Epoch 251 loss is 0.8762539625167847\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8597, 0.5861, 0.8362, 0.5543, 0.5444, 0.9307, 0.8076, 0.8447, 0.8174,\n",
      "        0.5439, 0.8527], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0078, -0.1018, -0.0139,  0.1576,  0.4222,  0.5005, -0.0378, -0.0879,\n",
      "         0.0134,  0.0589], grad_fn=<AddBackward0>)\n",
      "tensor(0.9034, grad_fn=<SumBackward0>)\n",
      "Epoch 252 loss is 0.9034019112586975\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5448, 0.5568, 0.5403, 0.5015, 0.5382, 0.8386, 0.5296, 0.8545, 0.5812,\n",
      "        0.5431, 0.8475], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0015, -0.0144, -0.0062,  0.4973,  0.0468,  0.5273, -0.0858,  0.0225,\n",
      "        -0.0024,  0.4437], grad_fn=<AddBackward0>)\n",
      "tensor(1.4273, grad_fn=<SumBackward0>)\n",
      "Epoch 253 loss is 1.427274227142334\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5242, 0.8681, 0.5058, 0.8324, 0.8049, 0.5358, 0.8327, 0.8454, 0.8631,\n",
      "        0.5618, 0.5754], grad_fn=<ViewBackward0>)\n",
      "tensor([-6.1544e-03,  5.1360e-01, -2.1039e-02,  4.9966e-02,  5.2631e-04,\n",
      "         6.7429e-02,  5.4553e-01, -9.0312e-02, -9.0007e-02, -9.5899e-02],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.8736, grad_fn=<SumBackward0>)\n",
      "Epoch 254 loss is 0.8736424446105957\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8941, 0.5294, 0.5234, 0.5248, 0.9068, 0.8541, 0.8319, 0.8466, 0.5926,\n",
      "        0.5404, 0.5262], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1236, -0.1231,  0.6289,  0.5512,  0.5117, -0.0201, -0.0872, -0.0972,\n",
      "        -0.1068, -0.0221], grad_fn=<AddBackward0>)\n",
      "tensor(1.1118, grad_fn=<SumBackward0>)\n",
      "Epoch 255 loss is 1.1118133068084717\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8575, 0.5805, 0.5866, 0.5696, 0.6065, 0.5513, 0.5906, 0.5737, 0.8523,\n",
      "        0.5809, 0.8426], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0903, -0.0960,  0.0433, -0.0118,  0.0350, -0.0109,  0.5018, -0.0032,\n",
      "         0.4482, -0.0033], grad_fn=<AddBackward0>)\n",
      "tensor(0.8128, grad_fn=<SumBackward0>)\n",
      "Epoch 256 loss is 0.8128352761268616\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8721, 0.5828, 0.7869, 0.5740, 0.7553, 0.5753, 0.5636, 0.5831, 0.6194,\n",
      "        0.8531, 0.8016], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0284, -0.0994,  0.2875, -0.0706, -0.0035, -0.0574,  0.0735,  0.4824,\n",
      "         0.3640,  0.3037], grad_fn=<AddBackward0>)\n",
      "tensor(1.2519, grad_fn=<SumBackward0>)\n",
      "Epoch 257 loss is 1.2519118785858154\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5445, 0.8319, 0.5956, 0.6074, 0.5826, 0.8727, 0.8170, 0.4875, 0.8357,\n",
      "        0.5905, 0.6307], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0851,  0.1047, -0.0831,  0.4618,  0.3494, -0.0317, -0.0123, -0.0755,\n",
      "         0.2386, -0.0684], grad_fn=<AddBackward0>)\n",
      "tensor(0.9685, grad_fn=<SumBackward0>)\n",
      "Epoch 258 loss is 0.9685312509536743\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5600, 0.8121, 0.8205, 0.5677, 0.7951, 0.6227, 0.6097, 0.5755, 0.6432,\n",
      "        0.7922, 0.7601], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4342,  0.0129, -0.0057, -0.0659,  0.0700, -0.0732,  0.0342,  0.3041,\n",
      "         0.3078,  0.1949], grad_fn=<AddBackward0>)\n",
      "tensor(1.2132, grad_fn=<SumBackward0>)\n",
      "Epoch 259 loss is 1.2132047414779663\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4480, 0.6350, 0.6972, 0.7570, 0.7732, 0.8043, 0.5663, 0.7895, 0.7427,\n",
      "        0.6355, 0.5905], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4153,  0.5150,  0.2303,  0.1786, -0.0636,  0.0271, -0.0205,  0.1154,\n",
      "        -0.0663, -0.0507], grad_fn=<AddBackward0>)\n",
      "tensor(1.2805, grad_fn=<SumBackward0>)\n",
      "Epoch 260 loss is 1.2804529666900635\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5793, 0.7412, 0.6638, 0.5980, 0.6424, 0.7992, 0.7807, 0.7561, 0.7617,\n",
      "        0.6024, 0.6371], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1408,  0.0312, -0.0329,  0.2258,  0.3045,  0.1895, -0.0125, -0.0594,\n",
      "        -0.0397, -0.0416], grad_fn=<AddBackward0>)\n",
      "tensor(0.7058, grad_fn=<SumBackward0>)\n",
      "Epoch 261 loss is 0.7057809829711914\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7992, 0.6416, 0.7593, 0.7519, 0.5774, 0.6953, 0.6170, 0.7578, 0.7931,\n",
      "        0.7273, 0.6111], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0133, -0.0157, -0.0214, -0.0214, -0.0450,  0.3007,  0.1631,  0.1839,\n",
      "        -0.0489, -0.0607], grad_fn=<AddBackward0>)\n",
      "tensor(0.4213, grad_fn=<SumBackward0>)\n",
      "Epoch 262 loss is 0.42132318019866943\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5888, 0.7405, 0.5989, 0.6540, 0.6837, 0.7249, 0.6713, 0.6839, 0.7010,\n",
      "        0.7043, 0.6232], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0168,  0.1087, -0.0189,  0.2100,  0.0289,  0.0003, -0.0080,  0.0550,\n",
      "        -0.0202, -0.0259], grad_fn=<AddBackward0>)\n",
      "tensor(0.3467, grad_fn=<SumBackward0>)\n",
      "Epoch 263 loss is 0.3467123508453369\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7332, 0.7472, 0.7276, 0.7495, 0.7069, 0.6951, 0.7134, 0.6966, 0.6942,\n",
      "        0.7154, 0.6873], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0018,  0.0272, -0.0134, -0.0108, -0.0120, -0.0035, -0.0003,  0.0034,\n",
      "        -0.0031, -0.0023], grad_fn=<AddBackward0>)\n",
      "tensor(-0.0167, grad_fn=<SumBackward0>)\n",
      "Epoch 264 loss is -0.01669490337371826\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6252, 0.7009, 0.6735, 0.6377, 0.6747, 0.6867, 0.7110, 0.6998, 0.7513,\n",
      "        0.7382, 0.6847], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0805,  0.0208, -0.0087,  0.0219,  0.1221,  0.0418,  0.1077,  0.0455,\n",
      "        -0.0050, -0.0222], grad_fn=<AddBackward0>)\n",
      "tensor(0.4043, grad_fn=<SumBackward0>)\n",
      "Epoch 265 loss is 0.40428757667541504\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7147, 0.7094, 0.6861, 0.7176, 0.6770, 0.6667, 0.6673, 0.7317, 0.6793,\n",
      "        0.6733, 0.6687], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0095,  0.0048, -0.0108, -0.0065, -0.0168,  0.0912,  0.0210,  0.0100,\n",
      "        -0.0210, -0.0035], grad_fn=<AddBackward0>)\n",
      "tensor(0.0588, grad_fn=<SumBackward0>)\n",
      "Epoch 266 loss is 0.058839499950408936\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7003, 0.6527, 0.7024, 0.6527, 0.8035, 0.8095, 0.7302, 0.7297, 0.7416,\n",
      "        0.7044, 0.6950], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0036, -0.0158,  0.2514,  0.1785,  0.1291, -0.0246, -0.0226, -0.0086,\n",
      "        -0.0116, -0.0155], grad_fn=<AddBackward0>)\n",
      "tensor(0.4638, grad_fn=<SumBackward0>)\n",
      "Epoch 267 loss is 0.46381044387817383\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7150, 0.7617, 0.7114, 0.7342, 0.6429, 0.6118, 0.7472, 0.6703, 0.7139,\n",
      "        0.6095, 0.6014], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0012,  0.0320, -0.0396, -0.0332,  0.0216,  0.0457,  0.1701, -0.0459,\n",
      "        -0.0230, -0.0375], grad_fn=<AddBackward0>)\n",
      "tensor(0.0890, grad_fn=<SumBackward0>)\n",
      "Epoch 268 loss is 0.08900284767150879\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6788, 0.6878, 0.6624, 0.6399, 0.7089, 0.7136, 0.6185, 0.6135, 0.6948,\n",
      "        0.6827, 0.6706], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0055, -0.0130,  0.0351,  0.0853, -0.0071, -0.0318, -0.0063,  0.1069,\n",
      "         0.0951, -0.0081], grad_fn=<AddBackward0>)\n",
      "tensor(0.2508, grad_fn=<SumBackward0>)\n",
      "Epoch 269 loss is 0.25078946352005005\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8883, 0.5711, 0.7796, 0.6050, 0.7575, 0.6306, 0.6762, 0.7309, 0.6714,\n",
      "        0.6535, 0.6915], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0362, -0.0944,  0.3106, -0.0497,  0.1188, -0.0089,  0.0679, -0.0076,\n",
      "        -0.0131,  0.0335], grad_fn=<AddBackward0>)\n",
      "tensor(0.3209, grad_fn=<SumBackward0>)\n",
      "Epoch 270 loss is 0.3209049105644226\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7064, 0.7600, 0.6469, 0.7393, 0.6098, 0.6855, 0.7131, 0.6474, 0.6454,\n",
      "        0.7376, 0.7486], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0198,  0.0548, -0.0501,  0.0643, -0.0087,  0.0627, -0.0134,  0.0407,\n",
      "         0.1686,  0.1721], grad_fn=<AddBackward0>)\n",
      "tensor(0.4713, grad_fn=<SumBackward0>)\n",
      "Epoch 271 loss is 0.4712867736816406\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6957, 0.6746, 0.7324, 0.6698, 0.6294, 0.7305, 0.6173, 0.7388, 0.7879,\n",
      "        0.6006, 0.6328], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0613, -0.0086, -0.0151, -0.0007, -0.0175,  0.1823,  0.0957, -0.0056,\n",
      "        -0.0353, -0.0517], grad_fn=<AddBackward0>)\n",
      "tensor(0.2049, grad_fn=<SumBackward0>)\n",
      "Epoch 272 loss is 0.2048594355583191\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6597, 0.6769, 0.7114, 0.7688, 0.7541, 0.7255, 0.7205, 0.6500, 0.6961,\n",
      "        0.6815, 0.7159], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0863,  0.1819,  0.1288,  0.0234, -0.0161, -0.0347, -0.0098, -0.0130,\n",
      "         0.1099,  0.0330], grad_fn=<AddBackward0>)\n",
      "tensor(0.4897, grad_fn=<SumBackward0>)\n",
      "Epoch 273 loss is 0.48966503143310547\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6952, 0.7290, 0.6518, 0.6481, 0.7451, 0.6580, 0.7222, 0.6022, 0.7226,\n",
      "        0.7362, 0.7272], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0145, -0.0157,  0.0268,  0.0103,  0.1235, -0.0476,  0.1077,  0.0233,\n",
      "         0.2083,  0.0076], grad_fn=<AddBackward0>)\n",
      "tensor(0.4298, grad_fn=<SumBackward0>)\n",
      "Epoch 274 loss is 0.4298238158226013\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6271, 0.6894, 0.7169, 0.7010, 0.6882, 0.7072, 0.6824, 0.7101, 0.6593,\n",
      "        0.6463, 0.6669], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1497,  0.1232, -0.0004, -0.0032, -0.0062,  0.0364, -0.0160, -0.0120,\n",
      "        -0.0144,  0.0127], grad_fn=<AddBackward0>)\n",
      "tensor(0.2698, grad_fn=<SumBackward0>)\n",
      "Epoch 275 loss is 0.2698025107383728\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5890, 0.7027, 0.7378, 0.6995, 0.6840, 0.7617, 0.6604, 0.6887, 0.6788,\n",
      "        0.6869, 0.6895], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2481,  0.1841, -0.0062,  0.0397, -0.0130,  0.0078, -0.0276,  0.0441,\n",
      "         0.0012,  0.0178], grad_fn=<AddBackward0>)\n",
      "tensor(0.4960, grad_fn=<SumBackward0>)\n",
      "Epoch 276 loss is 0.4959651231765747\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8008, 0.7298, 0.6554, 0.6432, 0.7487, 0.6426, 0.6936, 0.6902, 0.7000,\n",
      "        0.6726, 0.6508], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0485, -0.0525,  0.0314, -0.0043,  0.0840, -0.0195,  0.0957, -0.0070,\n",
      "        -0.0132, -0.0164], grad_fn=<AddBackward0>)\n",
      "tensor(0.0498, grad_fn=<SumBackward0>)\n",
      "Epoch 277 loss is 0.04978644847869873\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5635, 0.7264, 0.6807, 0.7472, 0.6884, 0.7127, 0.7577, 0.6280, 0.6879,\n",
      "        0.6851, 0.5983], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1954,  0.3062, -0.0127,  0.0533,  0.0175, -0.0201, -0.0083, -0.0242,\n",
      "        -0.0099, -0.0299], grad_fn=<AddBackward0>)\n",
      "tensor(0.4674, grad_fn=<SumBackward0>)\n",
      "Epoch 278 loss is 0.46738749742507935\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6328, 0.6053, 0.7402, 0.7405, 0.6172, 0.7275, 0.7397, 0.7139, 0.6368,\n",
      "        0.6482, 0.6579], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1790,  0.1795,  0.0198, -0.0042, -0.0003,  0.1612, -0.0302, -0.0305,\n",
      "        -0.0187,  0.0353], grad_fn=<AddBackward0>)\n",
      "tensor(0.4909, grad_fn=<SumBackward0>)\n",
      "Epoch 279 loss is 0.490933358669281\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4697, 0.7311, 0.7314, 0.6610, 0.6643, 0.6316, 0.6282, 0.7084, 0.7076,\n",
      "        0.7147, 0.7395], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4362,  0.3188, -0.0223, -0.0333, -0.0109,  0.0734,  0.1266,  0.1441,\n",
      "         0.0519,  0.0532], grad_fn=<AddBackward0>)\n",
      "tensor(1.1378, grad_fn=<SumBackward0>)\n",
      "Epoch 280 loss is 1.1377702951431274\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5808, 0.7745, 0.6572, 0.6812, 0.6295, 0.5982, 0.7764, 0.7105, 0.6435,\n",
      "        0.6651, 0.6380], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1273,  0.1673, -0.0483, -0.0197,  0.1587,  0.1350,  0.0755, -0.0371,\n",
      "        -0.0242, -0.0018], grad_fn=<AddBackward0>)\n",
      "tensor(0.5327, grad_fn=<SumBackward0>)\n",
      "Epoch 281 loss is 0.5327053070068359\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5881, 0.7398, 0.7503, 0.6480, 0.6806, 0.6721, 0.7392, 0.6199, 0.7265,\n",
      "        0.7632, 0.7420], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2703,  0.0998, -0.0198, -0.0261,  0.1520, -0.0202,  0.0907,  0.0400,\n",
      "         0.2035,  0.0259], grad_fn=<AddBackward0>)\n",
      "tensor(0.8160, grad_fn=<SumBackward0>)\n",
      "Epoch 282 loss is 0.8160408735275269\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7977, 0.7450, 0.7136, 0.7274, 0.6156, 0.6294, 0.7199, 0.7253, 0.6219,\n",
      "        0.5976, 0.6342], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0280, -0.0235, -0.0431, -0.0281, -0.0025,  0.1829, -0.0025, -0.0408,\n",
      "        -0.0304,  0.0205], grad_fn=<AddBackward0>)\n",
      "tensor(0.0046, grad_fn=<SumBackward0>)\n",
      "Epoch 283 loss is 0.004590809345245361\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7786, 0.7539, 0.7885, 0.6169, 0.5768, 0.7230, 0.7426, 0.6980, 0.7027,\n",
      "        0.7207, 0.7288], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0165, -0.0539, -0.0590, -0.0218,  0.2095,  0.2021, -0.0068, -0.0073,\n",
      "         0.0513,  0.0435], grad_fn=<AddBackward0>)\n",
      "tensor(0.3740, grad_fn=<SumBackward0>)\n",
      "Epoch 284 loss is 0.37398821115493774\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5822, 0.7372, 0.6589, 0.5828, 0.7468, 0.6696, 0.7425, 0.7435, 0.7154,\n",
      "        0.6527, 0.7337], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1277,  0.0009,  0.0159,  0.0180,  0.2661, -0.0011,  0.0762, -0.0299,\n",
      "        -0.0033,  0.0305], grad_fn=<AddBackward0>)\n",
      "tensor(0.5011, grad_fn=<SumBackward0>)\n",
      "Epoch 285 loss is 0.5010519027709961\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7358, 0.6726, 0.6621, 0.7178, 0.6442, 0.6062, 0.7257, 0.6666, 0.7194,\n",
      "        0.7145, 0.6257], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0246, -0.0060, -0.0095, -0.0186,  0.0132,  0.0373,  0.1887, -0.0037,\n",
      "        -0.0136, -0.0312], grad_fn=<AddBackward0>)\n",
      "tensor(0.1319, grad_fn=<SumBackward0>)\n",
      "Epoch 286 loss is 0.13193261623382568\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8090, 0.6349, 0.7249, 0.6212, 0.6997, 0.6560, 0.6737, 0.6940, 0.6960,\n",
      "        0.6935, 0.7001], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0280, -0.0626,  0.1080, -0.0230,  0.0875, -0.0019,  0.0667,  0.0329,\n",
      "         0.0101,  0.0067], grad_fn=<AddBackward0>)\n",
      "tensor(0.1965, grad_fn=<SumBackward0>)\n",
      "Epoch 287 loss is 0.19648772478103638\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5875, 0.7519, 0.7266, 0.6723, 0.7027, 0.7336, 0.7020, 0.7033, 0.6533,\n",
      "        0.6670, 0.7187], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2318,  0.1413, -0.0164,  0.0117,  0.0494,  0.0010, -0.0268, -0.0117,\n",
      "         0.0255,  0.1090], grad_fn=<AddBackward0>)\n",
      "tensor(0.5149, grad_fn=<SumBackward0>)\n",
      "Epoch 288 loss is 0.514879584312439\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6040, 0.7038, 0.7316, 0.7216, 0.7150, 0.7033, 0.6861, 0.7036, 0.7109,\n",
      "        0.6665, 0.6595], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2127,  0.1960,  0.0188, -0.0094, -0.0118, -0.0038,  0.0126, -0.0065,\n",
      "        -0.0147, -0.0171], grad_fn=<AddBackward0>)\n",
      "tensor(0.3766, grad_fn=<SumBackward0>)\n",
      "Epoch 289 loss is 0.37664371728897095\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4590, 0.7707, 0.6521, 0.6011, 0.6812, 0.6970, 0.7556, 0.6330, 0.6564,\n",
      "        0.7219, 0.6577], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.3219,  0.2368, -0.0298,  0.0747,  0.2575, -0.0161, -0.0135, -0.0112,\n",
      "         0.0412,  0.0021], grad_fn=<AddBackward0>)\n",
      "tensor(0.8635, grad_fn=<SumBackward0>)\n",
      "Epoch 290 loss is 0.8635427951812744\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6544, 0.6479, 0.6953, 0.6624, 0.7046, 0.6420, 0.7084, 0.7278, 0.6471,\n",
      "        0.7189, 0.6531], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0682,  0.0133,  0.0944, -0.0178,  0.0766,  0.0387,  0.0085,  0.0174,\n",
      "        -0.0249,  0.0100], grad_fn=<AddBackward0>)\n",
      "tensor(0.2845, grad_fn=<SumBackward0>)\n",
      "Epoch 291 loss is 0.2845001816749573\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6619, 0.7089, 0.7449, 0.6979, 0.6440, 0.6778, 0.7155, 0.6742, 0.7515,\n",
      "        0.7110, 0.7000], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1384,  0.0600, -0.0216, -0.0224,  0.0293,  0.0503,  0.1229, -0.0015,\n",
      "         0.0430, -0.0172], grad_fn=<AddBackward0>)\n",
      "tensor(0.3811, grad_fn=<SumBackward0>)\n",
      "Epoch 292 loss is 0.381147563457489\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7404, 0.7234, 0.7163, 0.6880, 0.7179, 0.7319, 0.6992, 0.7263, 0.7241,\n",
      "        0.6692, 0.7242], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0080, -0.0175, -0.0018,  0.0260,  0.0188,  0.0141, -0.0026, -0.0100,\n",
      "        -0.0007,  0.0002], grad_fn=<AddBackward0>)\n",
      "tensor(0.0184, grad_fn=<SumBackward0>)\n",
      "Epoch 293 loss is 0.018433332443237305\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7572, 0.7335, 0.7479, 0.7025, 0.6641, 0.7293, 0.6734, 0.6811, 0.7209,\n",
      "        0.6797, 0.6779], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0031, -0.0183, -0.0231, -0.0062, -0.0097,  0.0282, -0.0028,  0.0106,\n",
      "        -0.0011, -0.0143], grad_fn=<AddBackward0>)\n",
      "tensor(-0.0399, grad_fn=<SumBackward0>)\n",
      "Epoch 294 loss is -0.03985166549682617\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6664, 0.7659, 0.6578, 0.6883, 0.7145, 0.7484, 0.6351, 0.7175, 0.6646,\n",
      "        0.7273, 0.7508], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0029,  0.0365, -0.0171,  0.1510, -0.0177,  0.0049, -0.0279,  0.1537,\n",
      "         0.0555,  0.1437], grad_fn=<AddBackward0>)\n",
      "tensor(0.4797, grad_fn=<SumBackward0>)\n",
      "Epoch 295 loss is 0.4796556830406189\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7752, 0.5826, 0.6559, 0.7457, 0.6487, 0.7275, 0.7066, 0.6758, 0.6893,\n",
      "        0.7171, 0.7518], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0398, -0.0098,  0.1102,  0.1193, -0.0130,  0.0452, -0.0127,  0.0174,\n",
      "         0.1267,  0.1043], grad_fn=<AddBackward0>)\n",
      "tensor(0.4476, grad_fn=<SumBackward0>)\n",
      "Epoch 296 loss is 0.4475628733634949\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6341, 0.7319, 0.7263, 0.6565, 0.6439, 0.7003, 0.7104, 0.6223, 0.7172,\n",
      "        0.6435, 0.6296], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1537,  0.0373, -0.0293, -0.0087,  0.0898, -0.0072,  0.0281, -0.0223,\n",
      "         0.0121, -0.0292], grad_fn=<AddBackward0>)\n",
      "tensor(0.2244, grad_fn=<SumBackward0>)\n",
      "Epoch 297 loss is 0.22437870502471924\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5729, 0.7315, 0.7292, 0.6877, 0.6814, 0.7225, 0.6991, 0.6958, 0.6809,\n",
      "        0.7384, 0.6640], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2606,  0.1914, -0.0167, -0.0023,  0.0190,  0.0240, -0.0139,  0.0655,\n",
      "        -0.0106, -0.0056], grad_fn=<AddBackward0>)\n",
      "tensor(0.5115, grad_fn=<SumBackward0>)\n",
      "Epoch 298 loss is 0.5114775896072388\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6655, 0.6681, 0.7036, 0.7296, 0.6887, 0.7129, 0.7059, 0.6603, 0.7115,\n",
      "        0.6795, 0.7098], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0635,  0.1068,  0.0343,  0.0155, -0.0079, -0.0095, -0.0005, -0.0088,\n",
      "         0.0825, -0.0006], grad_fn=<AddBackward0>)\n",
      "tensor(0.2754, grad_fn=<SumBackward0>)\n",
      "Epoch 299 loss is 0.27539414167404175\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9172, 0.8591, 0.7045, 0.7549, 0.7027, 0.6933, 0.7269, 0.7002, 0.6774,\n",
      "        0.6974, 0.7001], grad_fn=<ViewBackward0>)\n",
      "tensor([-7.0898e-02, -5.4118e-02, -5.2128e-02, -3.7491e-03, -9.3293e-03,\n",
      "        -8.1825e-04, -5.2819e-03, -9.8433e-03, -5.1439e-05,  3.7719e-02],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(-0.1685, grad_fn=<SumBackward0>)\n",
      "Epoch 300 loss is -0.16849851608276367\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6350, 0.6917, 0.7520, 0.6672, 0.6648, 0.7187, 0.7008, 0.7283, 0.7185,\n",
      "        0.6954, 0.6699], grad_fn=<ViewBackward0>)\n",
      "tensor([ 1.9514e-01,  5.3663e-02, -8.9611e-03, -1.1123e-02,  5.6071e-02,\n",
      "         1.0590e-01, -4.5300e-05, -1.7992e-03, -1.9483e-02, -1.6213e-02],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.3532, grad_fn=<SumBackward0>)\n",
      "Epoch 301 loss is 0.35315102338790894\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7104, 0.6416, 0.7162, 0.6261, 0.7441, 0.6863, 0.6798, 0.6416, 0.6521,\n",
      "        0.7023, 0.6919], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0097, -0.0281,  0.1707, -0.0100,  0.0895, -0.0342, -0.0114,  0.0374,\n",
      "         0.0839,  0.0664], grad_fn=<AddBackward0>)\n",
      "tensor(0.3740, grad_fn=<SumBackward0>)\n",
      "Epoch 302 loss is 0.37399446964263916\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6538, 0.7067, 0.6918, 0.6821, 0.6380, 0.6928, 0.6823, 0.7243, 0.6512,\n",
      "        0.6476, 0.7185], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0633,  0.0471, -0.0229,  0.0016,  0.0004,  0.1439, -0.0139, -0.0116,\n",
      "        -0.0020,  0.1121], grad_fn=<AddBackward0>)\n",
      "tensor(0.3182, grad_fn=<SumBackward0>)\n",
      "Epoch 303 loss is 0.318200945854187\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6827, 0.6715, 0.6662, 0.6798, 0.7306, 0.7955, 0.5947, 0.7384, 0.6647,\n",
      "        0.6581, 0.6579], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0055, -0.0010,  0.0985,  0.2155, -0.0284,  0.0131, -0.0436,  0.1056,\n",
      "        -0.0269, -0.0023], grad_fn=<AddBackward0>)\n",
      "tensor(0.3251, grad_fn=<SumBackward0>)\n",
      "Epoch 304 loss is 0.32513123750686646\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7296, 0.7277, 0.7388, 0.6766, 0.6962, 0.6363, 0.6278, 0.6382, 0.6364,\n",
      "        0.6495, 0.7000], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0152, -0.0177, -0.0105, -0.0342, -0.0163, -0.0193,  0.0002,  0.0362,\n",
      "         0.1029,  0.1059], grad_fn=<AddBackward0>)\n",
      "tensor(0.1625, grad_fn=<SumBackward0>)\n",
      "Epoch 305 loss is 0.16252362728118896\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7143, 0.6409, 0.6021, 0.6367, 0.7331, 0.7611, 0.6688, 0.7044, 0.7893,\n",
      "        0.6465, 0.7344], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0374, -0.0259,  0.1536,  0.2650,  0.0534, -0.0096,  0.0470, -0.0074,\n",
      "         0.0500, -0.0183], grad_fn=<AddBackward0>)\n",
      "tensor(0.4705, grad_fn=<SumBackward0>)\n",
      "Epoch 306 loss is 0.47050243616104126\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6819, 0.6455, 0.6064, 0.6145, 0.7437, 0.6024, 0.6403, 0.6440, 0.6082,\n",
      "        0.6283, 0.6991], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0252, -0.0225,  0.1637, -0.0013,  0.0430, -0.0332,  0.0098, -0.0040,\n",
      "         0.0918,  0.1515], grad_fn=<AddBackward0>)\n",
      "tensor(0.3735, grad_fn=<SumBackward0>)\n",
      "Epoch 307 loss is 0.37349504232406616\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6939, 0.6006, 0.6528, 0.6375, 0.7769, 0.5923, 0.7504, 0.6335, 0.6192,\n",
      "        0.7780, 0.7716], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0137, -0.0188,  0.2939, -0.0202,  0.1881, -0.0478,  0.0448,  0.0461,\n",
      "         0.2301,  0.2539], grad_fn=<AddBackward0>)\n",
      "tensor(0.9565, grad_fn=<SumBackward0>)\n",
      "Epoch 308 loss is 0.9564561247825623\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6168, 0.7645, 0.6029, 0.7725, 0.5928, 0.5879, 0.7458, 0.8104, 0.5595,\n",
      "        0.7938, 0.5554], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0046,  0.2595, -0.0572, -0.0050, -0.0089,  0.3627, -0.0095,  0.0800,\n",
      "        -0.0850, -0.0014], grad_fn=<AddBackward0>)\n",
      "tensor(0.5306, grad_fn=<SumBackward0>)\n",
      "Epoch 309 loss is 0.5305503010749817\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7494, 0.9746, 0.5437, 0.9107, 0.8678, 0.8758, 0.6256, 0.7638, 0.5634,\n",
      "        0.5680, 0.7562], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0685,  0.2688, -0.0356,  0.5535, -0.0950, -0.0347, -0.1042, -0.0192,\n",
      "        -0.0025,  0.3213], grad_fn=<AddBackward0>)\n",
      "tensor(0.7839, grad_fn=<SumBackward0>)\n",
      "Epoch 310 loss is 0.7839325070381165\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7012, 0.7215, 0.7574, 0.6241, 0.8455, 0.8181, 0.7879, 0.5717, 0.6138,\n",
      "        0.6034, 0.5898], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0937, -0.0257,  0.2068,  0.1013,  0.2731, -0.0913, -0.0681, -0.0615,\n",
      "         0.0301, -0.0080], grad_fn=<AddBackward0>)\n",
      "tensor(0.4504, grad_fn=<SumBackward0>)\n",
      "Epoch 311 loss is 0.450361967086792\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7281, 0.7976, 0.5637, 0.8445, 0.5952, 0.7479, 0.7800, 0.5829, 0.5931,\n",
      "        0.7705, 0.7838], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0548,  0.1941, -0.0675,  0.3071, -0.0215, -0.0041, -0.0516, -0.0032,\n",
      "         0.3347,  0.3178], grad_fn=<AddBackward0>)\n",
      "tensor(0.9511, grad_fn=<SumBackward0>)\n",
      "Epoch 312 loss is 0.9511009454727173\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6958, 0.7045, 0.7666, 0.7909, 0.6006, 0.6573, 0.7261, 0.5966, 0.5949,\n",
      "        0.6018, 0.5918], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1181,  0.1586, -0.0346, -0.0364, -0.0216, -0.0014, -0.0208, -0.0414,\n",
      "        -0.0016, -0.0010], grad_fn=<AddBackward0>)\n",
      "tensor(0.1178, grad_fn=<SumBackward0>)\n",
      "Epoch 313 loss is 0.11781299114227295\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6752, 0.6432, 0.7885, 0.7553, 0.6390, 0.6129, 0.8598, 0.8251, 0.8346,\n",
      "        0.8149, 0.6049], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1888,  0.1334, -0.0014, -0.0585,  0.1742,  0.3100,  0.3696, -0.0149,\n",
      "        -0.0734, -0.0766], grad_fn=<AddBackward0>)\n",
      "tensor(0.9511, grad_fn=<SumBackward0>)\n",
      "Epoch 314 loss is 0.9510949850082397\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7244, 0.6890, 0.6875, 0.6877, 0.6751, 0.6865, 0.6733, 0.7576, 0.7387,\n",
      "        0.6231, 0.7427], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0123, -0.0122, -0.0046, -0.0003, -0.0048,  0.1374,  0.0869, -0.0167,\n",
      "        -0.0050,  0.0067], grad_fn=<AddBackward0>)\n",
      "tensor(0.1751, grad_fn=<SumBackward0>)\n",
      "Epoch 315 loss is 0.1750788688659668\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6934, 0.6406, 0.6585, 0.6607, 0.7049, 0.6554, 0.7371, 0.6561, 0.6812,\n",
      "        0.6563, 0.6592], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0116, -0.0109,  0.1072, -0.0010,  0.1272, -0.0163,  0.0430, -0.0269,\n",
      "         0.0052, -0.0073], grad_fn=<AddBackward0>)\n",
      "tensor(0.2085, grad_fn=<SumBackward0>)\n",
      "Epoch 316 loss is 0.20849978923797607\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8008, 0.7003, 0.7231, 0.6596, 0.6738, 0.6567, 0.6746, 0.6956, 0.7096,\n",
      "        0.6953, 0.7596], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0259, -0.0471, -0.0088, -0.0221,  0.0251,  0.0363,  0.0881,  0.0345,\n",
      "         0.1066,  0.0833], grad_fn=<AddBackward0>)\n",
      "tensor(0.2700, grad_fn=<SumBackward0>)\n",
      "Epoch 317 loss is 0.27003031969070435\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6389, 0.6264, 0.7522, 0.6172, 0.6401, 0.5961, 0.6267, 0.6169, 0.6264,\n",
      "        0.6151, 0.7531], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1888, -0.0072,  0.0228, -0.0520,  0.0158, -0.0077,  0.0505, -0.0039,\n",
      "         0.2270,  0.2112], grad_fn=<AddBackward0>)\n",
      "tensor(0.6453, grad_fn=<SumBackward0>)\n",
      "Epoch 318 loss is 0.6453198790550232\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5762, 0.6155, 0.6641, 0.6222, 0.7589, 0.7900, 0.7627, 0.7847, 0.8001,\n",
      "        0.7741, 0.5953], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1466,  0.0767,  0.2390,  0.2098,  0.2342,  0.0429,  0.0168,  0.0190,\n",
      "        -0.0631, -0.0683], grad_fn=<AddBackward0>)\n",
      "tensor(0.8537, grad_fn=<SumBackward0>)\n",
      "Epoch 319 loss is 0.853664755821228\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.3286, 0.7454, 0.6789, 0.7649, 0.6661, 0.6126, 0.7726, 0.6517, 0.6022,\n",
      "        0.8057, 0.5716], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.5839,  0.7271, -0.0265, -0.0221,  0.0129, -0.0048, -0.0035,  0.0551,\n",
      "        -0.0267, -0.0102], grad_fn=<AddBackward0>)\n",
      "tensor(1.2853, grad_fn=<SumBackward0>)\n",
      "Epoch 320 loss is 1.285302758216858\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5732, 0.5592, 0.5880, 0.5614, 0.8037, 0.6228, 0.8269, 0.8519, 0.8400,\n",
      "        0.5331, 0.8436], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0247, -0.0039,  0.4076,  0.0581,  0.4425,  0.0803,  0.3620, -0.0979,\n",
      "        -0.0028,  0.0060], grad_fn=<AddBackward0>)\n",
      "tensor(1.2766, grad_fn=<SumBackward0>)\n",
      "Epoch 321 loss is 1.2765566110610962\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5119, 0.5208, 0.6366, 0.8468, 0.5424, 0.5765, 0.8614, 0.5740, 0.8038,\n",
      "        0.8620, 0.5259], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2078,  0.5581,  0.0360, -0.0200,  0.0245,  0.0528,  0.3789,  0.0010,\n",
      "        -0.0161, -0.0927], grad_fn=<AddBackward0>)\n",
      "tensor(1.1303, grad_fn=<SumBackward0>)\n",
      "Epoch 322 loss is 1.1303495168685913\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4973, 0.8881, 0.5351, 0.5410, 0.8135, 0.5870, 0.8430, 0.8688, 0.8652,\n",
      "        0.5509, 0.5798], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0631,  0.0729, -0.0249,  0.0865,  0.5033,  0.0923,  0.4636, -0.0974,\n",
      "        -0.0963, -0.0951], grad_fn=<AddBackward0>)\n",
      "tensor(0.9679, grad_fn=<SumBackward0>)\n",
      "Epoch 323 loss is 0.9679264426231384\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5307, 0.5389, 0.8330, 0.8726, 0.5092, 0.5391, 0.5576, 0.5289, 0.5937,\n",
      "        0.8297, 0.8379], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.5039,  0.5699, -0.0099, -0.0980, -0.1050,  0.0327,  0.0911,  0.4535,\n",
      "         0.5151,  0.4069], grad_fn=<AddBackward0>)\n",
      "tensor(2.3602, grad_fn=<SumBackward0>)\n",
      "Epoch 324 loss is 2.3602373600006104\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9113, 0.8459, 0.8749, 0.8412, 0.5446, 0.5238, 0.9364, 0.5306, 0.8852,\n",
      "        0.8846, 0.9003], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0121, -0.0234, -0.1004, -0.1170,  0.1587, -0.0047,  0.6023, -0.0173,\n",
      "         0.6162,  0.0252], grad_fn=<AddBackward0>)\n",
      "tensor(1.1276, grad_fn=<SumBackward0>)\n",
      "Epoch 325 loss is 1.1275641918182373\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9383, 0.4948, 0.5146, 0.9075, 0.5678, 0.8964, 0.5461, 0.8963, 0.8764,\n",
      "        0.5533, 0.8930], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1412, -0.0103,  0.1217,  0.6363, -0.1204,  0.5475, -0.0067,  0.0120,\n",
      "        -0.0011,  0.0277], grad_fn=<AddBackward0>)\n",
      "tensor(1.0654, grad_fn=<SumBackward0>)\n",
      "Epoch 326 loss is 1.0654020309448242\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4915, 0.5546, 0.8254, 0.8946, 0.5227, 0.5600, 0.8101, 0.5542, 0.8916,\n",
      "        0.8721, 0.8852], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.5564,  0.6718, -0.0106, -0.0885, -0.0281,  0.0526,  0.5527,  0.1032,\n",
      "         0.5517, -0.0021], grad_fn=<AddBackward0>)\n",
      "tensor(2.3590, grad_fn=<SumBackward0>)\n",
      "Epoch 327 loss is 2.3590331077575684\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5279, 0.8320, 0.8322, 0.5477, 0.8834, 0.8441, 0.8143, 0.8304, 0.8811,\n",
      "        0.5708, 0.8750], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.5072,  0.0330,  0.0857,  0.0197,  0.4444, -0.0177,  0.0617, -0.0812,\n",
      "         0.0743, -0.0020], grad_fn=<AddBackward0>)\n",
      "tensor(1.1252, grad_fn=<SumBackward0>)\n",
      "Epoch 328 loss is 1.1251599788665771\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8493, 0.7835, 0.7718, 0.8108, 0.7995, 0.8212, 0.5938, 0.6096, 0.6329,\n",
      "        0.8345, 0.5845], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0258, -0.0128,  0.0265,  0.0823, -0.0723, -0.0633, -0.0628,  0.4012,\n",
      "        -0.0084, -0.0161], grad_fn=<AddBackward0>)\n",
      "tensor(0.2484, grad_fn=<SumBackward0>)\n",
      "Epoch 329 loss is 0.2484096884727478\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.3691, 0.7412, 0.6626, 0.6775, 0.7328, 0.7536, 0.6367, 0.7435, 0.6057,\n",
      "        0.6564, 0.7290], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4892,  0.5139, -0.0028,  0.1517, -0.0136,  0.0177, -0.0493,  0.0328,\n",
      "        -0.0048,  0.2055], grad_fn=<AddBackward0>)\n",
      "tensor(1.3403, grad_fn=<SumBackward0>)\n",
      "Epoch 330 loss is 1.3403232097625732\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5634, 0.6524, 0.7516, 0.7363, 0.6757, 0.7255, 0.6365, 0.6979, 0.7215,\n",
      "        0.7488, 0.7299], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.3137,  0.2882,  0.0387, -0.0087, -0.0333,  0.0370, -0.0013,  0.1871,\n",
      "         0.0534,  0.0140], grad_fn=<AddBackward0>)\n",
      "tensor(0.8888, grad_fn=<SumBackward0>)\n",
      "Epoch 331 loss is 0.8888477683067322\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7176, 0.7329, 0.7486, 0.6418, 0.6742, 0.6866, 0.6420, 0.7619, 0.6205,\n",
      "        0.7486, 0.7543], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0516, -0.0253, -0.0195, -0.0207,  0.0004,  0.1461, -0.0220,  0.1777,\n",
      "        -0.0025,  0.2230], grad_fn=<AddBackward0>)\n",
      "tensor(0.5087, grad_fn=<SumBackward0>)\n",
      "Epoch 332 loss is 0.5086929202079773\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6641, 0.6339, 0.8318, 0.5901, 0.8569, 0.7936, 0.6004, 0.6064, 0.6016,\n",
      "        0.6090, 0.7178], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2795, -0.0247,  0.3718, -0.0127,  0.0171, -0.0835, -0.0640,  0.0144,\n",
      "         0.1857,  0.1937], grad_fn=<AddBackward0>)\n",
      "tensor(0.8772, grad_fn=<SumBackward0>)\n",
      "Epoch 333 loss is 0.8772449493408203\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7373, 0.5709, 0.6035, 0.8293, 0.5204, 0.5363, 0.8515, 0.5879, 0.5646,\n",
      "        0.7971, 0.5819], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0446,  0.1534, -0.0168, -0.0224,  0.0369,  0.1124,  0.0473, -0.0181,\n",
      "        -0.0020,  0.0288], grad_fn=<AddBackward0>)\n",
      "tensor(0.2748, grad_fn=<SumBackward0>)\n",
      "Epoch 334 loss is 0.2748185396194458\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8233, 0.9093, 0.9622, 0.5324, 0.5326, 0.5170, 0.5195, 0.8980, 0.9973,\n",
      "        0.5169, 0.5362], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2315, -0.0970, -0.1256, -0.1484, -0.0043,  0.6090,  0.8006, -0.0009,\n",
      "        -0.1206, -0.1537], grad_fn=<AddBackward0>)\n",
      "tensor(0.9906, grad_fn=<SumBackward0>)\n",
      "Epoch 335 loss is 0.9906376600265503\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5490, 0.9498, 1.0032, 0.9369, 0.4910, 0.5129, 0.8875, 0.4941, 1.0003,\n",
      "        0.9827, 1.0704], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.7571,  0.6466, -0.1529, -0.1635, -0.0165,  0.0052,  0.8124,  0.1587,\n",
      "         0.9605,  0.1168], grad_fn=<AddBackward0>)\n",
      "tensor(3.1245, grad_fn=<SumBackward0>)\n",
      "Epoch 336 loss is 3.1244595050811768\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8651, 0.9068, 0.9448, 0.4882, 0.9337, 0.4873, 0.4436, 0.4621, 0.9307,\n",
      "        0.5186, 0.5068], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1329, -0.1256,  0.0447, -0.1525, -0.0149, -0.1572,  0.7389,  0.1250,\n",
      "         0.0745, -0.1413], grad_fn=<AddBackward0>)\n",
      "tensor(0.5246, grad_fn=<SumBackward0>)\n",
      "Epoch 337 loss is 0.5246259570121765\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5340, 0.4757, 0.4520, 0.9472, 0.4701, 0.9543, 0.4886, 0.9117, 0.4775,\n",
      "        0.9811, 0.8992], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0273,  0.6886, -0.0019,  0.8372, -0.1529,  0.7361, -0.1589,  0.8210,\n",
      "        -0.0042,  0.7029], grad_fn=<AddBackward0>)\n",
      "tensor(3.4406, grad_fn=<SumBackward0>)\n",
      "Epoch 338 loss is 3.440596103668213\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5626, 0.5132, 0.4756, 0.4775, 0.4925, 0.4837, 0.4609, 0.4914, 0.5081,\n",
      "        0.9691, 0.9444], grad_fn=<ViewBackward0>)\n",
      "tensor([-2.8972e-02, -2.8354e-02, -6.8820e-03,  1.3479e-02, -5.5482e-03,\n",
      "        -3.6886e-04,  4.0559e-02,  8.4704e-01,  7.5487e-01,  7.2716e-01],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(2.3130, grad_fn=<SumBackward0>)\n",
      "Epoch 339 loss is 2.312990188598633\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6578, 1.1648, 0.4056, 0.4250, 1.0058, 0.9677, 0.4700, 0.4506, 0.9288,\n",
      "        0.9516, 0.9500], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0841, -0.0776, -0.0530,  0.9369,  0.0751, -0.1851, -0.0130,  0.8027,\n",
      "         0.8323,  0.0354], grad_fn=<AddBackward0>)\n",
      "tensor(2.2696, grad_fn=<SumBackward0>)\n",
      "Epoch 340 loss is 2.269571304321289\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8770, 0.4863, 0.5070, 0.4959, 0.4865, 0.9028, 0.9080, 0.9508, 0.4807,\n",
      "        0.9493, 0.9198], grad_fn=<ViewBackward0>)\n",
      "tensor([-1.2336e-01, -1.2705e-01,  2.8849e-04,  6.5980e-01,  6.8681e-01,\n",
      "         7.7383e-01, -1.4073e-01,  6.8858e-02, -1.0335e-02,  7.3190e-01],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(2.5200, grad_fn=<SumBackward0>)\n",
      "Epoch 341 loss is 2.520020008087158\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5947, 0.5214, 0.8801, 0.8715, 0.8962, 0.5159, 0.8578, 0.8551, 0.9063,\n",
      "        0.5423, 0.5349], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4757,  0.4613,  0.6248, -0.1214, -0.0046, -0.0137,  0.6507, -0.1052,\n",
      "        -0.1067, -0.1238], grad_fn=<AddBackward0>)\n",
      "tensor(1.7371, grad_fn=<SumBackward0>)\n",
      "Epoch 342 loss is 1.7371116876602173\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8143, 0.8215, 0.5784, 0.5423, 0.5533, 0.5474, 0.9172, 0.5244, 0.8895,\n",
      "        0.5432, 0.5412], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0786, -0.0907, -0.0894, -0.0103,  0.6248, -0.0096,  0.5702, -0.1247,\n",
      "         0.0280, -0.1161], grad_fn=<AddBackward0>)\n",
      "tensor(0.7036, grad_fn=<SumBackward0>)\n",
      "Epoch 343 loss is 0.7035682201385498\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7532, 0.5745, 0.5859, 0.8244, 0.8762, 0.8443, 0.7988, 0.5496, 0.8645,\n",
      "        0.5624, 0.8528], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0558,  0.1186,  0.5029,  0.4306, -0.0086, -0.1089,  0.0336, -0.0788,\n",
      "         0.5054, -0.0039], grad_fn=<AddBackward0>)\n",
      "tensor(1.3353, grad_fn=<SumBackward0>)\n",
      "Epoch 344 loss is 1.3353259563446045\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6995, 0.6226, 0.8004, 0.7907, 0.5477, 0.5386, 0.5900, 0.5706, 0.7979,\n",
      "        0.5764, 0.5804], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1682,  0.1520, -0.0250, -0.0873, -0.0669,  0.0381,  0.4323, -0.0045,\n",
      "         0.0163, -0.0725], grad_fn=<AddBackward0>)\n",
      "tensor(0.5507, grad_fn=<SumBackward0>)\n",
      "Epoch 345 loss is 0.5507459044456482\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6629, 0.6204, 0.7739, 0.7536, 0.8208, 0.6459, 0.7727, 0.6094, 0.8119,\n",
      "        0.5694, 0.5909], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1849,  0.1511,  0.3340, -0.0426,  0.0318, -0.0705,  0.2766, -0.0677,\n",
      "        -0.0062, -0.0737], grad_fn=<AddBackward0>)\n",
      "tensor(0.7176, grad_fn=<SumBackward0>)\n",
      "Epoch 346 loss is 0.7176409363746643\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7250, 0.6730, 0.7058, 0.6822, 0.7862, 0.8367, 0.6843, 0.6709, 0.7442,\n",
      "        0.6218, 0.7672], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0064, -0.0143,  0.1886,  0.2182,  0.0035, -0.0384, -0.0308, -0.0208,\n",
      "         0.1606,  0.0384], grad_fn=<AddBackward0>)\n",
      "tensor(0.4985, grad_fn=<SumBackward0>)\n",
      "Epoch 347 loss is 0.4985108971595764\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6403, 0.7088, 0.7537, 0.6570, 0.6625, 0.6451, 0.6511, 0.6915, 0.7299,\n",
      "        0.7382, 0.7794], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1890,  0.0279, -0.0155, -0.0362, -0.0020,  0.0485,  0.1413,  0.1452,\n",
      "         0.1465,  0.0826], grad_fn=<AddBackward0>)\n",
      "tensor(0.7274, grad_fn=<SumBackward0>)\n",
      "Epoch 348 loss is 0.7273863554000854\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7827, 0.7098, 0.7020, 0.7272, 0.6478, 0.6891, 0.6472, 0.6827, 0.7247,\n",
      "        0.6054, 0.6315], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0269, -0.0185, -0.0207, -0.0043, -0.0267,  0.0581,  0.0594, -0.0139,\n",
      "        -0.0171, -0.0311], grad_fn=<AddBackward0>)\n",
      "tensor(-0.0417, grad_fn=<SumBackward0>)\n",
      "Epoch 349 loss is -0.04166358709335327\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4135, 0.6724, 0.6984, 0.6226, 0.5740, 0.7314, 0.6381, 0.8196, 0.5512,\n",
      "        0.5693, 0.8003], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4748,  0.3485, -0.0328,  0.0550,  0.0259,  0.4094, -0.0600, -0.0230,\n",
      "        -0.0064,  0.4151], grad_fn=<AddBackward0>)\n",
      "tensor(1.6064, grad_fn=<SumBackward0>)\n",
      "Epoch 350 loss is 1.6063814163208008\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5499, 0.8327, 0.5644, 0.5331, 0.5996, 0.8283, 0.8200, 0.6232, 0.5964,\n",
      "        0.5675, 0.8088], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0242, -0.0056, -0.0777,  0.4397,  0.4781,  0.0394, -0.0773, -0.0842,\n",
      "         0.3094,  0.3540], grad_fn=<AddBackward0>)\n",
      "tensor(1.4001, grad_fn=<SumBackward0>)\n",
      "Epoch 351 loss is 1.4000540971755981\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9231, 0.8313, 0.8532, 0.8875, 0.5387, 0.5566, 0.5704, 0.5279, 0.8982,\n",
      "        0.8780, 0.5809], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0233, -0.0119, -0.0975, -0.0989, -0.1057, -0.0036,  0.5694,  0.5126,\n",
      "         0.0883, -0.1058], grad_fn=<AddBackward0>)\n",
      "tensor(0.7237, grad_fn=<SumBackward0>)\n",
      "Epoch 352 loss is 0.7236909866333008\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9341, 0.5063, 0.5780, 0.8409, 0.8480, 0.5204, 0.5038, 0.8657, 0.5534,\n",
      "        0.8689, 0.8750], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1187, -0.0311,  0.5694, -0.0192, -0.1124,  0.0295,  0.0550,  0.6085,\n",
      "         0.0155,  0.5359], grad_fn=<AddBackward0>)\n",
      "tensor(1.5325, grad_fn=<SumBackward0>)\n",
      "Epoch 353 loss is 1.5325255393981934\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9560, 0.8995, 0.5511, 0.5036, 0.5821, 0.5318, 0.8642, 0.5412, 0.5426,\n",
      "        0.5265, 0.5028], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1350, -0.1508, -0.1058, -0.0064,  0.6010, -0.0136,  0.0180, -0.1126,\n",
      "        -0.0128, -0.0133], grad_fn=<AddBackward0>)\n",
      "tensor(0.0687, grad_fn=<SumBackward0>)\n",
      "Epoch 354 loss is 0.06869840621948242\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4969, 0.5176, 0.9411, 0.4970, 0.8995, 0.9457, 0.9086, 0.4779, 0.9306,\n",
      "        0.9461, 0.9310], grad_fn=<ViewBackward0>)\n",
      "tensor([ 7.4030e-01,  1.1474e-04,  6.3644e-01,  7.6330e-03,  6.8613e-01,\n",
      "        -1.4051e-01, -5.0231e-03,  6.2397e-02,  7.5509e-01,  6.5535e-04],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(2.7432, grad_fn=<SumBackward0>)\n",
      "Epoch 355 loss is 2.7432303428649902\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9469, 0.9005, 0.9129, 0.9267, 0.9241, 0.5489, 0.8565, 0.5568, 0.5196,\n",
      "        0.8963, 0.8547], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0113, -0.0067,  0.0393, -0.1214, -0.0234, -0.1224, -0.0098,  0.0663,\n",
      "         0.4964,  0.5584], grad_fn=<AddBackward0>)\n",
      "tensor(0.8654, grad_fn=<SumBackward0>)\n",
      "Epoch 356 loss is 0.865426242351532\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8832, 0.9504, 0.9388, 0.9196, 0.5233, 0.8842, 0.5440, 0.8109, 0.5565,\n",
      "        0.5067, 0.4879], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0927,  0.0607, -0.1424, -0.0182, -0.1252,  0.4793, -0.1093, -0.0124,\n",
      "        -0.1077, -0.0229], grad_fn=<AddBackward0>)\n",
      "tensor(0.0948, grad_fn=<SumBackward0>)\n",
      "Epoch 357 loss is 0.09481900930404663\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5222, 0.9191, 0.9124, 0.8536, 0.5569, 0.5107, 0.6435, 0.5554, 0.8909,\n",
      "        0.5721, 0.5639], grad_fn=<ViewBackward0>)\n",
      "tensor([ 6.5029e-01,  5.5239e-01, -1.2072e-01, -1.3389e-01, -7.0026e-02,\n",
      "        -4.8012e-04,  6.3370e-01, -2.3810e-02,  1.4046e-02, -1.0901e-01],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(1.3925, grad_fn=<SumBackward0>)\n",
      "Epoch 358 loss is 1.3924909830093384\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5598, 0.5913, 0.5958, 0.5528, 0.5238, 0.5349, 0.8552, 0.5396, 0.8292,\n",
      "        0.8235, 0.8754], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0601, -0.0023, -0.0225, -0.0203,  0.5040,  0.0263,  0.4903, -0.0106,\n",
      "         0.5597,  0.0771], grad_fn=<AddBackward0>)\n",
      "tensor(1.6619, grad_fn=<SumBackward0>)\n",
      "Epoch 359 loss is 1.6618529558181763\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.3672, 0.6822, 0.6440, 0.5802, 0.5882, 0.8443, 0.5845, 0.8045, 0.7539,\n",
      "        0.7403, 0.7560], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4613,  0.3549, -0.0313,  0.3337,  0.0071,  0.3604, -0.0301,  0.2598,\n",
      "        -0.0162,  0.0035], grad_fn=<AddBackward0>)\n",
      "tensor(1.7033, grad_fn=<SumBackward0>)\n",
      "Epoch 360 loss is 1.7032692432403564\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8084, 0.7309, 0.7364, 0.7208, 0.6644, 0.5967, 0.6656, 0.5794, 0.7464,\n",
      "        0.7085, 0.6313], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0240, -0.0292, -0.0222, -0.0466, -0.0184, -0.0283,  0.2496,  0.0715,\n",
      "         0.0865, -0.0383], grad_fn=<AddBackward0>)\n",
      "tensor(0.2006, grad_fn=<SumBackward0>)\n",
      "Epoch 361 loss is 0.2005554437637329\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7594, 0.7205, 0.6267, 0.6008, 0.7321, 0.7127, 0.7433, 0.6659, 0.5797,\n",
      "        0.6700, 0.6494], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0442, -0.0528,  0.0193,  0.1433,  0.2374, -0.0220, -0.0443, -0.0244,\n",
      "        -0.0055,  0.1161], grad_fn=<AddBackward0>)\n",
      "tensor(0.3227, grad_fn=<SumBackward0>)\n",
      "Epoch 362 loss is 0.32265836000442505\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7701, 0.6214, 0.6849, 0.7113, 0.6801, 0.7049, 0.6381, 0.6492, 0.7305,\n",
      "        0.7261, 0.6524], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0284, -0.0196,  0.0979,  0.0334, -0.0244, -0.0103,  0.0426,  0.1465,\n",
      "         0.0054, -0.0260], grad_fn=<AddBackward0>)\n",
      "tensor(0.2171, grad_fn=<SumBackward0>)\n",
      "Epoch 363 loss is 0.21710455417633057\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7495, 0.6260, 0.6940, 0.7453, 0.6894, 0.6997, 0.6753, 0.6603, 0.6786,\n",
      "        0.7367, 0.6943], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0185, -0.0014,  0.1057,  0.0094, -0.0233, -0.0097, -0.0070,  0.1022,\n",
      "         0.0566,  0.0261], grad_fn=<AddBackward0>)\n",
      "tensor(0.2402, grad_fn=<SumBackward0>)\n",
      "Epoch 364 loss is 0.24019336700439453\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6854, 0.6456, 0.6876, 0.7089, 0.6839, 0.7348, 0.7068, 0.6833, 0.7254,\n",
      "        0.7404, 0.7000], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0038,  0.0392,  0.0640,  0.0786, -0.0007, -0.0002, -0.0031,  0.0560,\n",
      "         0.0278, -0.0084], grad_fn=<AddBackward0>)\n",
      "tensor(0.2568, grad_fn=<SumBackward0>)\n",
      "Epoch 365 loss is 0.25684112310409546\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6353, 0.6669, 0.7048, 0.6112, 0.6825, 0.7571, 0.6857, 0.6854, 0.7543,\n",
      "        0.7568, 0.7039], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1157, -0.0081,  0.0260,  0.0873,  0.1242,  0.0048, -0.0009,  0.1185,\n",
      "         0.0309, -0.0168], grad_fn=<AddBackward0>)\n",
      "tensor(0.4816, grad_fn=<SumBackward0>)\n",
      "Epoch 366 loss is 0.48157066106796265\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6897, 0.6671, 0.6834, 0.6350, 0.6737, 0.5783, 0.5979, 0.7701, 0.7985,\n",
      "        0.7790, 0.6041], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0021, -0.0183,  0.0110, -0.0350, -0.0124,  0.1606,  0.3671,  0.3018,\n",
      "        -0.0553, -0.0648], grad_fn=<AddBackward0>)\n",
      "tensor(0.6526, grad_fn=<SumBackward0>)\n",
      "Epoch 367 loss is 0.6525911092758179\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7041, 0.6861, 0.7699, 0.6484, 0.6252, 0.6436, 0.7775, 0.5863, 0.6310,\n",
      "        0.6133, 0.6266], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1096, -0.0186, -0.0203, -0.0421,  0.2151, -0.0130, -0.0042, -0.0547,\n",
      "         0.0672, -0.0015], grad_fn=<AddBackward0>)\n",
      "tensor(0.2376, grad_fn=<SumBackward0>)\n",
      "Epoch 368 loss is 0.2375706434249878\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6804, 0.6744, 0.6591, 0.7610, 0.7718, 0.6293, 0.6133, 0.5983, 0.7867,\n",
      "        0.7853, 0.7595], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0071,  0.1344,  0.1624, -0.0099, -0.0492, -0.0579,  0.2622,  0.2866,\n",
      "         0.2687, -0.0091], grad_fn=<AddBackward0>)\n",
      "tensor(0.9812, grad_fn=<SumBackward0>)\n",
      "Epoch 369 loss is 0.9811848402023315\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8174, 0.4888, 0.5318, 0.8293, 0.7792, 0.6052, 0.7497, 0.6135, 0.5814,\n",
      "        0.5607, 0.5882], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0952,  0.0197,  0.4840,  0.1224, -0.0265, -0.0552, -0.0079, -0.0630,\n",
      "        -0.0084,  0.0113], grad_fn=<AddBackward0>)\n",
      "tensor(0.3811, grad_fn=<SumBackward0>)\n",
      "Epoch 370 loss is 0.3810933232307434\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6359, 0.6309, 0.5676, 0.5812, 0.6056, 0.8005, 0.8137, 0.7406, 0.6241,\n",
      "        0.5825, 0.7578], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0228, -0.0182, -0.0084,  0.3883,  0.3875,  0.2251, -0.0588, -0.0771,\n",
      "         0.0286,  0.2228], grad_fn=<AddBackward0>)\n",
      "tensor(1.0670, grad_fn=<SumBackward0>)\n",
      "Epoch 371 loss is 1.067040205001831\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7188, 0.7998, 0.5578, 0.5628, 0.5610, 0.7788, 0.8606, 0.6145, 0.8415,\n",
      "        0.8036, 0.7843], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0537, -0.0520, -0.0796,  0.3683,  0.4965,  0.0891,  0.1044, -0.0190,\n",
      "         0.2831, -0.0190], grad_fn=<AddBackward0>)\n",
      "tensor(1.1181, grad_fn=<SumBackward0>)\n",
      "Epoch 372 loss is 1.118062973022461\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6363, 0.6157, 0.5987, 0.7469, 0.5991, 0.5821, 0.8225, 0.7819, 0.6072,\n",
      "        0.8105, 0.8842], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0125,  0.1843, -0.0055, -0.0056,  0.1260,  0.3046,  0.0418, -0.0040,\n",
      "         0.1705,  0.4616], grad_fn=<AddBackward0>)\n",
      "tensor(1.2613, grad_fn=<SumBackward0>)\n",
      "Epoch 373 loss is 1.261289358139038\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8004, 0.5747, 0.6103, 0.5604, 0.8028, 0.8574, 0.9448, 0.5890, 0.6097,\n",
      "        0.6258, 0.7865], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0634, -0.0800,  0.3800,  0.4118,  0.6407, -0.0713, -0.0826, -0.1064,\n",
      "         0.3292,  0.2947], grad_fn=<AddBackward0>)\n",
      "tensor(1.6529, grad_fn=<SumBackward0>)\n",
      "Epoch 374 loss is 1.6528706550598145\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7372, 0.7562, 0.7981, 0.8028, 0.8071, 0.6044, 0.6060, 0.7644, 0.8044,\n",
      "        0.6159, 0.6044], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1015,  0.1094,  0.0848, -0.0646, -0.0656, -0.0142,  0.3333,  0.0165,\n",
      "        -0.0534, -0.0667], grad_fn=<AddBackward0>)\n",
      "tensor(0.3810, grad_fn=<SumBackward0>)\n",
      "Epoch 375 loss is 0.3810480237007141\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6986, 0.7516, 0.7099, 0.6349, 0.6051, 0.6285, 0.7560, 0.7567, 0.6947,\n",
      "        0.7801, 0.6404], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0188, -0.0212, -0.0488, -0.0271,  0.2018,  0.2526,  0.1103,  0.0402,\n",
      "        -0.0388, -0.0181], grad_fn=<AddBackward0>)\n",
      "tensor(0.4697, grad_fn=<SumBackward0>)\n",
      "Epoch 376 loss is 0.4697234034538269\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7114, 0.6691, 0.6250, 0.6424, 0.6121, 0.6323, 0.6598, 0.7730, 0.6688,\n",
      "        0.6745, 0.6855], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0288, -0.0230, -0.0190,  0.0122,  0.0291,  0.2682,  0.0609,  0.0244,\n",
      "        -0.0292,  0.0278], grad_fn=<AddBackward0>)\n",
      "tensor(0.3226, grad_fn=<SumBackward0>)\n",
      "Epoch 377 loss is 0.32257795333862305\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6681, 0.6724, 0.7008, 0.6901, 0.7206, 0.6386, 0.6510, 0.6235, 0.7082,\n",
      "        0.7558, 0.6752], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0546,  0.0368,  0.0804, -0.0207, -0.0130, -0.0324,  0.1160,  0.1745,\n",
      "         0.0862, -0.0110], grad_fn=<AddBackward0>)\n",
      "tensor(0.4714, grad_fn=<SumBackward0>)\n",
      "Epoch 378 loss is 0.4713626503944397\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7572, 0.7580, 0.6677, 0.6619, 0.7513, 0.6202, 0.6852, 0.6381, 0.6869,\n",
      "        0.6756, 0.7134], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0299, -0.0318, -0.0022, -0.0158,  0.0388, -0.0377,  0.1111, -0.0032,\n",
      "         0.1255,  0.0442], grad_fn=<AddBackward0>)\n",
      "tensor(0.1989, grad_fn=<SumBackward0>)\n",
      "Epoch 379 loss is 0.19892537593841553\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9313, 0.8246, 0.7632, 0.7656, 0.7596, 0.7149, 0.7187, 0.7337, 0.7029,\n",
      "        0.6705, 0.6760], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0560, -0.0552, -0.0217, -0.0161, -0.0156, -0.0086, -0.0040, -0.0161,\n",
      "        -0.0192, -0.0089], grad_fn=<AddBackward0>)\n",
      "tensor(-0.2216, grad_fn=<SumBackward0>)\n",
      "Epoch 380 loss is -0.2215670347213745\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6078, 0.7530, 0.7585, 0.7315, 0.6995, 0.6789, 0.6882, 0.6890, 0.6654,\n",
      "        0.7291, 0.7230], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2512,  0.2062, -0.0178, -0.0266, -0.0145, -0.0035, -0.0045,  0.0682,\n",
      "         0.0568,  0.0960], grad_fn=<AddBackward0>)\n",
      "tensor(0.6116, grad_fn=<SumBackward0>)\n",
      "Epoch 381 loss is 0.6115903854370117\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7284, 0.7452, 0.6505, 0.6894, 0.7377, 0.7346, 0.6981, 0.7048, 0.7207,\n",
      "        0.6668, 0.6644], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0260, -0.0130, -0.0025,  0.1402,  0.0146, -0.0110, -0.0047, -0.0104,\n",
      "        -0.0135, -0.0187], grad_fn=<AddBackward0>)\n",
      "tensor(0.0550, grad_fn=<SumBackward0>)\n",
      "Epoch 382 loss is 0.0550389289855957\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6506, 0.6806, 0.6898, 0.6902, 0.6561, 0.6916, 0.6457, 0.6592, 0.6977,\n",
      "        0.6739, 0.7738], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0652,  0.0660, -0.0082,  0.0030, -0.0148,  0.0052,  0.0103,  0.0469,\n",
      "         0.1910,  0.1268], grad_fn=<AddBackward0>)\n",
      "tensor(0.4913, grad_fn=<SumBackward0>)\n",
      "Epoch 383 loss is 0.4912978410720825\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6629, 0.6418, 0.7590, 0.7141, 0.6805, 0.6922, 0.6606, 0.7559, 0.6719,\n",
      "        0.7043, 0.6743], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1602,  0.0854,  0.0645, -0.0223, -0.0178,  0.1258, -0.0068,  0.0729,\n",
      "        -0.0272,  0.0040], grad_fn=<AddBackward0>)\n",
      "tensor(0.4387, grad_fn=<SumBackward0>)\n",
      "Epoch 384 loss is 0.4386675953865051\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7316, 0.6956, 0.6682, 0.6720, 0.7369, 0.6542, 0.6705, 0.7178, 0.6526,\n",
      "        0.6663, 0.7141], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0211, -0.0199,  0.0689, -0.0047, -0.0005, -0.0064, -0.0005, -0.0014,\n",
      "        -0.0013,  0.1025], grad_fn=<AddBackward0>)\n",
      "tensor(0.1157, grad_fn=<SumBackward0>)\n",
      "Epoch 385 loss is 0.11566370725631714\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6861, 0.6906, 0.6654, 0.6575, 0.7161, 0.6263, 0.7961, 0.6202, 0.6218,\n",
      "        0.7846, 0.6968], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0069, -0.0095,  0.0425, -0.0130,  0.2310, -0.0320, -0.0015, -0.0038,\n",
      "         0.1276,  0.1250], grad_fn=<AddBackward0>)\n",
      "tensor(0.4595, grad_fn=<SumBackward0>)\n",
      "Epoch 386 loss is 0.4594753384590149\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7254, 0.7122, 0.5802, 0.6022, 0.7412, 0.7186, 0.7638, 0.6056, 0.7550,\n",
      "        0.7999, 0.6124], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0484, -0.0410,  0.0483,  0.2307,  0.2693, -0.0452,  0.0606,  0.0602,\n",
      "         0.0114, -0.0475], grad_fn=<AddBackward0>)\n",
      "tensor(0.4983, grad_fn=<SumBackward0>)\n",
      "Epoch 387 loss is 0.49825143814086914\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7530, 0.6426, 0.7404, 0.7333, 0.7768, 0.7355, 0.7600, 0.7761, 0.6095,\n",
      "        0.7575, 0.7468], grad_fn=<ViewBackward0>)\n",
      "tensor([-4.2079e-03, -6.5503e-03,  2.2358e-01, -1.6376e-03,  4.4500e-02,\n",
      "        -2.2602e-04, -4.2001e-02, -8.5711e-04, -9.7607e-03,  2.2896e-01],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.4318, grad_fn=<SumBackward0>)\n",
      "Epoch 388 loss is 0.43179869651794434\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7052, 0.6871, 0.7087, 0.6687, 0.7370, 0.6461, 0.6338, 0.6462, 0.6541,\n",
      "        0.6716, 0.6510], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0058, -0.0122,  0.0833, -0.0208, -0.0116, -0.0303,  0.0133,  0.0630,\n",
      "         0.0080, -0.0010], grad_fn=<AddBackward0>)\n",
      "tensor(0.0974, grad_fn=<SumBackward0>)\n",
      "Epoch 389 loss is 0.09736061096191406\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4363, 0.7582, 0.5781, 0.7485, 0.7661, 0.7014, 0.6904, 0.7294, 0.7079,\n",
      "        0.6500, 0.7202], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2363,  0.5203,  0.0132,  0.2056, -0.0194, -0.0122,  0.0108, -0.0135,\n",
      "        -0.0031,  0.0205], grad_fn=<AddBackward0>)\n",
      "tensor(0.9586, grad_fn=<SumBackward0>)\n",
      "Epoch 390 loss is 0.958617091178894\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6847, 0.6930, 0.7051, 0.7089, 0.6580, 0.6760, 0.6931, 0.6966, 0.7073,\n",
      "        0.6571, 0.6286], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0339,  0.0403, -0.0117, -0.0097, -0.0053,  0.0643,  0.0523, -0.0120,\n",
      "        -0.0227, -0.0262], grad_fn=<AddBackward0>)\n",
      "tensor(0.1032, grad_fn=<SumBackward0>)\n",
      "Epoch 391 loss is 0.10322648286819458\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6159, 0.6982, 0.6646, 0.6888, 0.6502, 0.6374, 0.6005, 0.7565, 0.7375,\n",
      "        0.7086, 0.6449], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0811,  0.1215, -0.0160, -0.0090, -0.0294,  0.1771,  0.1668,  0.1802,\n",
      "        -0.0372, -0.0309], grad_fn=<AddBackward0>)\n",
      "tensor(0.6041, grad_fn=<SumBackward0>)\n",
      "Epoch 392 loss is 0.6040955781936646\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6052, 0.7113, 0.7097, 0.6442, 0.7135, 0.6541, 0.6073, 0.6753, 0.7391,\n",
      "        0.7137, 0.7308], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1741,  0.0649,  0.0037, -0.0185, -0.0123, -0.0127,  0.1417,  0.1774,\n",
      "         0.0924, -0.0028], grad_fn=<AddBackward0>)\n",
      "tensor(0.6079, grad_fn=<SumBackward0>)\n",
      "Epoch 393 loss is 0.6079211235046387\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7805, 0.7465, 0.7126, 0.5992, 0.7690, 0.5879, 0.7591, 0.6544, 0.6866,\n",
      "        0.6423, 0.7277], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0226, -0.0604,  0.0376, -0.0416,  0.2664, -0.0382,  0.1644, -0.0389,\n",
      "         0.1222,  0.0685], grad_fn=<AddBackward0>)\n",
      "tensor(0.4573, grad_fn=<SumBackward0>)\n",
      "Epoch 394 loss is 0.45732223987579346\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5944, 0.8399, 0.6066, 0.7446, 0.6476, 0.7554, 0.8119, 0.7847, 0.7436,\n",
      "        0.5853, 0.7419], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0203,  0.2503, -0.0641,  0.2479,  0.1120,  0.2286, -0.0039, -0.0755,\n",
      "        -0.0143, -0.0006], grad_fn=<AddBackward0>)\n",
      "tensor(0.7008, grad_fn=<SumBackward0>)\n",
      "Epoch 395 loss is 0.700752317905426\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6103, 0.8075, 0.7623, 0.7709, 0.6004, 0.8090, 0.6889, 0.7590, 0.7690,\n",
      "        0.6446, 0.7354], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2533,  0.2675, -0.0690,  0.0778, -0.0273,  0.2643, -0.0133, -0.0148,\n",
      "        -0.0079, -0.0112], grad_fn=<AddBackward0>)\n",
      "tensor(0.7194, grad_fn=<SumBackward0>)\n",
      "Epoch 396 loss is 0.7194281816482544\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8094, 0.7537, 0.6356, 0.6475, 0.5899, 0.7145, 0.7138, 0.6411, 0.6674,\n",
      "        0.6562, 0.6122], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0579, -0.0540, -0.0546,  0.1315,  0.1105,  0.0854, -0.0157, -0.0192,\n",
      "        -0.0096, -0.0184], grad_fn=<AddBackward0>)\n",
      "tensor(0.0980, grad_fn=<SumBackward0>)\n",
      "Epoch 397 loss is 0.09803134202957153\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5491, 0.7670, 0.6302, 0.7466, 0.7531, 0.6595, 0.6205, 0.6830, 0.6976,\n",
      "        0.7893, 0.6096], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1351,  0.3292, -0.0046,  0.0489, -0.0420, -0.0234,  0.0634,  0.2812,\n",
      "        -0.0245, -0.0293], grad_fn=<AddBackward0>)\n",
      "tensor(0.7340, grad_fn=<SumBackward0>)\n",
      "Epoch 398 loss is 0.7340492010116577\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6057, 0.6214, 0.5921, 0.7290, 0.6352, 0.6086, 0.6274, 0.6226, 0.6572,\n",
      "        0.7098, 0.7816], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0046,  0.2054,  0.0231,  0.0276, -0.0339, -0.0042,  0.0810,  0.1372,\n",
      "         0.2649,  0.2072], grad_fn=<AddBackward0>)\n",
      "tensor(0.9039, grad_fn=<SumBackward0>)\n",
      "Epoch 399 loss is 0.9038996696472168\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.0193, 0.5957, 0.7315, 0.7120, 0.7180, 0.7334, 0.6482, 0.7116, 0.7869,\n",
      "        0.7758, 0.6508], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0959, -0.1024,  0.2038,  0.0032, -0.0213, -0.0021,  0.0891,  0.2127,\n",
      "        -0.0203, -0.0454], grad_fn=<AddBackward0>)\n",
      "tensor(0.2215, grad_fn=<SumBackward0>)\n",
      "Epoch 400 loss is 0.22145593166351318\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7631, 0.6658, 0.6590, 0.7107, 0.6728, 0.7396, 0.6122, 0.6504, 0.6289,\n",
      "        0.6037, 0.7334], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0347, -0.0175,  0.0116,  0.1344, -0.0328, -0.0075, -0.0369, -0.0029,\n",
      "         0.1383,  0.1742], grad_fn=<AddBackward0>)\n",
      "tensor(0.3263, grad_fn=<SumBackward0>)\n",
      "Epoch 401 loss is 0.32628190517425537\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7863, 0.6551, 0.6896, 0.7475, 0.7627, 0.5725, 0.6538, 0.7965, 0.7828,\n",
      "        0.7461, 0.7837], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0322, -0.0129,  0.1793, -0.0390, -0.0313,  0.0564,  0.3504,  0.1539,\n",
      "        -0.0042,  0.0016], grad_fn=<AddBackward0>)\n",
      "tensor(0.6219, grad_fn=<SumBackward0>)\n",
      "Epoch 402 loss is 0.6218627095222473\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7867, 0.6212, 0.7197, 0.6515, 0.6420, 0.6935, 0.6387, 0.7322, 0.6581,\n",
      "        0.7444, 0.6212], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0223, -0.0451,  0.0347, -0.0087, -0.0043,  0.1503, -0.0118,  0.1763,\n",
      "        -0.0370, -0.0123], grad_fn=<AddBackward0>)\n",
      "tensor(0.2198, grad_fn=<SumBackward0>)\n",
      "Epoch 403 loss is 0.21980804204940796\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6654, 0.6185, 0.6477, 0.7752, 0.6697, 0.6301, 0.7714, 0.6122, 0.6229,\n",
      "        0.6178, 0.7335], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0059,  0.1831,  0.0853, -0.0059, -0.0013, -0.0192, -0.0024, -0.0512,\n",
      "         0.2021,  0.1843], grad_fn=<AddBackward0>)\n",
      "tensor(0.5690, grad_fn=<SumBackward0>)\n",
      "Epoch 404 loss is 0.5690451264381409\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7615, 0.6609, 0.7470, 0.7219, 0.7086, 0.7167, 0.6438, 0.6389, 0.6598,\n",
      "        0.6036, 0.7185], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0048, -0.0132,  0.0796, -0.0101, -0.0260, -0.0233, -0.0190, -0.0134,\n",
      "         0.1327,  0.0978], grad_fn=<AddBackward0>)\n",
      "tensor(0.2002, grad_fn=<SumBackward0>)\n",
      "Epoch 405 loss is 0.20024621486663818\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7548, 0.7228, 0.7444, 0.6752, 0.6763, 0.6922, 0.7399, 0.7464, 0.6352,\n",
      "        0.7612, 0.7910], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0035, -0.0265, -0.0155, -0.0174,  0.1078,  0.1167, -0.0190,  0.0355,\n",
      "         0.0744,  0.2597], grad_fn=<AddBackward0>)\n",
      "tensor(0.5122, grad_fn=<SumBackward0>)\n",
      "Epoch 406 loss is 0.5122448205947876\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7634, 0.7219, 0.6652, 0.7026, 0.6832, 0.6590, 0.6939, 0.6847, 0.7159,\n",
      "        0.7201, 0.6264], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0327, -0.0203, -0.0129, -0.0021, -0.0029,  0.0026,  0.0950,  0.0436,\n",
      "        -0.0195, -0.0299], grad_fn=<AddBackward0>)\n",
      "tensor(0.0210, grad_fn=<SumBackward0>)\n",
      "Epoch 407 loss is 0.020960986614227295\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7630, 0.7349, 0.6992, 0.6396, 0.7127, 0.6592, 0.7006, 0.7234, 0.6442,\n",
      "        0.6214, 0.6988], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0213, -0.0411, -0.0074, -0.0133,  0.1016,  0.0179, -0.0050, -0.0264,\n",
      "        -0.0082,  0.0909], grad_fn=<AddBackward0>)\n",
      "tensor(0.0877, grad_fn=<SumBackward0>)\n",
      "Epoch 408 loss is 0.08771693706512451\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7538, 0.6381, 0.6453, 0.6721, 0.6661, 0.6959, 0.6954, 0.6730, 0.6912,\n",
      "        0.6558, 0.6533], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0362, -0.0272,  0.0465,  0.0844,  0.0388,  0.0116, -0.0016, -0.0132,\n",
      "        -0.0065, -0.0126], grad_fn=<AddBackward0>)\n",
      "tensor(0.0839, grad_fn=<SumBackward0>)\n",
      "Epoch 409 loss is 0.08391356468200684\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.0117, 0.5738, 0.7000, 0.6528, 0.6740, 0.6848, 0.6651, 0.6850, 0.6918,\n",
      "        0.7034, 0.6693], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1039, -0.1196,  0.1670, -0.0051,  0.0204,  0.0182,  0.0117,  0.0638,\n",
      "        -0.0052, -0.0075], grad_fn=<AddBackward0>)\n",
      "tensor(0.0399, grad_fn=<SumBackward0>)\n",
      "Epoch 410 loss is 0.03992593288421631\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7168, 0.6739, 0.6951, 0.7071, 0.7085, 0.6586, 0.6924, 0.6940, 0.6778,\n",
      "        0.6659, 0.6360], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0073, -0.0033,  0.0577, -0.0122, -0.0049, -0.0048,  0.0320, -0.0088,\n",
      "        -0.0193, -0.0139], grad_fn=<AddBackward0>)\n",
      "tensor(0.0152, grad_fn=<SumBackward0>)\n",
      "Epoch 411 loss is 0.015240132808685303\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7272, 0.6532, 0.6202, 0.7171, 0.6430, 0.6870, 0.7692, 0.6307, 0.6441,\n",
      "        0.6911, 0.6822], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0357, -0.0034, -0.0034,  0.1114,  0.0868, -0.0041, -0.0143, -0.0260,\n",
      "         0.0859,  0.0636], grad_fn=<AddBackward0>)\n",
      "tensor(0.2609, grad_fn=<SumBackward0>)\n",
      "Epoch 412 loss is 0.2608714699745178\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6764, 0.6192, 0.5893, 0.6184, 0.6279, 0.6953, 0.6291, 0.7173, 0.6237,\n",
      "        0.6498, 0.7711], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0291, -0.0193,  0.0145,  0.1768,  0.0178,  0.1490, -0.0239,  0.0345,\n",
      "         0.0896,  0.2456], grad_fn=<AddBackward0>)\n",
      "tensor(0.6554, grad_fn=<SumBackward0>)\n",
      "Epoch 413 loss is 0.6554385423660278\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7160, 0.7678, 0.5843, 0.8163, 0.5992, 0.8298, 0.6321, 0.6049, 0.7923,\n",
      "        0.5827, 0.8030], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0439,  0.1672, -0.0562,  0.4092, -0.0614,  0.0094, -0.0125, -0.0165,\n",
      "         0.3301,  0.0178], grad_fn=<AddBackward0>)\n",
      "tensor(0.7433, grad_fn=<SumBackward0>)\n",
      "Epoch 414 loss is 0.7432705163955688\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6876, 0.7248, 0.7691, 0.6017, 0.7486, 0.7169, 0.7875, 0.7252, 0.5668,\n",
      "        0.8249, 0.6456], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1359, -0.0286,  0.0396, -0.0174,  0.3096, -0.0078, -0.0500,  0.0624,\n",
      "        -0.0265,  0.1314], grad_fn=<AddBackward0>)\n",
      "tensor(0.5485, grad_fn=<SumBackward0>)\n",
      "Epoch 415 loss is 0.5485414266586304\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7600, 0.7677, 0.7498, 0.8154, 0.8247, 0.5573, 0.7678, 0.8310, 0.5644,\n",
      "        0.5650, 0.8550], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0034,  0.0923,  0.0950, -0.0642, -0.0159,  0.0106,  0.0119, -0.0676,\n",
      "         0.0399,  0.4843], grad_fn=<AddBackward0>)\n",
      "tensor(0.5829, grad_fn=<SumBackward0>)\n",
      "Epoch 416 loss is 0.5829176306724548\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6774, 0.6062, 0.8327, 0.5817, 0.8362, 0.7440, 0.8463, 0.8912, 0.5612,\n",
      "        0.8194, 0.7593], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2588, -0.0319,  0.3834, -0.0295,  0.4410,  0.0915, -0.0609, -0.0090,\n",
      "        -0.0439,  0.3302], grad_fn=<AddBackward0>)\n",
      "tensor(1.3296, grad_fn=<SumBackward0>)\n",
      "Epoch 417 loss is 1.3296252489089966\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6729, 0.5881, 0.5799, 0.7491, 0.6035, 0.7591, 0.7560, 0.7904, 0.9073,\n",
      "        0.5933, 0.7972], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0310,  0.1270,  0.0256,  0.2988,  0.0114,  0.3116,  0.2469, -0.0542,\n",
      "         0.0113, -0.0367], grad_fn=<AddBackward0>)\n",
      "tensor(0.9108, grad_fn=<SumBackward0>)\n",
      "Epoch 418 loss is 0.910808265209198\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7395, 0.7794, 0.6197, 0.7289, 0.6283, 0.6371, 0.7218, 0.6432, 0.7899,\n",
      "        0.7512, 0.6471], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0400, -0.0035, -0.0504,  0.0291, -0.0024,  0.0248,  0.2546,  0.0489,\n",
      "         0.0065, -0.0476], grad_fn=<AddBackward0>)\n",
      "tensor(0.2201, grad_fn=<SumBackward0>)\n",
      "Epoch 419 loss is 0.22011828422546387\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5407, 0.8268, 0.5716, 0.7225, 0.6916, 0.7176, 0.6999, 0.6996, 0.6413,\n",
      "        0.6718, 0.6730], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0515,  0.3030, -0.0451,  0.2432, -0.0075,  0.0133, -0.0254, -0.0094,\n",
      "        -0.0089,  0.0529], grad_fn=<AddBackward0>)\n",
      "tensor(0.5677, grad_fn=<SumBackward0>)\n",
      "Epoch 420 loss is 0.56772780418396\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6263, 0.6169, 0.7057, 0.6804, 0.7057, 0.6739, 0.7459, 0.6754, 0.7106,\n",
      "        0.7335, 0.6401], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1323,  0.0902,  0.1481, -0.0106,  0.1092, -0.0101,  0.0612, -0.0041,\n",
      "        -0.0117, -0.0235], grad_fn=<AddBackward0>)\n",
      "tensor(0.4809, grad_fn=<SumBackward0>)\n",
      "Epoch 421 loss is 0.48093312978744507\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8039, 0.7807, 0.6036, 0.7990, 0.7296, 0.7626, 0.6494, 0.6537, 0.6879,\n",
      "        0.6402, 0.6497], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0668, -0.0016, -0.0170,  0.2650, -0.0499, -0.0253, -0.0249, -0.0031,\n",
      "        -0.0013, -0.0127], grad_fn=<AddBackward0>)\n",
      "tensor(0.0624, grad_fn=<SumBackward0>)\n",
      "Epoch 422 loss is 0.06239861249923706\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5991, 0.6645, 0.6256, 0.6144, 0.5627, 0.8358, 0.8026, 0.7734, 0.5486,\n",
      "        0.8298, 0.6002], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0442,  0.0255, -0.0339,  0.3502,  0.3138,  0.3512, -0.0957,  0.0454,\n",
      "        -0.0577,  0.0859], grad_fn=<AddBackward0>)\n",
      "tensor(1.0288, grad_fn=<SumBackward0>)\n",
      "Epoch 423 loss is 1.028787612915039\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8418, 0.6122, 0.6206, 0.5726, 0.5385, 0.8842, 0.8317, 0.5783, 0.5555,\n",
      "        0.5587, 0.6362], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0737, -0.0897, -0.0246,  0.4394,  0.4317,  0.0663, -0.1096, -0.0910,\n",
      "         0.0966,  0.1345], grad_fn=<AddBackward0>)\n",
      "tensor(0.7799, grad_fn=<SumBackward0>)\n",
      "Epoch 424 loss is 0.7798770666122437\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4880, 0.4738, 0.8715, 0.5554, 0.4999, 0.4805, 0.9435, 0.8769, 0.4793,\n",
      "        0.9437, 0.8797], grad_fn=<ViewBackward0>)\n",
      "tensor([ 6.3931e-01,  1.1243e-01,  4.3486e-02, -1.3034e-01,  6.4678e-01,\n",
      "         6.2836e-01, -4.0281e-04,  3.2455e-04,  4.5571e-03,  6.6728e-01],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(2.6118, grad_fn=<SumBackward0>)\n",
      "Epoch 425 loss is 2.6117827892303467\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9277, 0.9293, 0.4553, 0.4910, 0.9813, 0.9174, 0.9332, 0.9076, 0.8833,\n",
      "        0.9082, 0.9542], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1575, -0.1456,  0.0867,  0.7702,  0.7369, -0.0246, -0.0114, -0.0083,\n",
      "         0.0776,  0.1182], grad_fn=<AddBackward0>)\n",
      "tensor(1.4424, grad_fn=<SumBackward0>)\n",
      "Epoch 426 loss is 1.4423515796661377\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9254, 0.9320, 0.4793, 0.4951, 0.8916, 0.9073, 0.5088, 0.5047, 0.9359,\n",
      "        0.4946, 0.4926], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1487, -0.1434, -0.0135,  0.7134,  0.0227, -0.1290,  0.0476, -0.0047,\n",
      "        -0.0040, -0.1478], grad_fn=<AddBackward0>)\n",
      "tensor(0.1927, grad_fn=<SumBackward0>)\n",
      "Epoch 427 loss is 0.19268584251403809\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9771, 1.0001, 0.5141, 0.9293, 0.4773, 0.9600, 0.5173, 0.5113, 1.0298,\n",
      "        0.5028, 0.9468], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1543, -0.0159, -0.1742,  0.7432, -0.1373,  0.0566,  0.1163, -0.0049,\n",
      "         0.7259, -0.0277], grad_fn=<AddBackward0>)\n",
      "tensor(1.1276, grad_fn=<SumBackward0>)\n",
      "Epoch 428 loss is 1.127565860748291\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4614, 0.9399, 0.4752, 0.4848, 0.5009, 0.9719, 0.4915, 0.4447, 0.9445,\n",
      "        0.5089, 0.4840], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0230,  0.0391, -0.1464,  0.8279,  0.0111, -0.0187, -0.0092,  0.0290,\n",
      "         0.0655, -0.1535], grad_fn=<AddBackward0>)\n",
      "tensor(0.6679, grad_fn=<SumBackward0>)\n",
      "Epoch 429 loss is 0.6679211854934692\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.2785, 0.8407, 0.5134, 0.9511, 0.9710, 0.4618, 0.9459, 0.4590, 0.9576,\n",
      "        0.9378, 0.4841], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.2550, -0.1091,  0.2173, -0.0172, -0.0017, -0.1707,  0.8264, -0.0027,\n",
      "         0.0418, -0.1578], grad_fn=<AddBackward0>)\n",
      "tensor(0.3712, grad_fn=<SumBackward0>)\n",
      "Epoch 430 loss is 0.3712430000305176\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9690, 0.8889, 0.5380, 0.5009, 0.4725, 0.5276, 0.9477, 0.4888, 0.4723,\n",
      "        0.9771, 0.4646], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1437, -0.1560, -0.1388, -0.0035,  0.7447,  0.0271, -0.0184,  0.0490,\n",
      "        -0.0081, -0.0026], grad_fn=<AddBackward0>)\n",
      "tensor(0.3499, grad_fn=<SumBackward0>)\n",
      "Epoch 431 loss is 0.34986722469329834\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4668, 0.9824, 0.9489, 0.5271, 0.5255, 0.4661, 0.5190, 0.4844, 0.4942,\n",
      "        0.5540, 0.5248], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.8035,  0.1005, -0.1523, -0.1609, -0.0027, -0.0137,  0.0468,  0.0583,\n",
      "         0.0672,  0.0510], grad_fn=<AddBackward0>)\n",
      "tensor(0.7977, grad_fn=<SumBackward0>)\n",
      "Epoch 432 loss is 0.7977293133735657\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.0002, 0.9349, 0.5128, 0.9040, 0.5109, 0.5106, 0.9723, 0.9585, 0.9124,\n",
      "        0.4813, 0.4949], grad_fn=<ViewBackward0>)\n",
      "tensor([-1.6245e-01, -3.2055e-02, -1.4134e-01, -7.2932e-04,  1.1379e-01,\n",
      "         7.4599e-01,  6.6955e-01, -1.6365e-01, -1.5452e-01, -1.3916e-01],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.7354, grad_fn=<SumBackward0>)\n",
      "Epoch 433 loss is 0.7354335784912109\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9393, 0.4362, 0.4861, 0.4716, 0.4480, 0.5148, 0.9841, 1.0013, 0.9717,\n",
      "        0.4784, 0.8850], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1511, -0.1559,  0.0197,  0.0478,  0.8540,  0.9222,  0.7615, -0.1686,\n",
      "        -0.0388, -0.0289], grad_fn=<AddBackward0>)\n",
      "tensor(2.0620, grad_fn=<SumBackward0>)\n",
      "Epoch 434 loss is 2.0620319843292236\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9963, 0.4691, 0.9050, 0.4905, 0.4686, 0.8859, 0.9037, 0.9389, 0.4763,\n",
      "        0.9605, 0.4981], grad_fn=<ViewBackward0>)\n",
      "tensor([-3.0412e-02, -1.6858e-01, -1.5396e-04, -6.3713e-03,  6.8864e-01,\n",
      "         7.8370e-01, -1.3655e-01,  9.4537e-02, -1.4692e-01,  3.6390e-02],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(1.1143, grad_fn=<SumBackward0>)\n",
      "Epoch 435 loss is 1.1142747402191162\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4612, 0.4830, 0.8986, 0.4847, 0.4756, 0.4687, 0.9606, 0.4761, 0.4759,\n",
      "        0.9377, 0.9199], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.7290,  0.0392, -0.0025, -0.1433,  0.7932,  0.0008,  0.0120, -0.0076,\n",
      "         0.7396,  0.7400], grad_fn=<AddBackward0>)\n",
      "tensor(2.9004, grad_fn=<SumBackward0>)\n",
      "Epoch 436 loss is 2.9004368782043457\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9588, 0.8913, 0.8300, 0.9171, 0.4899, 0.5094, 0.9117, 0.5013, 0.9100,\n",
      "        0.8565, 0.5086], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0429, -0.0139, -0.1338, -0.1069, -0.0018,  0.0190,  0.6677, -0.0184,\n",
      "         0.0121, -0.1338], grad_fn=<AddBackward0>)\n",
      "tensor(0.2472, grad_fn=<SumBackward0>)\n",
      "Epoch 437 loss is 0.24719661474227905\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9551, 0.9054, 0.5436, 0.4765, 0.5545, 0.5672, 0.5669, 0.8283, 0.8405,\n",
      "        0.8562, 0.5481], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1371, -0.1595, -0.1170,  0.0394,  0.1508,  0.4562,  0.4554,  0.4821,\n",
      "        -0.0934, -0.0975], grad_fn=<AddBackward0>)\n",
      "tensor(0.9793, grad_fn=<SumBackward0>)\n",
      "Epoch 438 loss is 0.9792741537094116\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5164, 0.8699, 0.5572, 0.5471, 0.5304, 0.5155, 0.8844, 0.8723, 0.8596,\n",
      "        0.8520, 0.5225], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0679,  0.0511, -0.1132, -0.0139,  0.5622,  0.5698,  0.5735, -0.0108,\n",
      "        -0.1166, -0.1124], grad_fn=<AddBackward0>)\n",
      "tensor(1.4577, grad_fn=<SumBackward0>)\n",
      "Epoch 439 loss is 1.4577399492263794\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.1972, 0.7220, 0.5767, 0.8079, 0.8028, 0.8174, 0.6039, 0.8250, 0.5898,\n",
      "        0.5864, 0.5778], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.2068, -0.1297,  0.1348,  0.4012, -0.0680,  0.0370, -0.0759, -0.0058,\n",
      "        -0.0824, -0.0040], grad_fn=<AddBackward0>)\n",
      "tensor(0.0002, grad_fn=<SumBackward0>)\n",
      "Epoch 440 loss is 0.0002225041389465332\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8602, 0.8354, 0.8312, 0.5767, 0.5160, 0.5624, 0.8426, 0.8456, 0.8435,\n",
      "        0.8247, 0.5782], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0097, -0.0945, -0.1065, -0.0896,  0.4431,  0.5493,  0.4685, -0.0060,\n",
      "        -0.0891, -0.0884], grad_fn=<AddBackward0>)\n",
      "tensor(0.9772, grad_fn=<SumBackward0>)\n",
      "Epoch 441 loss is 0.9771813750267029\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8301, 0.6014, 0.8052, 0.5423, 0.7936, 0.7959, 0.5804, 0.5619, 0.7686,\n",
      "        0.5845, 0.5779], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0083, -0.0959,  0.3203, -0.0031,  0.0635, -0.0772, -0.0091,  0.0069,\n",
      "         0.0266, -0.0636], grad_fn=<AddBackward0>)\n",
      "tensor(0.1601, grad_fn=<SumBackward0>)\n",
      "Epoch 442 loss is 0.16009670495986938\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8266, 0.6233, 0.7695, 0.5963, 0.7754, 0.5806, 0.7479, 0.7414, 0.7555,\n",
      "        0.5701, 0.6383], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0191, -0.0768,  0.2535, -0.0629,  0.2527, -0.0114,  0.2915, -0.0593,\n",
      "        -0.0344, -0.0391], grad_fn=<AddBackward0>)\n",
      "tensor(0.4948, grad_fn=<SumBackward0>)\n",
      "Epoch 443 loss is 0.49482518434524536\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5652, 0.6455, 0.7102, 0.6961, 0.6844, 0.6427, 0.6943, 0.7405, 0.7461,\n",
      "        0.7653, 0.6311], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2417,  0.2182,  0.0647, -0.0225, -0.0006,  0.0935,  0.1723,  0.1184,\n",
      "        -0.0365, -0.0383], grad_fn=<AddBackward0>)\n",
      "tensor(0.8110, grad_fn=<SumBackward0>)\n",
      "Epoch 444 loss is 0.811004638671875\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6299, 0.6608, 0.6827, 0.6560, 0.6741, 0.6726, 0.6858, 0.7106, 0.7029,\n",
      "        0.6362, 0.6696], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0880,  0.0435,  0.0223, -0.0034,  0.0496,  0.0608,  0.0505, -0.0165,\n",
      "        -0.0137, -0.0111], grad_fn=<AddBackward0>)\n",
      "tensor(0.2700, grad_fn=<SumBackward0>)\n",
      "Epoch 445 loss is 0.27001333236694336\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6799, 0.6969, 0.7003, 0.7125, 0.6910, 0.7088, 0.6693, 0.6763, 0.6741,\n",
      "        0.6751, 0.6980], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0341,  0.0543, -0.0020,  0.0141, -0.0144, -0.0049, -0.0116,  0.0097,\n",
      "         0.0360,  0.0397], grad_fn=<AddBackward0>)\n",
      "tensor(0.1552, grad_fn=<SumBackward0>)\n",
      "Epoch 446 loss is 0.15515649318695068\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7130, 0.6683, 0.7170, 0.6544, 0.7635, 0.6198, 0.6825, 0.7056, 0.7043,\n",
      "        0.6440, 0.6620], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0066, -0.0195,  0.1586, -0.0324,  0.0468, -0.0193,  0.1408, -0.0128,\n",
      "        -0.0145, -0.0141], grad_fn=<AddBackward0>)\n",
      "tensor(0.2401, grad_fn=<SumBackward0>)\n",
      "Epoch 447 loss is 0.24012285470962524\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6728, 0.6283, 0.6545, 0.7415, 0.6261, 0.7241, 0.7438, 0.5974, 0.7652,\n",
      "        0.6527, 0.6389], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0061,  0.1144, -0.0007,  0.1161,  0.0038, -0.0096,  0.0684, -0.0304,\n",
      "         0.0691, -0.0421], grad_fn=<AddBackward0>)\n",
      "tensor(0.2830, grad_fn=<SumBackward0>)\n",
      "Epoch 448 loss is 0.2830279469490051\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6744, 0.6165, 0.6262, 0.6290, 0.7309, 0.7497, 0.7335, 0.7616, 0.6294,\n",
      "        0.7292, 0.7500], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0161, -0.0151,  0.1907,  0.2058,  0.1742,  0.0511, -0.0401, -0.0014,\n",
      "        -0.0038,  0.2010], grad_fn=<AddBackward0>)\n",
      "tensor(0.7462, grad_fn=<SumBackward0>)\n",
      "Epoch 449 loss is 0.7462316155433655\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9419, 0.8955, 0.5737, 0.6212, 0.6376, 0.7556, 0.6285, 0.6441, 0.7280,\n",
      "        0.5946, 0.7641], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1227, -0.1069, -0.0860,  0.3031,  0.0123,  0.0108, -0.0092, -0.0113,\n",
      "         0.2000,  0.0601], grad_fn=<AddBackward0>)\n",
      "tensor(0.2502, grad_fn=<SumBackward0>)\n",
      "Epoch 450 loss is 0.25022006034851074\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7318, 0.8249, 0.6385, 0.6753, 0.7614, 0.6419, 0.7853, 0.6194, 0.8229,\n",
      "        0.6325, 0.8253], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0311, -0.0188, -0.0212,  0.0056,  0.1833, -0.0473,  0.3016, -0.0509,\n",
      "         0.3432,  0.0040], grad_fn=<AddBackward0>)\n",
      "tensor(0.6684, grad_fn=<SumBackward0>)\n",
      "Epoch 451 loss is 0.6684175729751587\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6831, 0.6714, 0.6474, 0.6535, 0.7630, 0.6764, 0.7308, 0.7638, 0.7765,\n",
      "        0.6516, 0.6703], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0119, -0.0099,  0.1528,  0.0482,  0.1288,  0.0012,  0.1670, -0.0264,\n",
      "        -0.0312, -0.0354], grad_fn=<AddBackward0>)\n",
      "tensor(0.3832, grad_fn=<SumBackward0>)\n",
      "Epoch 452 loss is 0.38322824239730835\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6701, 0.6673, 0.6513, 0.7351, 0.6459, 0.5987, 0.7208, 0.6623, 0.6724,\n",
      "        0.6489, 0.7020], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0063,  0.1083, -0.0071, -0.0175, -0.0048,  0.0275,  0.1228, -0.0240,\n",
      "         0.0662,  0.0494], grad_fn=<AddBackward0>)\n",
      "tensor(0.3144, grad_fn=<SumBackward0>)\n",
      "Epoch 453 loss is 0.31444019079208374\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7550, 0.6522, 0.6646, 0.6896, 0.6803, 0.6884, 0.7013, 0.7715, 0.6274,\n",
      "        0.8001, 0.6045], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0301, -0.0218,  0.0468,  0.0398,  0.0194,  0.1519, -0.0203,  0.1647,\n",
      "        -0.0557, -0.0077], grad_fn=<AddBackward0>)\n",
      "tensor(0.2870, grad_fn=<SumBackward0>)\n",
      "Epoch 454 loss is 0.28699350357055664\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6709, 0.6605, 0.6945, 0.6454, 0.6852, 0.7072, 0.6834, 0.6919, 0.6478,\n",
      "        0.6789, 0.6674], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0394, -0.0085,  0.0411,  0.0211,  0.0634,  0.0111, -0.0198, -0.0015,\n",
      "        -0.0081,  0.0327], grad_fn=<AddBackward0>)\n",
      "tensor(0.1709, grad_fn=<SumBackward0>)\n",
      "Epoch 455 loss is 0.1709393858909607\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7544, 0.6442, 0.6999, 0.6735, 0.7565, 0.6745, 0.6994, 0.7350, 0.6644,\n",
      "        0.6615, 0.6683], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0182, -0.0270,  0.1872, -0.0085,  0.0432, -0.0072, -0.0034, -0.0127,\n",
      "        -0.0222,  0.0065], grad_fn=<AddBackward0>)\n",
      "tensor(0.1379, grad_fn=<SumBackward0>)\n",
      "Epoch 456 loss is 0.1378687620162964\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6611, 0.6282, 0.7123, 0.6624, 0.6926, 0.6355, 0.6507, 0.6663, 0.7375,\n",
      "        0.6678, 0.6903], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0853,  0.0022,  0.1074, -0.0256, -0.0039, -0.0088,  0.1699,  0.0285,\n",
      "         0.0401, -0.0157], grad_fn=<AddBackward0>)\n",
      "tensor(0.3794, grad_fn=<SumBackward0>)\n",
      "Epoch 457 loss is 0.3794099688529968\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7273, 0.6621, 0.6783, 0.6920, 0.7488, 0.6930, 0.6634, 0.6515, 0.7359,\n",
      "        0.7285, 0.6586], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0163, -0.0118,  0.1446,  0.0244, -0.0095, -0.0325,  0.0715,  0.1085,\n",
      "         0.0119, -0.0258], grad_fn=<AddBackward0>)\n",
      "tensor(0.2650, grad_fn=<SumBackward0>)\n",
      "Epoch 458 loss is 0.2650131583213806\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7338, 0.6653, 0.7015, 0.6730, 0.6881, 0.6736, 0.7008, 0.6939, 0.6977,\n",
      "        0.7073, 0.6141], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0108, -0.0203,  0.0380, -0.0093,  0.0464,  0.0097,  0.0402,  0.0109,\n",
      "        -0.0266, -0.0279], grad_fn=<AddBackward0>)\n",
      "tensor(0.0503, grad_fn=<SumBackward0>)\n",
      "Epoch 459 loss is 0.05028945207595825\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4260, 0.6325, 0.7309, 0.6893, 0.7369, 0.6339, 0.6953, 0.6752, 0.7505,\n",
      "        0.7365, 0.6337], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.5083,  0.4390,  0.1739, -0.0324,  0.0099, -0.0205,  0.1944,  0.0687,\n",
      "        -0.0138, -0.0389], grad_fn=<AddBackward0>)\n",
      "tensor(1.2885, grad_fn=<SumBackward0>)\n",
      "Epoch 460 loss is 1.288515567779541\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5740, 0.7758, 0.6146, 0.7969, 0.5870, 0.7639, 0.6135, 0.7512, 0.6530,\n",
      "        0.7444, 0.6500], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0676,  0.3714, -0.0629,  0.2488, -0.0611,  0.2737, -0.0370,  0.2182,\n",
      "        -0.0337, -0.0010], grad_fn=<AddBackward0>)\n",
      "tensor(0.9839, grad_fn=<SumBackward0>)\n",
      "Epoch 461 loss is 0.9838888049125671\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8242, 0.5557, 0.7837, 0.7133, 0.7596, 0.6063, 0.7505, 0.5986, 0.6002,\n",
      "        0.7324, 0.7203], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0135, -0.0370,  0.3398, -0.0591,  0.0619, -0.0537, -0.0020, -0.0060,\n",
      "         0.2028,  0.2002], grad_fn=<AddBackward0>)\n",
      "tensor(0.6334, grad_fn=<SumBackward0>)\n",
      "Epoch 462 loss is 0.6334404945373535\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7786, 0.7291, 0.7716, 0.7149, 0.7541, 0.7848, 0.5926, 0.7237, 0.6500,\n",
      "        0.6509, 0.7581], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0023, -0.0212,  0.0417,  0.0221, -0.0408, -0.0101, -0.0449,  0.0972,\n",
      "         0.0575,  0.1802], grad_fn=<AddBackward0>)\n",
      "tensor(0.2792, grad_fn=<SumBackward0>)\n",
      "Epoch 463 loss is 0.2791764736175537\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7800, 0.6175, 0.7448, 0.7500, 0.6388, 0.7302, 0.6375, 0.6261, 0.5972,\n",
      "        0.8073, 0.6287], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0118, -0.0100,  0.0355, -0.0049, -0.0375, -0.0042, -0.0443,  0.2831,\n",
      "         0.0044,  0.0526], grad_fn=<AddBackward0>)\n",
      "tensor(0.2629, grad_fn=<SumBackward0>)\n",
      "Epoch 464 loss is 0.2628912925720215\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7550, 0.6131, 0.7309, 0.7162, 0.6048, 0.7521, 0.7559, 0.7890, 0.7631,\n",
      "        0.7794, 0.6537], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0080, -0.0129, -0.0027,  0.0352,  0.0663,  0.3070,  0.0184,  0.0391,\n",
      "        -0.0451, -0.0365], grad_fn=<AddBackward0>)\n",
      "tensor(0.3607, grad_fn=<SumBackward0>)\n",
      "Epoch 465 loss is 0.3606693744659424\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7814, 0.6606, 0.6847, 0.7052, 0.6510, 0.7264, 0.7403, 0.6798, 0.6751,\n",
      "        0.6612, 0.7403], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0322, -0.0254, -0.0032,  0.0696,  0.0583,  0.0481, -0.0171, -0.0263,\n",
      "         0.1008,  0.1087], grad_fn=<AddBackward0>)\n",
      "tensor(0.2812, grad_fn=<SumBackward0>)\n",
      "Epoch 466 loss is 0.28117096424102783\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6185, 0.6693, 0.6664, 0.6536, 0.6603, 0.7019, 0.6856, 0.6848, 0.6635,\n",
      "        0.6600, 0.7520], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0798,  0.0585, -0.0030,  0.0592,  0.0534,  0.0408, -0.0128, -0.0085,\n",
      "         0.1120,  0.1475], grad_fn=<AddBackward0>)\n",
      "tensor(0.5268, grad_fn=<SumBackward0>)\n",
      "Epoch 467 loss is 0.526772677898407\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7089, 0.6534, 0.6853, 0.6961, 0.7431, 0.6901, 0.6811, 0.6754, 0.7336,\n",
      "        0.6628, 0.6852], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0079, -0.0043,  0.1494,  0.0081, -0.0050, -0.0225,  0.0724, -0.0061,\n",
      "         0.0162, -0.0161], grad_fn=<AddBackward0>)\n",
      "tensor(0.1842, grad_fn=<SumBackward0>)\n",
      "Epoch 468 loss is 0.1842321753501892\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7111, 0.7202, 0.7016, 0.7065, 0.6582, 0.6773, 0.6293, 0.7595, 0.7596,\n",
      "        0.6658, 0.7060], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0032, -0.0015, -0.0206, -0.0081, -0.0257,  0.1688,  0.1372,  0.0608,\n",
      "        -0.0179, -0.0179], grad_fn=<AddBackward0>)\n",
      "tensor(0.2719, grad_fn=<SumBackward0>)\n",
      "Epoch 469 loss is 0.2719174027442932\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9180, 0.8597, 0.5682, 0.6106, 0.6964, 0.6965, 0.6412, 0.6550, 0.7975,\n",
      "        0.6196, 0.7614], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1166, -0.1024, -0.0544,  0.2138,  0.0509, -0.0138,  0.1683, -0.0072,\n",
      "         0.1775, -0.0120], grad_fn=<AddBackward0>)\n",
      "tensor(0.3040, grad_fn=<SumBackward0>)\n",
      "Epoch 470 loss is 0.3040210008621216\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6951, 0.7455, 0.7257, 0.6322, 0.7565, 0.6432, 0.7072, 0.6549, 0.7368,\n",
      "        0.7729, 0.7748], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0511, -0.0209,  0.0184, -0.0275,  0.1250, -0.0339,  0.1561,  0.1094,\n",
      "         0.1999,  0.0633], grad_fn=<AddBackward0>)\n",
      "tensor(0.6408, grad_fn=<SumBackward0>)\n",
      "Epoch 471 loss is 0.6407994627952576\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6601, 0.7027, 0.6997, 0.7093, 0.7391, 0.7924, 0.6171, 0.7748, 0.7165,\n",
      "        0.6807, 0.6667], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0659,  0.0819,  0.0607,  0.1546, -0.0307,  0.0595, -0.0253,  0.1059,\n",
      "        -0.0361, -0.0166], grad_fn=<AddBackward0>)\n",
      "tensor(0.4198, grad_fn=<SumBackward0>)\n",
      "Epoch 472 loss is 0.4197540879249573\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6508, 0.6822, 0.7323, 0.6875, 0.7347, 0.7008, 0.6809, 0.6826, 0.7483,\n",
      "        0.6538, 0.6928], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1359,  0.0611,  0.0875, -0.0105, -0.0022, -0.0174,  0.0792, -0.0090,\n",
      "         0.0170, -0.0185], grad_fn=<AddBackward0>)\n",
      "tensor(0.3231, grad_fn=<SumBackward0>)\n",
      "Epoch 473 loss is 0.32314467430114746\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6208, 0.6008, 0.7669, 0.7340, 0.6924, 0.7022, 0.6737, 0.6861, 0.6740,\n",
      "        0.7022, 0.6655], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2436,  0.1888,  0.1527, -0.0216, -0.0201, -0.0021, -0.0094,  0.0475,\n",
      "        -0.0069, -0.0029], grad_fn=<AddBackward0>)\n",
      "tensor(0.5697, grad_fn=<SumBackward0>)\n",
      "Epoch 474 loss is 0.5697423815727234\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7442, 0.7374, 0.7741, 0.7295, 0.7737, 0.6122, 0.6311, 0.7408, 0.7115,\n",
      "        0.6918, 0.6211], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0499, -0.0049,  0.0605, -0.0540, -0.0328, -0.0110,  0.1655,  0.1011,\n",
      "        -0.0399, -0.0301], grad_fn=<AddBackward0>)\n",
      "tensor(0.2044, grad_fn=<SumBackward0>)\n",
      "Epoch 475 loss is 0.20437610149383545\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6131, 0.6889, 0.6686, 0.7196, 0.7256, 0.7339, 0.6645, 0.6890, 0.7272,\n",
      "        0.7710, 0.6343], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0925,  0.1776,  0.0612,  0.1089, -0.0184, -0.0122, -0.0022,  0.1776,\n",
      "        -0.0182, -0.0310], grad_fn=<AddBackward0>)\n",
      "tensor(0.5356, grad_fn=<SumBackward0>)\n",
      "Epoch 476 loss is 0.5356208086013794\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7596, 0.6268, 0.7810, 0.6099, 0.6575, 0.6794, 0.7209, 0.7414, 0.7355,\n",
      "        0.7490, 0.7257], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0357, -0.0499,  0.0512, -0.0339,  0.1850,  0.1397,  0.0934,  0.0468,\n",
      "        -0.0052, -0.0033], grad_fn=<AddBackward0>)\n",
      "tensor(0.4597, grad_fn=<SumBackward0>)\n",
      "Epoch 477 loss is 0.4596538543701172\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7746, 0.7151, 0.6445, 0.7192, 0.7440, 0.6510, 0.6488, 0.6986, 0.6828,\n",
      "        0.6446, 0.6402], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0434, -0.0185,  0.0482,  0.0109, -0.0234, -0.0151,  0.0530, -0.0014,\n",
      "        -0.0195, -0.0142], grad_fn=<AddBackward0>)\n",
      "tensor(-0.0235, grad_fn=<SumBackward0>)\n",
      "Epoch 478 loss is -0.023472189903259277\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7728, 0.6924, 0.6278, 0.7146, 0.6861, 0.6999, 0.6548, 0.6780, 0.6911,\n",
      "        0.7252, 0.6793], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0483, -0.0194, -0.0021,  0.1201, -0.0199, -0.0027, -0.0029,  0.1173,\n",
      "         0.0023, -0.0039], grad_fn=<AddBackward0>)\n",
      "tensor(0.1405, grad_fn=<SumBackward0>)\n",
      "Epoch 479 loss is 0.14049690961837769\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5338, 0.8273, 0.7769, 0.7655, 0.6538, 0.6672, 0.7582, 0.6388, 0.7490,\n",
      "        0.6382, 0.6006], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4053,  0.3862, -0.0578, -0.0366, -0.0024, -0.0050,  0.1363, -0.0400,\n",
      "        -0.0127, -0.0494], grad_fn=<AddBackward0>)\n",
      "tensor(0.7237, grad_fn=<SumBackward0>)\n",
      "Epoch 480 loss is 0.7236983776092529\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6595, 0.7081, 0.6940, 0.6530, 0.7346, 0.6305, 0.6398, 0.6514, 0.7286,\n",
      "        0.7477, 0.7342], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0574, -0.0022,  0.0441, -0.0212, -0.0044, -0.0277,  0.1636,  0.1798,\n",
      "         0.1380,  0.0093], grad_fn=<AddBackward0>)\n",
      "tensor(0.5368, grad_fn=<SumBackward0>)\n",
      "Epoch 481 loss is 0.5368167161941528\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7212, 0.6708, 0.6875, 0.6908, 0.6702, 0.7145, 0.6834, 0.6408, 0.6974,\n",
      "        0.6748, 0.7124], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0112, -0.0101, -0.0002,  0.0450, -0.0025, -0.0098, -0.0057, -0.0029,\n",
      "         0.1193,  0.0249], grad_fn=<AddBackward0>)\n",
      "tensor(0.1468, grad_fn=<SumBackward0>)\n",
      "Epoch 482 loss is 0.14680612087249756\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6462, 0.6557, 0.6809, 0.7097, 0.6861, 0.6766, 0.6742, 0.6432, 0.7561,\n",
      "        0.7495, 0.6965], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0578,  0.1058,  0.0507, -0.0014, -0.0118, -0.0143,  0.1325,  0.1255,\n",
      "         0.0889, -0.0199], grad_fn=<AddBackward0>)\n",
      "tensor(0.5137, grad_fn=<SumBackward0>)\n",
      "Epoch 483 loss is 0.5137484073638916\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6536, 0.7028, 0.7289, 0.7148, 0.6822, 0.7209, 0.6539, 0.6635, 0.6821,\n",
      "        0.7486, 0.6853], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1254,  0.1020, -0.0069, -0.0026, -0.0203, -0.0062, -0.0129,  0.1580,\n",
      "         0.0363,  0.0054], grad_fn=<AddBackward0>)\n",
      "tensor(0.3781, grad_fn=<SumBackward0>)\n",
      "Epoch 484 loss is 0.3780745267868042\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7500, 0.6385, 0.7346, 0.6579, 0.6754, 0.6919, 0.6613, 0.6398, 0.6850,\n",
      "        0.6592, 0.6860], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0051, -0.0307,  0.0614, -0.0142,  0.0056, -0.0119, -0.0023, -0.0007,\n",
      "         0.0770,  0.0016], grad_fn=<AddBackward0>)\n",
      "tensor(0.0807, grad_fn=<SumBackward0>)\n",
      "Epoch 485 loss is 0.08070993423461914\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7669, 0.6764, 0.7018, 0.6668, 0.7301, 0.6582, 0.7104, 0.7115, 0.7044,\n",
      "        0.6931, 0.7147], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0217, -0.0333,  0.0895, -0.0146,  0.0727, -0.0062,  0.0770, -0.0058,\n",
      "         0.0055,  0.0173], grad_fn=<AddBackward0>)\n",
      "tensor(0.1804, grad_fn=<SumBackward0>)\n",
      "Epoch 486 loss is 0.18036091327667236\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6156, 0.6466, 0.6949, 0.7297, 0.7188, 0.7279, 0.7347, 0.7266, 0.6967,\n",
      "        0.7343, 0.6602], grad_fn=<ViewBackward0>)\n",
      "tensor([ 1.3210e-01,  1.9011e-01,  1.2039e-01,  5.5066e-02,  8.3852e-03,\n",
      "         1.2898e-02, -1.0406e-02, -1.4585e-04, -2.2129e-02, -1.2167e-02],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.4741, grad_fn=<SumBackward0>)\n",
      "Epoch 487 loss is 0.47410255670547485\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7737, 0.7213, 0.6712, 0.6946, 0.7313, 0.5932, 0.6370, 0.7260, 0.6772,\n",
      "        0.7290, 0.7321], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0342, -0.0264,  0.0167, -0.0260, -0.0192, -0.0018,  0.1401,  0.1533,\n",
      "         0.0102,  0.0914], grad_fn=<AddBackward0>)\n",
      "tensor(0.3041, grad_fn=<SumBackward0>)\n",
      "Epoch 488 loss is 0.30408596992492676\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6010, 0.6556, 0.7516, 0.7340, 0.6285, 0.6903, 0.7786, 0.6474, 0.6021,\n",
      "        0.5932, 0.6801], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2510,  0.2216, -0.0091, -0.0204,  0.0744,  0.0315, -0.0294, -0.0618,\n",
      "         0.0544,  0.1299], grad_fn=<AddBackward0>)\n",
      "tensor(0.6422, grad_fn=<SumBackward0>)\n",
      "Epoch 489 loss is 0.6421715021133423\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.0247, 0.6350, 0.6023, 0.7279, 0.6647, 0.6691, 0.7461, 0.7528, 0.7331,\n",
      "        0.6494, 0.7260], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1408, -0.0989,  0.0494,  0.1114,  0.0304,  0.1470,  0.1066, -0.0322,\n",
      "        -0.0089, -0.0023], grad_fn=<AddBackward0>)\n",
      "tensor(0.1614, grad_fn=<SumBackward0>)\n",
      "Epoch 490 loss is 0.16143882274627686\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7756, 0.5833, 0.6014, 0.6181, 0.6386, 0.7441, 0.7281, 0.7054, 0.6718,\n",
      "        0.7602, 0.7692], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0581, -0.0525,  0.0922,  0.2380,  0.1834,  0.1113, -0.0241,  0.0534,\n",
      "         0.1064,  0.1623], grad_fn=<AddBackward0>)\n",
      "tensor(0.8122, grad_fn=<SumBackward0>)\n",
      "Epoch 491 loss is 0.812209963798523\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8145, 0.7891, 0.6009, 0.7426, 0.7447, 0.6554, 0.7688, 0.6316, 0.7628,\n",
      "        0.6947, 0.6466], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0712, -0.0240, -0.0148,  0.0908,  0.0437, -0.0377,  0.1790, -0.0247,\n",
      "         0.0251, -0.0387], grad_fn=<AddBackward0>)\n",
      "tensor(0.1275, grad_fn=<SumBackward0>)\n",
      "Epoch 492 loss is 0.12748247385025024\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7781, 0.6236, 0.6220, 0.6714, 0.7289, 0.7099, 0.7238, 0.7465, 0.6636,\n",
      "        0.7168, 0.6693], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0520, -0.0356,  0.1755,  0.1465,  0.0873,  0.0293, -0.0154, -0.0023,\n",
      "        -0.0257,  0.0095], grad_fn=<AddBackward0>)\n",
      "tensor(0.3170, grad_fn=<SumBackward0>)\n",
      "Epoch 493 loss is 0.3169844150543213\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6326, 0.7269, 0.6862, 0.7346, 0.7038, 0.7105, 0.7188, 0.7902, 0.6796,\n",
      "        0.6561, 0.6944], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0893,  0.1699, -0.0077,  0.0405, -0.0053,  0.1441, -0.0103, -0.0209,\n",
      "        -0.0319,  0.0246], grad_fn=<AddBackward0>)\n",
      "tensor(0.3924, grad_fn=<SumBackward0>)\n",
      "Epoch 494 loss is 0.3923800587654114\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7587, 0.6979, 0.6717, 0.6640, 0.6593, 0.6979, 0.6614, 0.7170, 0.6843,\n",
      "        0.6928, 0.6826], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0290, -0.0316, -0.0129,  0.0436, -0.0009,  0.0962, -0.0045,  0.0523,\n",
      "        -0.0115, -0.0006], grad_fn=<AddBackward0>)\n",
      "tensor(0.1013, grad_fn=<SumBackward0>)\n",
      "Epoch 495 loss is 0.10126316547393799\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7298, 0.6595, 0.7274, 0.6251, 0.7118, 0.6411, 0.7015, 0.7109, 0.7485,\n",
      "        0.7155, 0.6881], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0008, -0.0349,  0.0871, -0.0287,  0.1273, -0.0003,  0.1790,  0.0232,\n",
      "        -0.0076, -0.0201], grad_fn=<AddBackward0>)\n",
      "tensor(0.3243, grad_fn=<SumBackward0>)\n",
      "Epoch 496 loss is 0.3242833614349365\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6439, 0.6972, 0.6434, 0.6785, 0.7237, 0.6584, 0.6570, 0.6414, 0.7531,\n",
      "        0.6487, 0.7209], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0002,  0.0577,  0.0442,  0.0252, -0.0072, -0.0275,  0.1578, -0.0028,\n",
      "         0.1326, -0.0107], grad_fn=<AddBackward0>)\n",
      "tensor(0.3691, grad_fn=<SumBackward0>)\n",
      "Epoch 497 loss is 0.3690860867500305\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6887, 0.7169, 0.7388, 0.6683, 0.7366, 0.6415, 0.6301, 0.7181, 0.7319,\n",
      "        0.6302, 0.7128], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0834, -0.0068,  0.0329, -0.0324, -0.0127, -0.0062,  0.1508,  0.0002,\n",
      "        -0.0018, -0.0064], grad_fn=<AddBackward0>)\n",
      "tensor(0.2010, grad_fn=<SumBackward0>)\n",
      "Epoch 498 loss is 0.20097792148590088\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7162, 0.6916, 0.6718, 0.6860, 0.7131, 0.6614, 0.7338, 0.6745, 0.7310,\n",
      "        0.6745, 0.6770], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0148, -0.0101,  0.0359, -0.0035,  0.0797, -0.0129,  0.1160, -0.0198,\n",
      "         0.0043, -0.0180], grad_fn=<AddBackward0>)\n",
      "tensor(0.1569, grad_fn=<SumBackward0>)\n",
      "Epoch 499 loss is 0.15685242414474487\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5071, 0.5255, 0.7819, 0.6504, 0.6894, 0.6294, 0.7712, 0.5845, 0.6140,\n",
      "        0.7492, 0.7236], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4579,  0.2389,  0.2732, -0.0508,  0.2014, -0.0350, -0.0051, -0.0074,\n",
      "         0.2317,  0.1825], grad_fn=<AddBackward0>)\n",
      "tensor(1.4873, grad_fn=<SumBackward0>)\n",
      "Epoch 500 loss is 1.4873337745666504\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7128, 0.7101, 0.6750, 0.6633, 0.7170, 0.7138, 0.7331, 0.7348, 0.7119,\n",
      "        0.7025, 0.7206], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0126, -0.0165,  0.0116,  0.0647,  0.1163,  0.0297, -0.0006, -0.0102,\n",
      "        -0.0047,  0.0145], grad_fn=<AddBackward0>)\n",
      "tensor(0.1920, grad_fn=<SumBackward0>)\n",
      "Epoch 501 loss is 0.19204825162887573\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7060, 0.6808, 0.6503, 0.7243, 0.6829, 0.6718, 0.6993, 0.6597, 0.6922,\n",
      "        0.7274, 0.6541], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0186,  0.0306,  0.0034,  0.0359, -0.0083, -0.0077,  0.0340,  0.0468,\n",
      "        -0.0019, -0.0127], grad_fn=<AddBackward0>)\n",
      "tensor(0.1015, grad_fn=<SumBackward0>)\n",
      "Epoch 502 loss is 0.10147053003311157\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6867, 0.6740, 0.6986, 0.6583, 0.6634, 0.6638, 0.7351, 0.6240, 0.7077,\n",
      "        0.6808, 0.6703], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0199, -0.0095, -0.0035, -0.0116,  0.1280, -0.0131,  0.0731, -0.0181,\n",
      "         0.0771, -0.0125], grad_fn=<AddBackward0>)\n",
      "tensor(0.2299, grad_fn=<SumBackward0>)\n",
      "Epoch 503 loss is 0.22991889715194702\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7329, 0.6660, 0.7105, 0.7010, 0.6906, 0.7043, 0.6848, 0.6867, 0.6492,\n",
      "        0.6848, 0.7065], grad_fn=<ViewBackward0>)\n",
      "tensor([-7.4536e-03, -1.0648e-02,  4.1097e-02, -2.0723e-03, -5.3966e-03,\n",
      "        -1.3093e-03, -1.8386e-02,  5.3942e-05,  3.2962e-02,  9.5515e-02],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.1244, grad_fn=<SumBackward0>)\n",
      "Epoch 504 loss is 0.12436157464981079\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7881, 0.6873, 0.7149, 0.6968, 0.6845, 0.6667, 0.6789, 0.6677, 0.7010,\n",
      "        0.7127, 0.6642], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0244, -0.0304, -0.0009, -0.0161, -0.0059, -0.0056,  0.0572,  0.0564,\n",
      "        -0.0012, -0.0123], grad_fn=<AddBackward0>)\n",
      "tensor(0.0167, grad_fn=<SumBackward0>)\n",
      "Epoch 505 loss is 0.01669144630432129\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6210, 0.7443, 0.6586, 0.7804, 0.7425, 0.6896, 0.7184, 0.6693, 0.6618,\n",
      "        0.5643, 0.6265], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0627,  0.2656, -0.0006,  0.0516, -0.0207, -0.0244, -0.0093, -0.0514,\n",
      "        -0.0143, -0.0118], grad_fn=<AddBackward0>)\n",
      "tensor(0.2475, grad_fn=<SumBackward0>)\n",
      "Epoch 506 loss is 0.24751657247543335\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6529, 0.6965, 0.6875, 0.6704, 0.7495, 0.7330, 0.6313, 0.7434, 0.6765,\n",
      "        0.6954, 0.6747], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0577,  0.0292,  0.0883,  0.0759, -0.0131, -0.0020, -0.0188,  0.1069,\n",
      "        -0.0229, -0.0006], grad_fn=<AddBackward0>)\n",
      "tensor(0.3006, grad_fn=<SumBackward0>)\n",
      "Epoch 507 loss is 0.30058830976486206\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6332, 0.6709, 0.6672, 0.7276, 0.7172, 0.7094, 0.7214, 0.6555, 0.7145,\n",
      "        0.6711, 0.7413], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0566,  0.1573,  0.0771,  0.0705, -0.0021, -0.0205,  0.0084, -0.0168,\n",
      "         0.1429,  0.0447], grad_fn=<AddBackward0>)\n",
      "tensor(0.5181, grad_fn=<SumBackward0>)\n",
      "Epoch 508 loss is 0.5181077122688293\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6919, 0.6723, 0.7779, 0.7006, 0.6717, 0.7044, 0.6808, 0.6818, 0.6649,\n",
      "        0.7415, 0.6313], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1433,  0.0146, -0.0002, -0.0245, -0.0066,  0.0169, -0.0132,  0.1012,\n",
      "        -0.0168, -0.0112], grad_fn=<AddBackward0>)\n",
      "tensor(0.2035, grad_fn=<SumBackward0>)\n",
      "Epoch 509 loss is 0.20348447561264038\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4107, 0.8028, 0.7928, 0.7375, 0.6889, 0.7120, 0.7048, 0.7090, 0.6988,\n",
      "        0.6856, 0.6736], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.6368,  0.5445, -0.0380, -0.0269, -0.0109,  0.0334, -0.0044, -0.0064,\n",
      "        -0.0118, -0.0084], grad_fn=<AddBackward0>)\n",
      "tensor(1.1079, grad_fn=<SumBackward0>)\n",
      "Epoch 510 loss is 1.1078755855560303\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7742, 0.6518, 0.6480, 0.7145, 0.6711, 0.6989, 0.7165, 0.7080, 0.6944,\n",
      "        0.7120, 0.6871], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0421, -0.0199,  0.0322,  0.0847,  0.0034,  0.0616, -0.0015, -0.0015,\n",
      "        -0.0070, -0.0024], grad_fn=<AddBackward0>)\n",
      "tensor(0.1075, grad_fn=<SumBackward0>)\n",
      "Epoch 511 loss is 0.10751765966415405\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7842, 0.6486, 0.7725, 0.6232, 0.6222, 0.7614, 0.5778, 0.7434, 0.6442,\n",
      "        0.7012, 0.7632], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0039, -0.0537, -0.0088, -0.0037, -0.0151,  0.2019, -0.0391,  0.2057,\n",
      "         0.0330,  0.1983], grad_fn=<AddBackward0>)\n",
      "tensor(0.5147, grad_fn=<SumBackward0>)\n",
      "Epoch 512 loss is 0.5146796107292175\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7988, 0.6026, 0.7563, 0.5857, 0.7241, 0.6460, 0.7865, 0.6410, 0.7448,\n",
      "        0.7482, 0.7834], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0142, -0.0710,  0.2024, -0.0368,  0.3346, -0.0277,  0.1647, -0.0127,\n",
      "         0.2374,  0.0643], grad_fn=<AddBackward0>)\n",
      "tensor(0.8410, grad_fn=<SumBackward0>)\n",
      "Epoch 513 loss is 0.840994119644165\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8362, 0.7719, 0.5917, 0.7711, 0.6351, 0.6685, 0.6320, 0.7831, 0.7724,\n",
      "        0.6147, 0.7712], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0815, -0.0217, -0.0456,  0.1279, -0.0464,  0.2466,  0.1732, -0.0058,\n",
      "        -0.0040, -0.0004], grad_fn=<AddBackward0>)\n",
      "tensor(0.3424, grad_fn=<SumBackward0>)\n",
      "Epoch 514 loss is 0.34241920709609985\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8044, 0.6267, 0.6467, 0.7635, 0.6246, 0.6860, 0.7436, 0.6042, 0.7776,\n",
      "        0.5863, 0.7649], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0526, -0.0136, -0.0007,  0.0655, -0.0066, -0.0068,  0.1526, -0.0524,\n",
      "         0.2678, -0.0042], grad_fn=<AddBackward0>)\n",
      "tensor(0.3489, grad_fn=<SumBackward0>)\n",
      "Epoch 515 loss is 0.34891003370285034\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6605, 0.7435, 0.7639, 0.6710, 0.6103, 0.7844, 0.6200, 0.7370, 0.6049,\n",
      "        0.7499, 0.7674], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1724,  0.0175, -0.0444,  0.0341, -0.0170,  0.2111, -0.0598,  0.2165,\n",
      "         0.0508,  0.2709], grad_fn=<AddBackward0>)\n",
      "tensor(0.8520, grad_fn=<SumBackward0>)\n",
      "Epoch 516 loss is 0.8520358800888062\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6337, 0.6334, 0.7987, 0.6200, 0.7362, 0.7727, 0.6249, 0.6388, 0.7667,\n",
      "        0.6191, 0.6470], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2750, -0.0046,  0.1713, -0.0087,  0.0083, -0.0325, -0.0020, -0.0019,\n",
      "         0.0137, -0.0399], grad_fn=<AddBackward0>)\n",
      "tensor(0.3787, grad_fn=<SumBackward0>)\n",
      "Epoch 517 loss is 0.3787297010421753\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6311, 0.7221, 0.6302, 0.6639, 0.6963, 0.7334, 0.7263, 0.7181, 0.7065,\n",
      "        0.6510, 0.5979], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0003,  0.0547, -0.0086,  0.1720,  0.1041,  0.0362, -0.0090, -0.0251,\n",
      "        -0.0401, -0.0362], grad_fn=<AddBackward0>)\n",
      "tensor(0.2477, grad_fn=<SumBackward0>)\n",
      "Epoch 518 loss is 0.24771082401275635\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6505, 0.6928, 0.6133, 0.6585, 0.6529, 0.6897, 0.6948, 0.6468, 0.6679,\n",
      "        0.7284, 0.6253], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0124,  0.0134, -0.0133,  0.1274,  0.0604, -0.0020, -0.0072,  0.0561,\n",
      "        -0.0072, -0.0142], grad_fn=<AddBackward0>)\n",
      "tensor(0.2009, grad_fn=<SumBackward0>)\n",
      "Epoch 519 loss is 0.20090079307556152\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4911, 0.7534, 0.7773, 0.6489, 0.7137, 0.6636, 0.6127, 0.6451, 0.6780,\n",
      "        0.6837, 0.6744], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4771,  0.2631, -0.0132, -0.0379, -0.0121, -0.0229,  0.0241,  0.1182,\n",
      "         0.0488, -0.0012], grad_fn=<AddBackward0>)\n",
      "tensor(0.8441, grad_fn=<SumBackward0>)\n",
      "Epoch 520 loss is 0.8440580368041992\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7707, 0.6425, 0.7009, 0.7161, 0.7073, 0.7204, 0.6852, 0.6408, 0.7083,\n",
      "        0.7157, 0.7106], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0233, -0.0182,  0.1080,  0.0326, -0.0103, -0.0222, -0.0040,  0.0508,\n",
      "         0.1163,  0.0038], grad_fn=<AddBackward0>)\n",
      "tensor(0.2335, grad_fn=<SumBackward0>)\n",
      "Epoch 521 loss is 0.23351991176605225\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6494, 0.6746, 0.6959, 0.6716, 0.6525, 0.7352, 0.7455, 0.6296, 0.6457,\n",
      "        0.6824, 0.7044], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0776,  0.0370, -0.0074,  0.0655,  0.1232, -0.0077, -0.0298, -0.0210,\n",
      "         0.1248,  0.0979], grad_fn=<AddBackward0>)\n",
      "tensor(0.4601, grad_fn=<SumBackward0>)\n",
      "Epoch 522 loss is 0.4600502848625183\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7790, 0.5956, 0.6430, 0.6234, 0.6671, 0.7075, 0.7041, 0.6814, 0.6500,\n",
      "        0.6854, 0.6706], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0453, -0.0519,  0.1190,  0.1074,  0.1346,  0.0239, -0.0191, -0.0062,\n",
      "        -0.0036,  0.0343], grad_fn=<AddBackward0>)\n",
      "tensor(0.2930, grad_fn=<SumBackward0>)\n",
      "Epoch 523 loss is 0.29295676946640015\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6482, 0.6732, 0.7275, 0.6486, 0.6854, 0.6857, 0.6824, 0.7406, 0.6610,\n",
      "        0.6174, 0.6995], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1321,  0.0006,  0.0202, -0.0139,  0.0564,  0.0921, -0.0082, -0.0216,\n",
      "        -0.0137,  0.0640], grad_fn=<AddBackward0>)\n",
      "tensor(0.3079, grad_fn=<SumBackward0>)\n",
      "Epoch 524 loss is 0.3078666925430298\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7819, 0.6539, 0.6798, 0.7306, 0.6201, 0.6204, 0.7035, 0.6937, 0.6625,\n",
      "        0.7455, 0.7407], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0340, -0.0171, -0.0113, -0.0198, -0.0091,  0.1227,  0.0702,  0.0701,\n",
      "         0.0784,  0.1304], grad_fn=<AddBackward0>)\n",
      "tensor(0.3805, grad_fn=<SumBackward0>)\n",
      "Epoch 525 loss is 0.38052254915237427\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8186, 0.7573, 0.6031, 0.6280, 0.7647, 0.6383, 0.7071, 0.6461, 0.6100,\n",
      "        0.7714, 0.6791], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0718, -0.0635,  0.0124,  0.0586,  0.1318, -0.0395, -0.0094,  0.1071,\n",
      "         0.0550,  0.1153], grad_fn=<AddBackward0>)\n",
      "tensor(0.2958, grad_fn=<SumBackward0>)\n",
      "Epoch 526 loss is 0.2958003282546997\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7749, 0.7555, 0.7753, 0.7655, 0.7202, 0.7486, 0.6701, 0.6355, 0.7514,\n",
      "        0.7448, 0.7354], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0005, -0.0032, -0.0118, -0.0089, -0.0318, -0.0283,  0.0046,  0.1245,\n",
      "         0.1666, -0.0053], grad_fn=<AddBackward0>)\n",
      "tensor(0.2070, grad_fn=<SumBackward0>)\n",
      "Epoch 527 loss is 0.20703482627868652\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5973, 0.5796, 0.6364, 0.7690, 0.6779, 0.6105, 0.6438, 0.7174, 0.7415,\n",
      "        0.6930, 0.7381], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0653,  0.2862,  0.1637, -0.0087, -0.0417,  0.0658,  0.2183,  0.0821,\n",
      "         0.0346, -0.0011], grad_fn=<AddBackward0>)\n",
      "tensor(0.8646, grad_fn=<SumBackward0>)\n",
      "Epoch 528 loss is 0.8645842671394348\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5759, 0.7906, 0.5987, 0.7622, 0.7495, 0.6579, 0.7513, 0.7698, 0.7633,\n",
      "        0.7572, 0.7496], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0380,  0.3106, -0.0137,  0.0988, -0.0036,  0.0339,  0.1755,  0.0099,\n",
      "        -0.0067, -0.0046], grad_fn=<AddBackward0>)\n",
      "tensor(0.6380, grad_fn=<SumBackward0>)\n",
      "Epoch 529 loss is 0.6380133628845215\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.0030, 0.6068, 0.7342, 0.6932, 0.6788, 0.7058, 0.7535, 0.6235, 0.7553,\n",
      "        0.7144, 0.6419], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0896, -0.1033,  0.1200, -0.0095,  0.1005, -0.0184,  0.0824, -0.0130,\n",
      "         0.0307, -0.0378], grad_fn=<AddBackward0>)\n",
      "tensor(0.0620, grad_fn=<SumBackward0>)\n",
      "Epoch 530 loss is 0.061959922313690186\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6188, 0.7480, 0.7221, 0.7365, 0.6316, 0.7576, 0.7182, 0.7574, 0.6933,\n",
      "        0.6857, 0.6730], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1721,  0.1962, -0.0388,  0.0593, -0.0061,  0.2097, -0.0214, -0.0108,\n",
      "        -0.0281, -0.0068], grad_fn=<AddBackward0>)\n",
      "tensor(0.5252, grad_fn=<SumBackward0>)\n",
      "Epoch 531 loss is 0.5252495408058167\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5996, 0.6984, 0.6665, 0.6827, 0.7383, 0.6721, 0.7075, 0.6644, 0.6928,\n",
      "        0.6823, 0.6648], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1115,  0.1385,  0.0664,  0.0092,  0.0414, -0.0246,  0.0346, -0.0084,\n",
      "         0.0006, -0.0093], grad_fn=<AddBackward0>)\n",
      "tensor(0.3598, grad_fn=<SumBackward0>)\n",
      "Epoch 532 loss is 0.35981839895248413\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7227, 0.7396, 0.6830, 0.6470, 0.6631, 0.6760, 0.7201, 0.7481, 0.6740,\n",
      "        0.6736, 0.6991], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0132, -0.0252, -0.0255, -0.0023,  0.1219,  0.1418, -0.0007, -0.0155,\n",
      "        -0.0163,  0.0419], grad_fn=<AddBackward0>)\n",
      "tensor(0.2067, grad_fn=<SumBackward0>)\n",
      "Epoch 533 loss is 0.20669430494308472\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7088, 0.7556, 0.7227, 0.7177, 0.6616, 0.6676, 0.7065, 0.7046, 0.7056,\n",
      "        0.6547, 0.6834], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0232,  0.0149, -0.0313, -0.0184, -0.0038,  0.0717,  0.0633, -0.0173,\n",
      "        -0.0071, -0.0074], grad_fn=<AddBackward0>)\n",
      "tensor(0.0879, grad_fn=<SumBackward0>)\n",
      "Epoch 534 loss is 0.08789914846420288\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6405, 0.7173, 0.6638, 0.6791, 0.6785, 0.6405, 0.6749, 0.6624, 0.6021,\n",
      "        0.7329, 0.7195], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0388,  0.0644, -0.0129, -0.0078, -0.0014, -0.0054, -0.0128,  0.0967,\n",
      "         0.0951,  0.1957], grad_fn=<AddBackward0>)\n",
      "tensor(0.4504, grad_fn=<SumBackward0>)\n",
      "Epoch 535 loss is 0.4503767490386963\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6597, 0.6859, 0.6541, 0.6556, 0.6671, 0.7999, 0.8483, 0.7761, 0.6221,\n",
      "        0.7786, 0.6327], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0019, -0.0014, -0.0063,  0.2429,  0.3212,  0.1816, -0.0592, -0.0232,\n",
      "        -0.0478,  0.0176], grad_fn=<AddBackward0>)\n",
      "tensor(0.6235, grad_fn=<SumBackward0>)\n",
      "Epoch 536 loss is 0.6235350370407104\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6826, 0.6515, 0.7313, 0.5930, 0.6317, 0.7548, 0.7520, 0.6809, 0.6673,\n",
      "        0.6309, 0.7663], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0812, -0.0299, -0.0066,  0.0391,  0.2649,  0.0819, -0.0291, -0.0404,\n",
      "         0.1424,  0.1649], grad_fn=<AddBackward0>)\n",
      "tensor(0.6684, grad_fn=<SumBackward0>)\n",
      "Epoch 537 loss is 0.6684163808822632\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7435, 0.6344, 0.7330, 0.6265, 0.7437, 0.6638, 0.7100, 0.6582, 0.6248,\n",
      "        0.6319, 0.6283], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0035, -0.0390,  0.1823, -0.0231,  0.1391, -0.0285, -0.0130, -0.0261,\n",
      "        -0.0100,  0.0059], grad_fn=<AddBackward0>)\n",
      "tensor(0.1842, grad_fn=<SumBackward0>)\n",
      "Epoch 538 loss is 0.18424201011657715\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7071, 0.7240, 0.6522, 0.7377, 0.6483, 0.6178, 0.6238, 0.6492, 0.6917,\n",
      "        0.8052, 0.7685], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0183,  0.0511, -0.0252, -0.0114, -0.0380,  0.0016,  0.1231,  0.3024,\n",
      "         0.1987,  0.1279], grad_fn=<AddBackward0>)\n",
      "tensor(0.7119, grad_fn=<SumBackward0>)\n",
      "Epoch 539 loss is 0.7119054794311523\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5562, 0.8267, 0.5560, 0.5930, 0.6221, 0.6646, 0.6113, 0.6820, 0.7461,\n",
      "        0.8074, 0.6544], grad_fn=<ViewBackward0>)\n",
      "tensor([-7.1168e-05,  6.1330e-02, -6.8228e-02,  1.8098e-01,  3.0390e-02,\n",
      "         9.9854e-02,  1.3577e-01,  3.2684e-01, -9.2026e-03, -3.0573e-02],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.7271, grad_fn=<SumBackward0>)\n",
      "Epoch 540 loss is 0.7270844578742981\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6662, 0.6041, 0.7700, 0.7956, 0.8439, 0.7654, 0.6601, 0.6185, 0.8744,\n",
      "        0.6224, 0.7654], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1731,  0.2157,  0.3998, -0.0016, -0.0452, -0.0752,  0.1817, -0.0126,\n",
      "         0.2449, -0.0363], grad_fn=<AddBackward0>)\n",
      "tensor(1.0444, grad_fn=<SumBackward0>)\n",
      "Epoch 541 loss is 1.0443696975708008\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8042, 0.7352, 0.7527, 0.5954, 0.7666, 0.6057, 0.7756, 0.5995, 0.7754,\n",
      "        0.8042, 0.5926], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0172, -0.0696,  0.0525, -0.0490,  0.3004, -0.0557,  0.2829,  0.0477,\n",
      "        -0.0023, -0.0609], grad_fn=<AddBackward0>)\n",
      "tensor(0.4287, grad_fn=<SumBackward0>)\n",
      "Epoch 542 loss is 0.4287446141242981\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7474, 0.6250, 0.7083, 0.5976, 0.7737, 0.5909, 0.6342, 0.6477, 0.7326,\n",
      "        0.7597, 0.7758], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0130, -0.0499,  0.2479, -0.0391,  0.0610, -0.0420,  0.2362,  0.2091,\n",
      "         0.2135,  0.0720], grad_fn=<AddBackward0>)\n",
      "tensor(0.8956, grad_fn=<SumBackward0>)\n",
      "Epoch 543 loss is 0.8956469893455505\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6513, 0.6248, 0.6223, 0.7921, 0.7420, 0.7915, 0.6056, 0.8408, 0.7246,\n",
      "        0.6370, 0.8061], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0097,  0.2345,  0.1954,  0.2820, -0.0622,  0.1646, -0.0223,  0.0524,\n",
      "        -0.0116,  0.1357], grad_fn=<AddBackward0>)\n",
      "tensor(0.9589, grad_fn=<SumBackward0>)\n",
      "Epoch 544 loss is 0.9589473605155945\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7293, 0.5686, 0.7206, 0.6370, 0.5961, 0.6982, 0.6429, 0.6398, 0.6742,\n",
      "        0.7690, 0.7115], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0029, -0.0308,  0.0459, -0.0075,  0.0098,  0.0727, -0.0080,  0.2102,\n",
      "         0.1195,  0.0621], grad_fn=<AddBackward0>)\n",
      "tensor(0.4712, grad_fn=<SumBackward0>)\n",
      "Epoch 545 loss is 0.47118276357650757\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6970, 0.6660, 0.7088, 0.7416, 0.8048, 0.6731, 0.7341, 0.6332, 0.7349,\n",
      "        0.7086, 0.6415], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0197,  0.0743,  0.2313, -0.0119, -0.0025, -0.0572,  0.1030, -0.0085,\n",
      "         0.0139, -0.0311], grad_fn=<AddBackward0>)\n",
      "tensor(0.3310, grad_fn=<SumBackward0>)\n",
      "Epoch 546 loss is 0.33097773790359497\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6778, 0.6581, 0.6769, 0.6897, 0.6570, 0.7049, 0.7281, 0.7242, 0.6466,\n",
      "        0.6811, 0.7160], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0003,  0.0199, -0.0003,  0.0466,  0.0640,  0.1119, -0.0194, -0.0157,\n",
      "        -0.0027,  0.1155], grad_fn=<AddBackward0>)\n",
      "tensor(0.3195, grad_fn=<SumBackward0>)\n",
      "Epoch 547 loss is 0.3195352554321289\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6802, 0.6441, 0.7025, 0.6947, 0.7106, 0.7164, 0.6306, 0.6955, 0.6908,\n",
      "        0.7844, 0.7035], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0372,  0.0241,  0.1108,  0.0231, -0.0214, -0.0050, -0.0085,  0.2564,\n",
      "         0.0134,  0.0212], grad_fn=<AddBackward0>)\n",
      "tensor(0.4512, grad_fn=<SumBackward0>)\n",
      "Epoch 548 loss is 0.45120102167129517\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6389, 0.6514, 0.6652, 0.6765, 0.6907, 0.6406, 0.6445, 0.6926, 0.7243,\n",
      "        0.6555, 0.6758], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0438,  0.0626,  0.0655, -0.0082, -0.0107,  0.0032,  0.1394,  0.0184,\n",
      "        -0.0056, -0.0162], grad_fn=<AddBackward0>)\n",
      "tensor(0.2922, grad_fn=<SumBackward0>)\n",
      "Epoch 549 loss is 0.29217493534088135\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4661, 0.6296, 0.6484, 0.6925, 0.6598, 0.7004, 0.6818, 0.6489, 0.7020,\n",
      "        0.6859, 0.6948], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.3038,  0.3772,  0.0504,  0.0866, -0.0036, -0.0036,  0.0027,  0.0068,\n",
      "         0.0766, -0.0024], grad_fn=<AddBackward0>)\n",
      "tensor(0.8946, grad_fn=<SumBackward0>)\n",
      "Epoch 550 loss is 0.8945940732955933\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5569, 0.7724, 0.7334, 0.7743, 0.7720, 0.7470, 0.7070, 0.6192, 0.6333,\n",
      "        0.7066, 0.6157], grad_fn=<ViewBackward0>)\n",
      "tensor([ 2.9401e-01,  3.6222e-01, -1.4472e-04,  2.2721e-02, -2.2409e-02,\n",
      "        -5.0940e-02, -3.7909e-02, -1.4460e-04, -1.1538e-03, -5.8550e-03],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.5604, grad_fn=<SumBackward0>)\n",
      "Epoch 551 loss is 0.5603960156440735\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7898, 0.6457, 0.6246, 0.7362, 0.7912, 0.7688, 0.5692, 0.5817, 0.6449,\n",
      "        0.7431, 0.6443], grad_fn=<ViewBackward0>)\n",
      "tensor([-5.5067e-02, -1.7890e-02,  2.4238e-01,  2.4021e-01, -5.5664e-02,\n",
      "        -6.9821e-02, -4.1277e-02,  2.8996e-01,  1.0429e-01, -2.1267e-04],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.6369, grad_fn=<SumBackward0>)\n",
      "Epoch 552 loss is 0.6369130611419678\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7960, 0.7843, 0.5936, 0.5830, 0.7617, 0.6218, 0.5823, 0.7583, 0.6159,\n",
      "        0.7890, 0.7823], grad_fn=<ViewBackward0>)\n",
      "tensor([-6.7447e-02, -7.0976e-02, -7.5178e-03,  4.6931e-02, -2.6459e-04,\n",
      "        -1.1532e-03, -1.9681e-03,  3.4455e-01,  3.9934e-02,  2.7727e-01],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.5594, grad_fn=<SumBackward0>)\n",
      "Epoch 553 loss is 0.5593650937080383\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5891, 0.7806, 0.6079, 0.6835, 0.6830, 0.6151, 0.6361, 0.6587, 0.6432,\n",
      "        0.6329, 0.6011], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0314,  0.1573, -0.0325,  0.0120, -0.0158, -0.0081,  0.0468, -0.0010,\n",
      "        -0.0192, -0.0140], grad_fn=<AddBackward0>)\n",
      "tensor(0.1568, grad_fn=<SumBackward0>)\n",
      "Epoch 554 loss is 0.15682858228683472\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8153, 0.6650, 0.7371, 0.6788, 0.5993, 0.6042, 0.7917, 0.7960, 0.6048,\n",
      "        0.5904, 0.7375], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0261, -0.0455, -0.0219, -0.0443,  0.1882,  0.3278,  0.0011, -0.0671,\n",
      "        -0.0195,  0.2211], grad_fn=<AddBackward0>)\n",
      "tensor(0.5138, grad_fn=<SumBackward0>)\n",
      "Epoch 555 loss is 0.5137974619865417\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8403, 0.6018, 0.7724, 0.6363, 0.6032, 0.6359, 0.6425, 0.5759, 0.7759,\n",
      "        0.7871, 0.5766], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0226, -0.0680,  0.0023, -0.0455,  0.0103, -0.0091,  0.2332,  0.2410,\n",
      "         0.0012, -0.0664], grad_fn=<AddBackward0>)\n",
      "tensor(0.2764, grad_fn=<SumBackward0>)\n",
      "Epoch 556 loss is 0.276378333568573\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5449, 0.8213, 0.6062, 0.5606, 0.7675, 0.6041, 0.8055, 0.7962, 0.7828,\n",
      "        0.8233, 0.6287], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1020,  0.0260, -0.0179, -0.0007,  0.4082,  0.0478,  0.2979,  0.0297,\n",
      "        -0.0558, -0.0514], grad_fn=<AddBackward0>)\n",
      "tensor(0.7859, grad_fn=<SumBackward0>)\n",
      "Epoch 557 loss is 0.7858654856681824\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8320, 0.5764, 0.8238, 0.5852, 0.6043, 0.7471, 0.6225, 0.5747, 0.5303,\n",
      "        0.8352, 0.7870], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0027, -0.0822,  0.0464, -0.0256,  0.0622, -0.0099, -0.0722,  0.3545,\n",
      "         0.3538,  0.4277], grad_fn=<AddBackward0>)\n",
      "tensor(1.0520, grad_fn=<SumBackward0>)\n",
      "Epoch 558 loss is 1.0519771575927734\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8668, 0.5317, 0.5935, 0.7876, 0.6544, 0.8093, 0.6342, 0.5936, 0.8052,\n",
      "        0.5620, 0.6134], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0911, -0.0264,  0.2044,  0.3595, -0.0512, -0.0203, -0.0014, -0.0241,\n",
      "         0.0330, -0.0639], grad_fn=<AddBackward0>)\n",
      "tensor(0.3187, grad_fn=<SumBackward0>)\n",
      "Epoch 559 loss is 0.3186931014060974\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.1311, 0.7247, 0.7311, 0.7826, 0.5474, 0.7914, 0.5967, 0.5879, 0.7908,\n",
      "        0.6075, 0.5417], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1333, -0.1162, -0.0591,  0.1005, -0.0620,  0.0674, -0.0002,  0.0181,\n",
      "        -0.0154, -0.0830], grad_fn=<AddBackward0>)\n",
      "tensor(-0.2832, grad_fn=<SumBackward0>)\n",
      "Epoch 560 loss is -0.28320783376693726\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8431, 0.5895, 0.5342, 0.8561, 0.6369, 0.6242, 0.5478, 0.7913, 0.5820,\n",
      "        0.5384, 0.5640], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1030,  0.0217,  0.0790,  0.1500, -0.1028,  0.2573, -0.0141, -0.0031,\n",
      "        -0.0758, -0.0060], grad_fn=<AddBackward0>)\n",
      "tensor(0.2033, grad_fn=<SumBackward0>)\n",
      "Epoch 561 loss is 0.20325762033462524\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5400, 0.8368, 0.5316, 0.5575, 0.8092, 0.7969, 0.8031, 0.6109, 0.6417,\n",
      "        0.8218, 0.8445], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0028,  0.0291, -0.0092,  0.4422,  0.4094, -0.0661, -0.0517,  0.0311,\n",
      "         0.3893,  0.3380], grad_fn=<AddBackward0>)\n",
      "tensor(1.5093, grad_fn=<SumBackward0>)\n",
      "Epoch 562 loss is 1.5092966556549072\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5190, 0.5299, 0.7997, 0.5938, 0.7771, 0.6199, 0.8149, 0.5962, 0.8033,\n",
      "        0.8214, 0.5780], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4677,  0.1247,  0.4121, -0.0599,  0.3685, -0.0603,  0.3056,  0.0108,\n",
      "        -0.0061, -0.0751], grad_fn=<AddBackward0>)\n",
      "tensor(1.4881, grad_fn=<SumBackward0>)\n",
      "Epoch 563 loss is 1.4880645275115967\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5707, 0.5718, 0.8146, 0.6097, 0.7846, 0.5728, 0.6161, 0.7662, 0.8069,\n",
      "        0.6568, 0.7778], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4065,  0.0651,  0.3545, -0.0806,  0.0106, -0.0061,  0.3901,  0.0678,\n",
      "         0.0194, -0.0097], grad_fn=<AddBackward0>)\n",
      "tensor(1.2175, grad_fn=<SumBackward0>)\n",
      "Epoch 564 loss is 1.2175347805023193\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7923, 0.8250, 0.6303, 0.7857, 0.6073, 0.7703, 0.6127, 0.6491, 0.5741,\n",
      "        0.5854, 0.5971], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0540, -0.0022, -0.0726,  0.2333, -0.0576,  0.0697, -0.0654, -0.0091,\n",
      "        -0.0173,  0.0383], grad_fn=<AddBackward0>)\n",
      "tensor(0.0630, grad_fn=<SumBackward0>)\n",
      "Epoch 565 loss is 0.06295263767242432\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6094, 0.5944, 0.7744, 0.7583, 0.7575, 0.7965, 0.6101, 0.6426, 0.7410,\n",
      "        0.7588, 0.7578], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2750,  0.2482,  0.2719,  0.0368, -0.0494, -0.0383, -0.0185,  0.2478,\n",
      "         0.1919,  0.0279], grad_fn=<AddBackward0>)\n",
      "tensor(1.1933, grad_fn=<SumBackward0>)\n",
      "Epoch 566 loss is 1.193333387374878\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5846, 0.6489, 0.7598, 0.7548, 0.6198, 0.7726, 0.6285, 0.7615, 0.7737,\n",
      "        0.6208, 0.6435], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2921,  0.2836, -0.0097,  0.0213, -0.0421,  0.2361,  0.0018, -0.0026,\n",
      "        -0.0393, -0.0434], grad_fn=<AddBackward0>)\n",
      "tensor(0.6978, grad_fn=<SumBackward0>)\n",
      "Epoch 567 loss is 0.6977635622024536\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5972, 0.6686, 0.6858, 0.7371, 0.6871, 0.7070, 0.6501, 0.7396, 0.6561,\n",
      "        0.6406, 0.7431], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1478,  0.2332,  0.0309,  0.0353, -0.0290,  0.0875, -0.0170, -0.0032,\n",
      "         0.0058,  0.1450], grad_fn=<AddBackward0>)\n",
      "tensor(0.6364, grad_fn=<SumBackward0>)\n",
      "Epoch 568 loss is 0.636405885219574\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6471, 0.6565, 0.7094, 0.6787, 0.6367, 0.7288, 0.7209, 0.6756, 0.7377,\n",
      "        0.6872, 0.6694], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1039,  0.0528, -0.0066,  0.0322,  0.0702,  0.0648,  0.0149, -0.0112,\n",
      "        -0.0021, -0.0228], grad_fn=<AddBackward0>)\n",
      "tensor(0.2962, grad_fn=<SumBackward0>)\n",
      "Epoch 569 loss is 0.2961529493331909\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4688, 0.6032, 0.7439, 0.6703, 0.6700, 0.6718, 0.6450, 0.7013, 0.6711,\n",
      "        0.6934, 0.6856], grad_fn=<ViewBackward0>)\n",
      "tensor([ 4.5849e-01,  3.3591e-01,  1.1135e-01, -2.4042e-02, -8.4635e-03,\n",
      "         5.2160e-02, -2.2042e-04,  8.0746e-02, -5.2309e-03,  2.4151e-02],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(1.0248, grad_fn=<SumBackward0>)\n",
      "Epoch 570 loss is 1.024847149848938\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6628, 0.6957, 0.6945, 0.6655, 0.6969, 0.6740, 0.6821, 0.6629, 0.6685,\n",
      "        0.6843, 0.6803], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0529,  0.0044,  0.0019, -0.0068,  0.0277, -0.0113, -0.0018,  0.0037,\n",
      "         0.0291,  0.0197], grad_fn=<AddBackward0>)\n",
      "tensor(0.1195, grad_fn=<SumBackward0>)\n",
      "Epoch 571 loss is 0.11951541900634766\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7521, 0.6516, 0.6645, 0.6975, 0.6863, 0.7232, 0.7462, 0.6968, 0.6757,\n",
      "        0.6933, 0.6879], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0292, -0.0182,  0.0578,  0.0978,  0.0811,  0.0176, -0.0158, -0.0176,\n",
      "        -0.0030,  0.0203], grad_fn=<AddBackward0>)\n",
      "tensor(0.1909, grad_fn=<SumBackward0>)\n",
      "Epoch 572 loss is 0.19090420007705688\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6645, 0.6347, 0.6824, 0.7502, 0.6916, 0.7134, 0.6299, 0.7192, 0.6560,\n",
      "        0.6871, 0.6855], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0298,  0.1429,  0.0947,  0.0516, -0.0401,  0.0460, -0.0191,  0.0953,\n",
      "        -0.0112,  0.0492], grad_fn=<AddBackward0>)\n",
      "tensor(0.4391, grad_fn=<SumBackward0>)\n",
      "Epoch 573 loss is 0.4390551447868347\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6733, 0.6510, 0.7089, 0.6852, 0.7062, 0.7020, 0.7076, 0.7067, 0.6781,\n",
      "        0.6860, 0.6522], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0593,  0.0197,  0.0920, -0.0023,  0.0374,  0.0008, -0.0080, -0.0072,\n",
      "        -0.0182, -0.0086], grad_fn=<AddBackward0>)\n",
      "tensor(0.1650, grad_fn=<SumBackward0>)\n",
      "Epoch 574 loss is 0.16495108604431152\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7338, 0.7377, 0.7143, 0.6377, 0.7079, 0.7053, 0.6426, 0.7466, 0.7189,\n",
      "        0.7154, 0.7311], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0065, -0.0320, -0.0099, -0.0030,  0.0081,  0.0644,  0.0227,  0.1213,\n",
      "        -0.0051,  0.0204], grad_fn=<AddBackward0>)\n",
      "tensor(0.1803, grad_fn=<SumBackward0>)\n",
      "Epoch 575 loss is 0.18031299114227295\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7532, 0.7241, 0.6641, 0.7251, 0.7395, 0.6443, 0.6232, 0.6798, 0.7002,\n",
      "        0.6713, 0.6976], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0297, -0.0094,  0.0257, -0.0066, -0.0339, -0.0199,  0.0931,  0.0802,\n",
      "         0.0296, -0.0009], grad_fn=<AddBackward0>)\n",
      "tensor(0.1282, grad_fn=<SumBackward0>)\n",
      "Epoch 576 loss is 0.12821465730667114\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7615, 0.7346, 0.6696, 0.7052, 0.7115, 0.7071, 0.6830, 0.6895, 0.6417,\n",
      "        0.7339, 0.6270], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0306, -0.0188, -0.0077,  0.0625, -0.0074, -0.0073, -0.0218,  0.0850,\n",
      "        -0.0208, -0.0049], grad_fn=<AddBackward0>)\n",
      "tensor(0.0281, grad_fn=<SumBackward0>)\n",
      "Epoch 577 loss is 0.02806788682937622\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6029, 0.6217, 0.6364, 0.6582, 0.6907, 0.6114, 0.7318, 0.6580, 0.6962,\n",
      "        0.6722, 0.6960], grad_fn=<ViewBackward0>)\n",
      "tensor([ 5.5857e-02,  9.2143e-02,  1.1506e-01, -8.3339e-03,  1.2276e-01,\n",
      "        -1.0923e-02,  1.4134e-01, -1.9894e-02,  6.3287e-02, -8.9526e-05],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.5512, grad_fn=<SumBackward0>)\n",
      "Epoch 578 loss is 0.5512099862098694\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7685, 0.6266, 0.7120, 0.7388, 0.7363, 0.6806, 0.6285, 0.6665, 0.6169,\n",
      "        0.6726, 0.7887], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0189, -0.0099,  0.1828, -0.0105, -0.0368, -0.0233, -0.0212,  0.0736,\n",
      "         0.2038,  0.2864], grad_fn=<AddBackward0>)\n",
      "tensor(0.6260, grad_fn=<SumBackward0>)\n",
      "Epoch 579 loss is 0.6260302066802979\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.0422, 0.7924, 0.7129, 0.6251, 0.6330, 0.7566, 0.5974, 0.5922, 0.5776,\n",
      "        0.5908, 0.6567], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1098, -0.1390, -0.0531,  0.0729, -0.0093, -0.0136, -0.0597, -0.0022,\n",
      "         0.1076,  0.1319], grad_fn=<AddBackward0>)\n",
      "tensor(-0.0742, grad_fn=<SumBackward0>)\n",
      "Epoch 580 loss is -0.07417380809783936\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5365, 0.6118, 0.7727, 0.8159, 0.5957, 0.6139, 0.5842, 0.5886, 0.5886,\n",
      "        0.8325, 0.7910], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.3936,  0.4657, -0.0054, -0.0529, -0.0772, -0.0024, -0.0084,  0.4137,\n",
      "         0.3373,  0.3372], grad_fn=<AddBackward0>)\n",
      "tensor(1.8012, grad_fn=<SumBackward0>)\n",
      "Epoch 581 loss is 1.8012142181396484\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9220, 0.5698, 0.8405, 0.5610, 0.5763, 0.5640, 0.5307, 0.5084, 0.8451,\n",
      "        0.8223, 0.5933], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0272, -0.1203,  0.0108, -0.0922, -0.0101, -0.0226,  0.4684,  0.4859,\n",
      "         0.1414, -0.0839], grad_fn=<AddBackward0>)\n",
      "tensor(0.7503, grad_fn=<SumBackward0>)\n",
      "Epoch 582 loss is 0.7503191828727722\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9028, 0.5335, 0.5645, 0.5648, 0.5798, 0.5953, 0.5582, 0.8764, 0.5615,\n",
      "        0.8793, 0.8386], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1128, -0.1127,  0.0772,  0.0514, -0.0022,  0.4943, -0.0113,  0.5353,\n",
      "        -0.0126,  0.4617], grad_fn=<AddBackward0>)\n",
      "tensor(1.3684, grad_fn=<SumBackward0>)\n",
      "Epoch 583 loss is 1.3684041500091553\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9246, 0.5097, 0.4751, 0.8612, 0.8525, 0.5388, 0.9161, 0.9125, 0.5321,\n",
      "        0.5131, 0.8385], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1499, -0.0211,  0.5713,  0.1063,  0.0915,  0.1000, -0.0023, -0.1343,\n",
      "        -0.0247,  0.5107], grad_fn=<AddBackward0>)\n",
      "tensor(1.0476, grad_fn=<SumBackward0>)\n",
      "Epoch 584 loss is 1.0475691556930542\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8658, 0.8805, 0.8728, 0.5493, 0.8458, 0.5251, 0.5378, 0.5258, 0.5685,\n",
      "        0.5399, 0.8682], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0116, -0.1055, -0.0116, -0.1159, -0.0038, -0.1067,  0.0725,  0.0036,\n",
      "         0.5706,  0.4993], grad_fn=<AddBackward0>)\n",
      "tensor(0.8141, grad_fn=<SumBackward0>)\n",
      "Epoch 585 loss is 0.8140754699707031\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9422, 0.4949, 0.5245, 0.4917, 0.5188, 0.5007, 0.8747, 0.5023, 0.8905,\n",
      "        0.9382, 0.5446], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1392, -0.1501,  0.0397, -0.0079,  0.6383, -0.0055,  0.6496,  0.1057,\n",
      "         0.0705, -0.1153], grad_fn=<AddBackward0>)\n",
      "tensor(1.0859, grad_fn=<SumBackward0>)\n",
      "Epoch 586 loss is 1.0858803987503052\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4944, 0.9312, 0.5281, 0.5047, 0.4958, 0.9041, 0.5472, 0.8302, 0.8737,\n",
      "        0.5182, 0.8540], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0562,  0.0171, -0.1451,  0.6265,  0.0708,  0.5573, -0.0101, -0.0097,\n",
      "         0.0396, -0.0066], grad_fn=<AddBackward0>)\n",
      "tensor(1.1962, grad_fn=<SumBackward0>)\n",
      "Epoch 587 loss is 1.196174144744873\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5095, 0.5158, 0.8744, 0.5177, 0.5616, 0.5191, 0.9125, 0.5693, 0.5256,\n",
      "        0.5389, 0.8525], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.6081,  0.0137,  0.0763, -0.1184,  0.6580,  0.0128,  0.0108, -0.1245,\n",
      "         0.4721,  0.5448], grad_fn=<AddBackward0>)\n",
      "tensor(2.1538, grad_fn=<SumBackward0>)\n",
      "Epoch 588 loss is 2.1537821292877197\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4966, 0.9408, 0.4859, 0.5258, 0.9089, 0.5227, 0.4840, 0.5045, 0.8606,\n",
      "        0.5542, 0.8424], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0036,  0.0486, -0.0106,  0.0614, -0.0139, -0.1348,  0.5631,  0.1170,\n",
      "         0.5631, -0.0061], grad_fn=<AddBackward0>)\n",
      "tensor(1.1842, grad_fn=<SumBackward0>)\n",
      "Epoch 589 loss is 1.1842305660247803\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.2976, 0.8347, 0.4913, 0.4962, 0.8701, 0.9040, 0.9267, 0.9586, 0.9624,\n",
      "        0.9409, 0.9141], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.2688, -0.2671,  0.0591,  0.6879,  0.7175,  0.1474,  0.0973,  0.0237,\n",
      "        -0.0148, -0.0161], grad_fn=<AddBackward0>)\n",
      "tensor(1.1660, grad_fn=<SumBackward0>)\n",
      "Epoch 590 loss is 1.166021704673767\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9370, 0.4985, 0.5154, 0.5122, 0.5409, 0.8972, 0.9078, 0.9046, 0.8842,\n",
      "        0.9593, 0.8968], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1405, -0.1416,  0.0707,  0.6363,  0.6593,  0.6062, -0.0043,  0.0859,\n",
      "        -0.0026,  0.0211], grad_fn=<AddBackward0>)\n",
      "tensor(1.7903, grad_fn=<SumBackward0>)\n",
      "Epoch 591 loss is 1.7903192043304443\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9202, 0.9007, 0.9011, 0.9221, 0.9012, 0.5309, 0.5043, 0.8696, 0.5405,\n",
      "        0.5653, 0.8795], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0064,  0.0031,  0.0009, -0.1234, -0.1393, -0.0105,  0.0159,  0.1016,\n",
      "         0.0165,  0.5650], grad_fn=<AddBackward0>)\n",
      "tensor(0.4235, grad_fn=<SumBackward0>)\n",
      "Epoch 592 loss is 0.4235345125198364\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9091, 0.4843, 0.5506, 0.6191, 0.8228, 0.5434, 0.5488, 0.8005, 0.5833,\n",
      "        0.8124, 0.5471], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1195, -0.0967,  0.5642, -0.0024, -0.0234, -0.0075,  0.0666,  0.4395,\n",
      "        -0.0844, -0.0121], grad_fn=<AddBackward0>)\n",
      "tensor(0.7243, grad_fn=<SumBackward0>)\n",
      "Epoch 593 loss is 0.7242642641067505\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8616, 0.8398, 0.5630, 0.5916, 0.7751, 0.5999, 0.7440, 0.6589, 0.6139,\n",
      "        0.8254, 0.8177], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0995, -0.0900, -0.0215,  0.0616,  0.2541, -0.0388,  0.0232,  0.1356,\n",
      "         0.2647,  0.3397], grad_fn=<AddBackward0>)\n",
      "tensor(0.8291, grad_fn=<SumBackward0>)\n",
      "Epoch 594 loss is 0.8290607929229736\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5875, 0.5922, 0.6738, 0.7329, 0.6220, 0.6333, 0.7817, 0.6072, 0.7798,\n",
      "        0.5938, 0.5791], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1439,  0.2423,  0.0496, -0.0135,  0.0813, -0.0050,  0.2441, -0.0626,\n",
      "        -0.0094, -0.0669], grad_fn=<AddBackward0>)\n",
      "tensor(0.6039, grad_fn=<SumBackward0>)\n",
      "Epoch 595 loss is 0.6038956046104431\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5707, 0.6143, 0.6207, 0.6100, 0.7913, 0.7828, 0.6249, 0.8059, 0.6008,\n",
      "        0.6192, 0.6249], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0833,  0.0654,  0.2951,  0.2702,  0.0249,  0.0243, -0.0606, -0.0019,\n",
      "        -0.0603,  0.0401], grad_fn=<AddBackward0>)\n",
      "tensor(0.6804, grad_fn=<SumBackward0>)\n",
      "Epoch 596 loss is 0.6804091930389404\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7960, 0.7999, 0.7205, 0.6748, 0.7141, 0.6816, 0.6111, 0.6454, 0.7122,\n",
      "        0.6687, 0.7226], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0252, -0.0404, -0.0286, -0.0130, -0.0212, -0.0229,  0.0509,  0.0960,\n",
      "         0.1287,  0.0175], grad_fn=<AddBackward0>)\n",
      "tensor(0.1419, grad_fn=<SumBackward0>)\n",
      "Epoch 597 loss is 0.14189493656158447\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7739, 0.7251, 0.7078, 0.6601, 0.7056, 0.6755, 0.6932, 0.7479, 0.7012,\n",
      "        0.6299, 0.6971], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0220, -0.0379, -0.0065, -0.0107,  0.0552,  0.0705,  0.0428, -0.0211,\n",
      "        -0.0169, -0.0014], grad_fn=<AddBackward0>)\n",
      "tensor(0.0518, grad_fn=<SumBackward0>)\n",
      "Epoch 598 loss is 0.051809847354888916\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6174, 0.7019, 0.6596, 0.7153, 0.6783, 0.6934, 0.7381, 0.6575, 0.7051,\n",
      "        0.6685, 0.6924], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0703,  0.1631, -0.0078,  0.0564,  0.0380, -0.0070,  0.0195, -0.0232,\n",
      "         0.0582, -0.0042], grad_fn=<AddBackward0>)\n",
      "tensor(0.3631, grad_fn=<SumBackward0>)\n",
      "Epoch 599 loss is 0.3631347417831421\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9629, 0.7487, 0.7976, 0.6870, 0.7216, 0.6479, 0.7046, 0.7240, 0.6999,\n",
      "        0.7340, 0.7525], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0551, -0.0920, -0.0090, -0.0499,  0.0294,  0.0040,  0.0866,  0.0490,\n",
      "         0.0475,  0.0877], grad_fn=<AddBackward0>)\n",
      "tensor(0.0981, grad_fn=<SumBackward0>)\n",
      "Epoch 600 loss is 0.09813857078552246\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7496, 0.7151, 0.7171, 0.6933, 0.6862, 0.6655, 0.6993, 0.6653, 0.6581,\n",
      "        0.6637, 0.7013], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0108, -0.0188, -0.0097, -0.0172,  0.0101, -0.0070, -0.0025, -0.0119,\n",
      "         0.0601,  0.0720], grad_fn=<AddBackward0>)\n",
      "tensor(0.0643, grad_fn=<SumBackward0>)\n",
      "Epoch 601 loss is 0.0643458366394043\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6595, 0.6661, 0.6722, 0.7652, 0.6848, 0.6882, 0.6642, 0.6909, 0.6918,\n",
      "        0.6753, 0.6940], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0211,  0.1762,  0.0311,  0.0267, -0.0337,  0.0103,  0.0061,  0.0185,\n",
      "         0.0052,  0.0037], grad_fn=<AddBackward0>)\n",
      "tensor(0.2651, grad_fn=<SumBackward0>)\n",
      "Epoch 602 loss is 0.2651057243347168\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7024, 0.6554, 0.7565, 0.6200, 0.6631, 0.6471, 0.7192, 0.6314, 0.6595,\n",
      "        0.6826, 0.6335], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0901, -0.0275,  0.0129, -0.0365,  0.1653, -0.0106,  0.0207, -0.0122,\n",
      "         0.0036, -0.0087], grad_fn=<AddBackward0>)\n",
      "tensor(0.1971, grad_fn=<SumBackward0>)\n",
      "Epoch 603 loss is 0.19714480638504028\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6322, 0.7618, 0.7819, 0.7612, 0.8561, 0.5849, 0.5733, 0.6148, 0.6089,\n",
      "        0.5812, 0.5740], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2496,  0.2151,  0.1571, -0.0657, -0.0626, -0.0804,  0.0400,  0.0131,\n",
      "        -0.0136, -0.0116], grad_fn=<AddBackward0>)\n",
      "tensor(0.4408, grad_fn=<SumBackward0>)\n",
      "Epoch 604 loss is 0.44081127643585205\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7641, 0.5648, 0.5677, 0.8276, 0.8031, 0.5683, 0.5772, 0.8146, 0.5629,\n",
      "        0.8757, 0.8678], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0655,  0.1058,  0.3970,  0.0010, -0.0835,  0.0191, -0.0018,  0.4976,\n",
      "         0.0887,  0.5081], grad_fn=<AddBackward0>)\n",
      "tensor(1.4667, grad_fn=<SumBackward0>)\n",
      "Epoch 605 loss is 1.466660976409912\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7951, 0.8829, 0.8077, 0.8315, 0.5497, 0.5524, 0.8683, 0.5396, 0.5240,\n",
      "        0.5340, 0.5208], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0211,  0.0606, -0.1111, -0.0851,  0.0614, -0.0034, -0.0095, -0.1114,\n",
      "        -0.0062, -0.0011], grad_fn=<AddBackward0>)\n",
      "tensor(-0.1846, grad_fn=<SumBackward0>)\n",
      "Epoch 606 loss is -0.1846415400505066\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5788, 0.8270, 0.5392, 0.9033, 0.8836, 0.8254, 0.5455, 0.5467, 0.8549,\n",
      "        0.9355, 0.5073], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0132,  0.5408,  0.0943,  0.4771, -0.1193, -0.1123,  0.0492,  0.6501,\n",
      "        -0.0131, -0.1159], grad_fn=<AddBackward0>)\n",
      "tensor(1.4376, grad_fn=<SumBackward0>)\n",
      "Epoch 607 loss is 1.4376181364059448\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8071, 0.8658, 0.8680, 0.5518, 0.8794, 0.9177, 0.5219, 0.5219, 0.9112,\n",
      "        0.4959, 0.4874], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1015, -0.0851,  0.0227,  0.0829, -0.0100, -0.1191, -0.0022, -0.0087,\n",
      "        -0.0115, -0.1413], grad_fn=<AddBackward0>)\n",
      "tensor(-0.1708, grad_fn=<SumBackward0>)\n",
      "Epoch 608 loss is -0.1708458662033081\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5509, 0.8035, 0.5672, 0.5517, 0.8759, 0.8954, 0.9013, 0.4800, 0.5215,\n",
      "        0.5396, 0.5302], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0272,  0.0014,  0.1207,  0.5470,  0.5827, -0.1320, -0.1246, -0.1206,\n",
      "         0.0838,  0.0146], grad_fn=<AddBackward0>)\n",
      "tensor(1.0001, grad_fn=<SumBackward0>)\n",
      "Epoch 609 loss is 1.000135898590088\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7842, 1.0187, 0.9059, 0.8967, 0.5236, 0.8775, 0.9086, 0.5019, 0.5464,\n",
      "        0.5361, 0.8819], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2029,  0.1875, -0.1650, -0.0095,  0.0199, -0.0072, -0.1104, -0.1242,\n",
      "         0.6333,  0.5591], grad_fn=<AddBackward0>)\n",
      "tensor(1.1865, grad_fn=<SumBackward0>)\n",
      "Epoch 610 loss is 1.1864806413650513\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6117, 0.5789, 0.5517, 0.5579, 0.8979, 0.4936, 0.5107, 0.8451, 0.9173,\n",
      "        0.9749, 0.5350], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0200, -0.0180,  0.5317, -0.0194, -0.0157, -0.0176,  0.7062,  0.7738,\n",
      "        -0.1033, -0.1274], grad_fn=<AddBackward0>)\n",
      "tensor(1.6902, grad_fn=<SumBackward0>)\n",
      "Epoch 611 loss is 1.690225601196289\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5805, 0.8102, 0.8665, 0.5364, 0.5681, 0.5838, 0.7917, 0.8132, 0.8060,\n",
      "        0.5793, 0.7650], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4767, -0.0147, -0.0807, -0.0942,  0.4255,  0.4086,  0.3703, -0.0708,\n",
      "        -0.0161, -0.0137], grad_fn=<AddBackward0>)\n",
      "tensor(1.3909, grad_fn=<SumBackward0>)\n",
      "Epoch 612 loss is 1.3909001350402832\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6998, 0.8390, 0.5441, 0.5290, 0.5509, 0.8089, 0.8064, 0.5880, 0.7144,\n",
      "        0.7619, 0.8129], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0519, -0.0569, -0.0961,  0.4413,  0.4623,  0.0619, -0.0315, -0.0148,\n",
      "         0.3748,  0.1641], grad_fn=<AddBackward0>)\n",
      "tensor(1.2533, grad_fn=<SumBackward0>)\n",
      "Epoch 613 loss is 1.25327467918396\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6207, 0.7658, 0.8352, 0.7516, 0.8025, 0.8020, 0.7620, 0.6210, 0.5884,\n",
      "        0.6008, 0.6083], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.3575,  0.2181,  0.0611, -0.0111,  0.0174, -0.0605, -0.0712, -0.0537,\n",
      "        -0.0042,  0.0331], grad_fn=<AddBackward0>)\n",
      "tensor(0.4864, grad_fn=<SumBackward0>)\n",
      "Epoch 614 loss is 0.48639190196990967\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6620, 0.6573, 0.6499, 0.6255, 0.6483, 0.6104, 0.8086, 0.5956, 0.6087,\n",
      "        0.6117, 0.6089], grad_fn=<ViewBackward0>)\n",
      "tensor([-4.0566e-03, -1.2186e-02, -3.0189e-03, -1.3168e-02,  3.0526e-01,\n",
      "        -1.7548e-02, -5.5480e-04, -6.5652e-02,  2.2097e-02,  2.9683e-04],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.2115, grad_fn=<SumBackward0>)\n",
      "Epoch 615 loss is 0.2114686369895935\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7073, 0.6742, 0.7040, 0.6173, 0.7096, 0.6297, 0.6800, 0.6418, 0.6230,\n",
      "        0.7721, 0.7889], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0011, -0.0300,  0.0590, -0.0248,  0.1044, -0.0226, -0.0022,  0.1536,\n",
      "         0.2451,  0.2765], grad_fn=<AddBackward0>)\n",
      "tensor(0.7580, grad_fn=<SumBackward0>)\n",
      "Epoch 616 loss is 0.7579919695854187\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6843, 0.6752, 0.6655, 0.7329, 0.7441, 0.6647, 0.6606, 0.6865, 0.6691,\n",
      "        0.6985, 0.6717], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0063,  0.0810,  0.1149, -0.0003, -0.0241, -0.0192,  0.0074,  0.0631,\n",
      "        -0.0049,  0.0043], grad_fn=<AddBackward0>)\n",
      "tensor(0.2159, grad_fn=<SumBackward0>)\n",
      "Epoch 617 loss is 0.2159285545349121\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7398, 0.6891, 0.6715, 0.6955, 0.7996, 0.6740, 0.7063, 0.6979, 0.6718,\n",
      "        0.6547, 0.6762], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0228, -0.0148,  0.1841,  0.0041,  0.0180, -0.0339, -0.0007, -0.0172,\n",
      "        -0.0073,  0.0073], grad_fn=<AddBackward0>)\n",
      "tensor(0.1169, grad_fn=<SumBackward0>)\n",
      "Epoch 618 loss is 0.11694973707199097\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7045, 0.7296, 0.7108, 0.6663, 0.6947, 0.6926, 0.6978, 0.6717, 0.6758,\n",
      "        0.6508, 0.6862], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0105, -0.0127, -0.0116, -0.0061,  0.0526, -0.0077, -0.0056, -0.0157,\n",
      "         0.0243,  0.0173], grad_fn=<AddBackward0>)\n",
      "tensor(0.0453, grad_fn=<SumBackward0>)\n",
      "Epoch 619 loss is 0.045298874378204346\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4530, 0.7466, 0.6603, 0.6684, 0.6760, 0.7054, 0.6222, 0.7008, 0.7207,\n",
      "        0.6835, 0.7522], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.3455,  0.3589, -0.0235,  0.0752, -0.0154,  0.0414,  0.0255,  0.1021,\n",
      "         0.0856,  0.0524], grad_fn=<AddBackward0>)\n",
      "tensor(1.0477, grad_fn=<SumBackward0>)\n",
      "Epoch 620 loss is 1.0476727485656738\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6921, 0.6673, 0.6871, 0.7555, 0.6968, 0.6227, 0.6723, 0.6842, 0.6852,\n",
      "        0.6593, 0.6499], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0017,  0.1058,  0.0491, -0.0215, -0.0277, -0.0042,  0.1043, -0.0044,\n",
      "        -0.0114, -0.0118], grad_fn=<AddBackward0>)\n",
      "tensor(0.1765, grad_fn=<SumBackward0>)\n",
      "Epoch 621 loss is 0.1764952540397644\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6500, 0.7142, 0.7505, 0.6521, 0.6849, 0.6750, 0.7062, 0.6768, 0.7201,\n",
      "        0.6699, 0.7207], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1676,  0.0036, -0.0098, -0.0252,  0.0901, -0.0027,  0.0751, -0.0121,\n",
      "         0.0731,  0.0009], grad_fn=<AddBackward0>)\n",
      "tensor(0.3606, grad_fn=<SumBackward0>)\n",
      "Epoch 622 loss is 0.36063432693481445\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6962, 0.6300, 0.6682, 0.6732, 0.6305, 0.6695, 0.6961, 0.6935, 0.6863,\n",
      "        0.6927, 0.7045], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0093, -0.0077,  0.0010,  0.0021,  0.0381,  0.1050,  0.0280, -0.0011,\n",
      "         0.0184,  0.0304], grad_fn=<AddBackward0>)\n",
      "tensor(0.2048, grad_fn=<SumBackward0>)\n",
      "Epoch 623 loss is 0.20481187105178833\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7133, 0.7021, 0.7041, 0.7226, 0.7627, 0.7145, 0.7004, 0.6915, 0.6897,\n",
      "        0.6651, 0.6883], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0030,  0.0156,  0.1010,  0.0173, -0.0074, -0.0237, -0.0083, -0.0117,\n",
      "        -0.0010, -0.0004], grad_fn=<AddBackward0>)\n",
      "tensor(0.0782, grad_fn=<SumBackward0>)\n",
      "Epoch 624 loss is 0.07821810245513916\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6933, 0.7236, 0.7309, 0.7005, 0.7765, 0.7010, 0.7167, 0.6658, 0.7137,\n",
      "        0.7044, 0.6270], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0627,  0.0121,  0.0882, -0.0100,  0.0269, -0.0369,  0.0212, -0.0041,\n",
      "        -0.0129, -0.0289], grad_fn=<AddBackward0>)\n",
      "tensor(0.1183, grad_fn=<SumBackward0>)\n",
      "Epoch 625 loss is 0.11827945709228516\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7357, 0.6774, 0.6604, 0.6964, 0.7592, 0.6943, 0.7201, 0.7391, 0.6448,\n",
      "        0.7338, 0.6890], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0251, -0.0131,  0.1363,  0.0565,  0.0394, -0.0067, -0.0165,  0.0228,\n",
      "        -0.0167,  0.0737], grad_fn=<AddBackward0>)\n",
      "tensor(0.2507, grad_fn=<SumBackward0>)\n",
      "Epoch 626 loss is 0.25066983699798584\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7111, 0.6587, 0.7048, 0.6935, 0.7644, 0.6691, 0.6900, 0.7720, 0.7159,\n",
      "        0.6783, 0.6591], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0021, -0.0059,  0.1762, -0.0119, -0.0012,  0.0127,  0.0779, -0.0039,\n",
      "        -0.0376, -0.0189], grad_fn=<AddBackward0>)\n",
      "tensor(0.1853, grad_fn=<SumBackward0>)\n",
      "Epoch 627 loss is 0.18527299165725708\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6684, 0.7018, 0.6412, 0.6610, 0.7190, 0.6867, 0.7018, 0.6907, 0.6894,\n",
      "        0.6940, 0.7283], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0091, -0.0025,  0.0286,  0.0758,  0.0680, -0.0094,  0.0046, -0.0026,\n",
      "         0.0627,  0.0647], grad_fn=<AddBackward0>)\n",
      "tensor(0.2809, grad_fn=<SumBackward0>)\n",
      "Epoch 628 loss is 0.2809144854545593\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6025, 0.7567, 0.7264, 0.7052, 0.6928, 0.6418, 0.6491, 0.5945, 0.7842,\n",
      "        0.6672, 0.7393], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2066,  0.1712, -0.0213, -0.0282, -0.0187, -0.0327,  0.2373,  0.0303,\n",
      "         0.2413, -0.0150], grad_fn=<AddBackward0>)\n",
      "tensor(0.7709, grad_fn=<SumBackward0>)\n",
      "Epoch 629 loss is 0.7708783745765686\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.0416, 0.7266, 0.6467, 0.6135, 0.5778, 0.6408, 0.6863, 0.7775, 0.7286,\n",
      "        0.6494, 0.6537], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1316, -0.1427, -0.0496, -0.0020,  0.1213,  0.3329,  0.1464, -0.0123,\n",
      "        -0.0413, -0.0250], grad_fn=<AddBackward0>)\n",
      "tensor(0.1962, grad_fn=<SumBackward0>)\n",
      "Epoch 630 loss is 0.1961766481399536\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7881, 0.6447, 0.6415, 0.7525, 0.6097, 0.7431, 0.7751, 0.7850, 0.7623,\n",
      "        0.6472, 0.7879], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0489, -0.0119, -0.0117,  0.1695,  0.0377,  0.2921,  0.0320, -0.0426,\n",
      "         0.0050,  0.0427], grad_fn=<AddBackward0>)\n",
      "tensor(0.4639, grad_fn=<SumBackward0>)\n",
      "Epoch 631 loss is 0.463869571685791\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5885, 0.8015, 0.5990, 0.7793, 0.7535, 0.7676, 0.7845, 0.8309, 0.7997,\n",
      "        0.5794, 0.5623], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0175,  0.3180, -0.0160,  0.2810,  0.0086,  0.1290,  0.0536, -0.0684,\n",
      "        -0.0895, -0.0791], grad_fn=<AddBackward0>)\n",
      "tensor(0.5547, grad_fn=<SumBackward0>)\n",
      "Epoch 632 loss is 0.5547364354133606\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7976, 0.6137, 0.6299, 0.6050, 0.5635, 0.7729, 0.5826, 0.7503, 0.6152,\n",
      "        0.6103, 0.6290], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0559, -0.0642, -0.0167,  0.2384, -0.0075,  0.3112, -0.0526,  0.0461,\n",
      "        -0.0404,  0.0231], grad_fn=<AddBackward0>)\n",
      "tensor(0.3815, grad_fn=<SumBackward0>)\n",
      "Epoch 633 loss is 0.3815461993217468\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5329, 0.6373, 0.7504, 0.7942, 0.5692, 0.7665, 0.7090, 0.6723, 0.6249,\n",
      "        0.6455, 0.6053], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.3624,  0.4354, -0.0227,  0.0269, -0.0284,  0.1717, -0.0472, -0.0212,\n",
      "        -0.0223, -0.0065], grad_fn=<AddBackward0>)\n",
      "tensor(0.8481, grad_fn=<SumBackward0>)\n",
      "Epoch 634 loss is 0.8481389880180359\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8145, 0.7464, 0.7640, 0.7626, 0.7552, 0.6497, 0.6466, 0.6813, 0.6836,\n",
      "        0.7376, 0.6989], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0169, -0.0173,  0.0146, -0.0381, -0.0386, -0.0246,  0.0565,  0.1516,\n",
      "         0.0294,  0.0255], grad_fn=<AddBackward0>)\n",
      "tensor(0.1420, grad_fn=<SumBackward0>)\n",
      "Epoch 635 loss is 0.14204084873199463\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5694, 0.7728, 0.7628, 0.6502, 0.7447, 0.6326, 0.6302, 0.6423, 0.7652,\n",
      "        0.6185, 0.7578], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.3223,  0.1346, -0.0094, -0.0434, -0.0067, -0.0341,  0.2210, -0.0039,\n",
      "         0.1925, -0.0025], grad_fn=<AddBackward0>)\n",
      "tensor(0.7705, grad_fn=<SumBackward0>)\n",
      "Epoch 636 loss is 0.7705235481262207\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6306, 0.6467, 0.6470, 0.6641, 0.7063, 0.6923, 0.6661, 0.7312, 0.7292,\n",
      "        0.7315, 0.7188], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0273,  0.0558,  0.0994,  0.0756,  0.0034,  0.0416,  0.0616,  0.1090,\n",
      "        -0.0041, -0.0035], grad_fn=<AddBackward0>)\n",
      "tensor(0.4660, grad_fn=<SumBackward0>)\n",
      "Epoch 637 loss is 0.46596747636795044\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6600, 0.6915, 0.6659, 0.7180, 0.7017, 0.6858, 0.7326, 0.7040, 0.6740,\n",
      "        0.7036, 0.7563], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0099,  0.0966,  0.0170,  0.0332,  0.0244,  0.0039, -0.0039, -0.0097,\n",
      "         0.0871,  0.1371], grad_fn=<AddBackward0>)\n",
      "tensor(0.3955, grad_fn=<SumBackward0>)\n",
      "Epoch 638 loss is 0.3955375552177429\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7541, 0.6426, 0.6477, 0.6709, 0.6508, 0.7011, 0.6655, 0.7186, 0.6525,\n",
      "        0.6883, 0.6679], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0355, -0.0277,  0.0137,  0.0890, -0.0018,  0.1130, -0.0162,  0.0380,\n",
      "        -0.0169,  0.0256], grad_fn=<AddBackward0>)\n",
      "tensor(0.1811, grad_fn=<SumBackward0>)\n",
      "Epoch 639 loss is 0.18111783266067505\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5117, 0.8186, 0.6018, 0.7601, 0.6299, 0.6154, 0.7640, 0.7550, 0.6570,\n",
      "        0.6447, 0.7033], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1500,  0.4140, -0.0629,  0.0227,  0.0064,  0.2084,  0.0694, -0.0398,\n",
      "        -0.0172,  0.0772], grad_fn=<AddBackward0>)\n",
      "tensor(0.8283, grad_fn=<SumBackward0>)\n",
      "Epoch 640 loss is 0.8283207416534424\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6777, 0.6841, 0.8079, 0.6405, 0.6007, 0.7470, 0.7380, 0.7872, 0.8292,\n",
      "        0.6269, 0.7339], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2171, -0.0124, -0.0278, -0.0203,  0.1624,  0.3108,  0.1370, -0.0370,\n",
      "        -0.0178, -0.0318], grad_fn=<AddBackward0>)\n",
      "tensor(0.6803, grad_fn=<SumBackward0>)\n",
      "Epoch 641 loss is 0.6802538633346558\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6700, 0.6966, 0.6353, 0.7824, 0.6041, 0.6638, 0.6530, 0.6652, 0.8164,\n",
      "        0.7572, 0.6273], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0116,  0.1874, -0.0308,  0.0475, -0.0431,  0.1018,  0.2544,  0.1736,\n",
      "        -0.0126, -0.0630], grad_fn=<AddBackward0>)\n",
      "tensor(0.6035, grad_fn=<SumBackward0>)\n",
      "Epoch 642 loss is 0.6034752130508423\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6599, 0.6492, 0.6360, 0.7497, 0.7504, 0.8338, 0.6076, 0.7445, 0.7252,\n",
      "        0.6154, 0.8048], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0080,  0.1497,  0.1687,  0.3298, -0.0474, -0.0020, -0.0362,  0.0129,\n",
      "         0.1005,  0.1327], grad_fn=<AddBackward0>)\n",
      "tensor(0.8007, grad_fn=<SumBackward0>)\n",
      "Epoch 643 loss is 0.8006885647773743\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6430, 0.7832, 0.7807, 0.7545, 0.7195, 0.6461, 0.6494, 0.6371, 0.7200,\n",
      "        0.6139, 0.7737], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2295,  0.1859, -0.0212, -0.0449, -0.0350, -0.0275,  0.1233, -0.0118,\n",
      "         0.2276,  0.0894], grad_fn=<AddBackward0>)\n",
      "tensor(0.7152, grad_fn=<SumBackward0>)\n",
      "Epoch 644 loss is 0.7151687741279602\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7123, 0.7174, 0.6449, 0.6988, 0.6790, 0.7738, 0.5538, 0.6323, 0.6882,\n",
      "        0.6645, 0.6302], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0225, -0.0045, -0.0128,  0.2148, -0.0483, -0.0156, -0.0285,  0.1845,\n",
      "        -0.0007, -0.0193], grad_fn=<AddBackward0>)\n",
      "tensor(0.2471, grad_fn=<SumBackward0>)\n",
      "Epoch 645 loss is 0.24707210063934326\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6577, 0.6846, 0.6757, 0.7229, 0.7204, 0.7924, 0.6320, 0.7440, 0.8197,\n",
      "        0.6114, 0.6434], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0301,  0.1087,  0.0597,  0.1944, -0.0303,  0.0393,  0.0455, -0.0069,\n",
      "        -0.0335, -0.0587], grad_fn=<AddBackward0>)\n",
      "tensor(0.3483, grad_fn=<SumBackward0>)\n",
      "Epoch 646 loss is 0.3483085632324219\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6603, 0.6857, 0.6291, 0.6468, 0.7215, 0.6423, 0.6794, 0.6395, 0.7043,\n",
      "        0.6587, 0.6975], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0104, -0.0045,  0.0596,  0.0219,  0.0544, -0.0273,  0.1035, -0.0069,\n",
      "         0.0966, -0.0023], grad_fn=<AddBackward0>)\n",
      "tensor(0.2846, grad_fn=<SumBackward0>)\n",
      "Epoch 647 loss is 0.2846262454986572\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7747, 0.7739, 0.7289, 0.7108, 0.7024, 0.6886, 0.6741, 0.6708, 0.6870,\n",
      "        0.6944, 0.6509], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0153, -0.0213, -0.0238, -0.0135, -0.0122, -0.0105, -0.0005,  0.0338,\n",
      "        -0.0066, -0.0120], grad_fn=<AddBackward0>)\n",
      "tensor(-0.0820, grad_fn=<SumBackward0>)\n",
      "Epoch 648 loss is -0.08199936151504517\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7945, 0.6436, 0.6954, 0.7132, 0.7296, 0.7358, 0.6596, 0.6207, 0.5933,\n",
      "        0.7292, 0.6451], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0330, -0.0271,  0.1433,  0.0673, -0.0179, -0.0363, -0.0475,  0.1161,\n",
      "         0.0407,  0.0863], grad_fn=<AddBackward0>)\n",
      "tensor(0.2919, grad_fn=<SumBackward0>)\n",
      "Epoch 649 loss is 0.29187828302383423\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.0863, 0.6273, 0.7431, 0.6099, 0.6067, 0.6119, 0.7769, 0.7409, 0.7742,\n",
      "        0.7615, 0.6302], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1144, -0.1588, -0.0069, -0.0437,  0.2784,  0.2236,  0.2705, -0.0051,\n",
      "        -0.0369, -0.0480], grad_fn=<AddBackward0>)\n",
      "tensor(0.3588, grad_fn=<SumBackward0>)\n",
      "Epoch 650 loss is 0.35877829790115356\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5852, 0.5453, 0.7647, 0.7706, 0.7906, 0.5923, 0.6883, 0.7576, 0.8085,\n",
      "        0.8390, 0.6038], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2992,  0.3091,  0.4088, -0.0575, -0.0274, -0.0110,  0.3604,  0.2512,\n",
      "        -0.0513, -0.0682], grad_fn=<AddBackward0>)\n",
      "tensor(1.4133, grad_fn=<SumBackward0>)\n",
      "Epoch 651 loss is 1.4132509231567383\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9037, 0.8073, 0.5983, 0.5969, 0.7571, 0.6314, 0.5732, 0.8019, 0.7729,\n",
      "        0.7951, 0.8141], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1018, -0.1022, -0.0167,  0.0552, -0.0079,  0.0748,  0.2358,  0.3698,\n",
      "         0.0202,  0.0686], grad_fn=<AddBackward0>)\n",
      "tensor(0.5957, grad_fn=<SumBackward0>)\n",
      "Epoch 652 loss is 0.5957417488098145\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5793, 0.5922, 0.5586, 0.8255, 0.8307, 0.5628, 0.7939, 0.5663, 0.7977,\n",
      "        0.6365, 0.5983], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0069,  0.4103,  0.3974,  0.0071, -0.0105, -0.0881,  0.3915, -0.0525,\n",
      "         0.0533, -0.0665], grad_fn=<AddBackward0>)\n",
      "tensor(1.0350, grad_fn=<SumBackward0>)\n",
      "Epoch 653 loss is 1.0350381135940552\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5563, 0.8521, 0.5883, 0.8143, 0.5794, 0.7610, 0.5981, 0.8001, 0.7916,\n",
      "        0.8059, 0.5747], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0534,  0.4301, -0.0909,  0.2878, -0.0721,  0.3678,  0.0510,  0.3464,\n",
      "        -0.0751, -0.0723], grad_fn=<AddBackward0>)\n",
      "tensor(1.2261, grad_fn=<SumBackward0>)\n",
      "Epoch 654 loss is 1.226102590560913\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8252, 0.6388, 0.6201, 0.7417, 0.6543, 0.6226, 0.7815, 0.7671, 0.6607,\n",
      "        0.7623, 0.7449], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0684, -0.0278,  0.0259,  0.0042,  0.0664,  0.1879,  0.0635, -0.0064,\n",
      "        -0.0074,  0.1403], grad_fn=<AddBackward0>)\n",
      "tensor(0.3782, grad_fn=<SumBackward0>)\n",
      "Epoch 655 loss is 0.3782241940498352\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7578, 0.6584, 0.7238, 0.6527, 0.7362, 0.7436, 0.5609, 0.8164, 0.7737,\n",
      "        0.7482, 0.6163], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0113, -0.0350,  0.1296,  0.0330, -0.0306,  0.1337,  0.0502,  0.3122,\n",
      "        -0.0667, -0.0525], grad_fn=<AddBackward0>)\n",
      "tensor(0.4625, grad_fn=<SumBackward0>)\n",
      "Epoch 656 loss is 0.46253424882888794\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6734, 0.7295, 0.6287, 0.7312, 0.6827, 0.6255, 0.7349, 0.7200, 0.6111,\n",
      "        0.6513, 0.6201], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0149,  0.0964, -0.0156, -0.0011,  0.0061,  0.0622, -0.0048, -0.0278,\n",
      "        -0.0333,  0.0150], grad_fn=<AddBackward0>)\n",
      "tensor(0.0822, grad_fn=<SumBackward0>)\n",
      "Epoch 657 loss is 0.0821642279624939\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8041, 0.7038, 0.7588, 0.7105, 0.7433, 0.6630, 0.7135, 0.7542, 0.7370,\n",
      "        0.6165, 0.7261], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0151, -0.0312,  0.0657, -0.0319,  0.0049,  0.0182,  0.1234, -0.0323,\n",
      "        -0.0094, -0.0036], grad_fn=<AddBackward0>)\n",
      "tensor(0.0886, grad_fn=<SumBackward0>)\n",
      "Epoch 658 loss is 0.08863437175750732\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6373, 0.6866, 0.6829, 0.7193, 0.7209, 0.6860, 0.7164, 0.6750, 0.7009,\n",
      "        0.6552, 0.6505], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0761,  0.1368,  0.0573,  0.0051, -0.0010, -0.0153,  0.0248, -0.0204,\n",
      "        -0.0082, -0.0168], grad_fn=<AddBackward0>)\n",
      "tensor(0.2383, grad_fn=<SumBackward0>)\n",
      "Epoch 659 loss is 0.23834824562072754\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9258, 0.8399, 0.5813, 0.8801, 0.7103, 0.6645, 0.6784, 0.6900, 0.7010,\n",
      "        0.7704, 0.8182], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1148, -0.0152, -0.0432,  0.1386, -0.0673, -0.0068,  0.0610,  0.1534,\n",
      "         0.2136,  0.1953], grad_fn=<AddBackward0>)\n",
      "tensor(0.5146, grad_fn=<SumBackward0>)\n",
      "Epoch 660 loss is 0.5146375894546509\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6853, 0.7393, 0.7286, 0.7122, 0.7829, 0.6152, 0.6812, 0.7594, 0.7763,\n",
      "        0.6473, 0.7950], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0722,  0.0448,  0.0727, -0.0378, -0.0103, -0.0078,  0.2684, -0.0113,\n",
      "         0.0594,  0.0313], grad_fn=<AddBackward0>)\n",
      "tensor(0.4814, grad_fn=<SumBackward0>)\n",
      "Epoch 661 loss is 0.48143428564071655\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7073, 0.6500, 0.6178, 0.6422, 0.7237, 0.7599, 0.5926, 0.7909, 0.6183,\n",
      "        0.7614, 0.6226], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0298, -0.0217,  0.1229,  0.2367, -0.0165,  0.1119, -0.0472,  0.2813,\n",
      "        -0.0561,  0.0072], grad_fn=<AddBackward0>)\n",
      "tensor(0.5888, grad_fn=<SumBackward0>)\n",
      "Epoch 662 loss is 0.5887529850006104\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6830, 0.6013, 0.6390, 0.6629, 0.6809, 0.6980, 0.7207, 0.7231, 0.6144,\n",
      "        0.6559, 0.6707], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0147, -0.0067,  0.1326,  0.0983,  0.0962,  0.0703, -0.0279, -0.0216,\n",
      "        -0.0175,  0.0939], grad_fn=<AddBackward0>)\n",
      "tensor(0.4032, grad_fn=<SumBackward0>)\n",
      "Epoch 663 loss is 0.4031660556793213\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6614, 0.6659, 0.7667, 0.7424, 0.7213, 0.6318, 0.6511, 0.6531, 0.7622,\n",
      "        0.6342, 0.6279], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1755,  0.1350,  0.0924, -0.0450, -0.0304, -0.0227,  0.2173, -0.0056,\n",
      "        -0.0084, -0.0448], grad_fn=<AddBackward0>)\n",
      "tensor(0.4632, grad_fn=<SumBackward0>)\n",
      "Epoch 664 loss is 0.4631880521774292\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6978, 0.6925, 0.6331, 0.6361, 0.7510, 0.7493, 0.7093, 0.6624, 0.7195,\n",
      "        0.6636, 0.7339], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0216, -0.0206,  0.0975,  0.1936,  0.1219, -0.0296, -0.0099, -0.0152,\n",
      "         0.1192,  0.0240], grad_fn=<AddBackward0>)\n",
      "tensor(0.4594, grad_fn=<SumBackward0>)\n",
      "Epoch 665 loss is 0.45941609144210815\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7244, 0.6773, 0.6970, 0.7486, 0.7022, 0.7191, 0.6576, 0.6204, 0.6383,\n",
      "        0.6845, 0.7164], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0091,  0.0402,  0.0416,  0.0367, -0.0303, -0.0273, -0.0269,  0.0447,\n",
      "         0.1600,  0.1301], grad_fn=<AddBackward0>)\n",
      "tensor(0.3598, grad_fn=<SumBackward0>)\n",
      "Epoch 666 loss is 0.35977447032928467\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6309, 0.6619, 0.6998, 0.6400, 0.6669, 0.6834, 0.6526, 0.7021, 0.7007,\n",
      "        0.6211, 0.7079], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1149,  0.0152,  0.0083, -0.0055,  0.0211,  0.0586,  0.0288, -0.0105,\n",
      "         0.0097,  0.0120], grad_fn=<AddBackward0>)\n",
      "tensor(0.2525, grad_fn=<SumBackward0>)\n",
      "Epoch 667 loss is 0.252527117729187\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6373, 0.6864, 0.6469, 0.6745, 0.7306, 0.7042, 0.6946, 0.6900, 0.6831,\n",
      "        0.6685, 0.7192], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0161,  0.0621,  0.0736,  0.0955,  0.0335, -0.0135, -0.0070, -0.0087,\n",
      "         0.0486,  0.0602], grad_fn=<AddBackward0>)\n",
      "tensor(0.3604, grad_fn=<SumBackward0>)\n",
      "Epoch 668 loss is 0.3603947162628174\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6610, 0.6565, 0.7319, 0.7283, 0.6587, 0.6051, 0.7917, 0.6610, 0.6376,\n",
      "        0.7149, 0.7309], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1183,  0.1123,  0.0037, -0.0423,  0.1056,  0.0038,  0.0541, -0.0256,\n",
      "         0.1165,  0.1556], grad_fn=<AddBackward0>)\n",
      "tensor(0.6019, grad_fn=<SumBackward0>)\n",
      "Epoch 669 loss is 0.6019380688667297\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4527, 0.6532, 0.6674, 0.7056, 0.7858, 0.7479, 0.7257, 0.6096, 0.6226,\n",
      "        0.7359, 0.6775], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.3578,  0.4214,  0.2209,  0.1342,  0.0336, -0.0587, -0.0418,  0.0169,\n",
      "         0.1132,  0.0915], grad_fn=<AddBackward0>)\n",
      "tensor(1.2890, grad_fn=<SumBackward0>)\n",
      "Epoch 670 loss is 1.2890336513519287\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8171, 0.6569, 0.8126, 0.7731, 0.6554, 0.5904, 0.6441, 0.6176, 0.7801,\n",
      "        0.6086, 0.7467], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0015, -0.0147, -0.0005, -0.0741, -0.0430, -0.0126,  0.3161, -0.0119,\n",
      "         0.2152, -0.0111], grad_fn=<AddBackward0>)\n",
      "tensor(0.3620, grad_fn=<SumBackward0>)\n",
      "Epoch 671 loss is 0.3619738817214966\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8477, 0.7805, 0.8349, 0.5469, 0.5931, 0.5991, 0.8390, 0.6207, 0.7360,\n",
      "        0.6439, 0.7612], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0043, -0.1002, -0.0625, -0.0786,  0.4868,  0.0459,  0.2282, -0.0650,\n",
      "         0.2342,  0.0420], grad_fn=<AddBackward0>)\n",
      "tensor(0.7265, grad_fn=<SumBackward0>)\n",
      "Epoch 672 loss is 0.7264869213104248\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8231, 0.8490, 0.5805, 0.8003, 0.5922, 0.7800, 0.6902, 0.5528, 0.5883,\n",
      "        0.7754, 0.8002], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0809, -0.0076, -0.0856,  0.3325, -0.0367, -0.0131, -0.0639,  0.1420,\n",
      "         0.4123,  0.3532], grad_fn=<AddBackward0>)\n",
      "tensor(0.9522, grad_fn=<SumBackward0>)\n",
      "Epoch 673 loss is 0.9522412419319153\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5835, 0.8259, 0.5625, 0.8237, 0.6412, 0.7875, 0.8235, 0.8035, 0.8693,\n",
      "        0.8451, 0.5780], grad_fn=<ViewBackward0>)\n",
      "tensor([-6.9910e-03,  4.0038e-01, -6.1561e-02,  3.7506e-01, -4.7266e-05,\n",
      "         2.7058e-01,  1.3628e-01,  3.5977e-02, -7.5166e-02, -9.7078e-02],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.9774, grad_fn=<SumBackward0>)\n",
      "Epoch 674 loss is 0.9774329662322998\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5830, 0.5999, 0.7807, 0.8179, 0.6016, 0.8063, 0.5908, 0.7818, 0.6009,\n",
      "        0.5895, 0.5768], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.3296,  0.3915,  0.0028,  0.0426, -0.0757,  0.3004, -0.0685, -0.0005,\n",
      "        -0.0683, -0.0080], grad_fn=<AddBackward0>)\n",
      "tensor(0.8459, grad_fn=<SumBackward0>)\n",
      "Epoch 675 loss is 0.8459237813949585\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5172, 0.6041, 0.7684, 0.6435, 0.6009, 0.7415, 0.6585, 0.7905, 0.6238,\n",
      "        0.7969, 0.7376], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4185,  0.2104, -0.0011, -0.0089,  0.0250,  0.3160, -0.0392,  0.2306,\n",
      "        -0.0176,  0.1897], grad_fn=<AddBackward0>)\n",
      "tensor(1.3234, grad_fn=<SumBackward0>)\n",
      "Epoch 676 loss is 1.3234461545944214\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8221, 0.6344, 0.5846, 0.7856, 0.7760, 0.7598, 0.7673, 0.5682, 0.5914,\n",
      "        0.5969, 0.7709], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0791, -0.0122,  0.2359,  0.2919, -0.0061, -0.0693, -0.0561, -0.0568,\n",
      "         0.3377,  0.2991], grad_fn=<AddBackward0>)\n",
      "tensor(0.8851, grad_fn=<SumBackward0>)\n",
      "Epoch 677 loss is 0.8851091861724854\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5967, 0.7336, 0.7262, 0.6868, 0.6531, 0.7185, 0.7083, 0.7170, 0.6764,\n",
      "        0.6650, 0.6513], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2160,  0.1502, -0.0269, -0.0026,  0.0358,  0.1065, -0.0140, -0.0144,\n",
      "        -0.0219, -0.0084], grad_fn=<AddBackward0>)\n",
      "tensor(0.4203, grad_fn=<SumBackward0>)\n",
      "Epoch 678 loss is 0.420279860496521\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7499, 0.7185, 0.6326, 0.6894, 0.6322, 0.7186, 0.7114, 0.7096, 0.6881,\n",
      "        0.6543, 0.7305], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0391, -0.0202, -0.0288,  0.1434,  0.0367,  0.1290, -0.0102, -0.0190,\n",
      "         0.0348,  0.0706], grad_fn=<AddBackward0>)\n",
      "tensor(0.2972, grad_fn=<SumBackward0>)\n",
      "Epoch 679 loss is 0.29722821712493896\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.0124, 0.7973, 0.6695, 0.6591, 0.6593, 0.6934, 0.7379, 0.6336, 0.6370,\n",
      "        0.7273, 0.6791], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1143, -0.1178, -0.0460,  0.0397,  0.1314, -0.0086, -0.0188, -0.0035,\n",
      "         0.0757,  0.0701], grad_fn=<AddBackward0>)\n",
      "tensor(0.0080, grad_fn=<SumBackward0>)\n",
      "Epoch 680 loss is 0.007959485054016113\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7457, 0.6883, 0.6830, 0.7032, 0.6879, 0.6838, 0.7323, 0.7592, 0.5945,\n",
      "        0.7339, 0.6541], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0209, -0.0142, -0.0001,  0.0015,  0.0485,  0.1189, -0.0298,  0.0026,\n",
      "        -0.0350,  0.0993], grad_fn=<AddBackward0>)\n",
      "tensor(0.1707, grad_fn=<SumBackward0>)\n",
      "Epoch 681 loss is 0.1707322597503662\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6219, 0.6859, 0.6528, 0.7583, 0.7527, 0.6509, 0.6806, 0.6602, 0.6569,\n",
      "        0.7475, 0.7195], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0515,  0.2273,  0.1114, -0.0006, -0.0259, -0.0308,  0.0100,  0.1115,\n",
      "         0.0988,  0.1043], grad_fn=<AddBackward0>)\n",
      "tensor(0.6574, grad_fn=<SumBackward0>)\n",
      "Epoch 682 loss is 0.657376766204834\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6442, 0.6856, 0.6712, 0.6178, 0.6293, 0.6605, 0.6142, 0.7743, 0.6892,\n",
      "        0.6172, 0.7632], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0450, -0.0088, -0.0188, -0.0036, -0.0012,  0.2417,  0.0478,  0.0051,\n",
      "        -0.0037,  0.1233], grad_fn=<AddBackward0>)\n",
      "tensor(0.4269, grad_fn=<SumBackward0>)\n",
      "Epoch 683 loss is 0.42687302827835083\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6866, 0.6571, 0.7678, 0.7655, 0.7456, 0.7857, 0.7863, 0.6399, 0.6348,\n",
      "        0.7388, 0.6203], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1353,  0.1315,  0.1475,  0.0298,  0.0347, -0.0352, -0.0503, -0.0158,\n",
      "        -0.0065, -0.0048], grad_fn=<AddBackward0>)\n",
      "tensor(0.3662, grad_fn=<SumBackward0>)\n",
      "Epoch 684 loss is 0.366232693195343\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7115, 0.6268, 0.6324, 0.6223, 0.7521, 0.7470, 0.7246, 0.6376, 0.6345,\n",
      "        0.7439, 0.6280], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0264, -0.0297,  0.2088,  0.1911,  0.1706, -0.0382, -0.0375,  0.0321,\n",
      "        -0.0032, -0.0022], grad_fn=<AddBackward0>)\n",
      "tensor(0.4654, grad_fn=<SumBackward0>)\n",
      "Epoch 685 loss is 0.46543580293655396\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6689, 0.7132, 0.7415, 0.7619, 0.5931, 0.7432, 0.6773, 0.6597, 0.7714,\n",
      "        0.7007, 0.6517], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1210,  0.1550, -0.0400,  0.0029, -0.0282,  0.1110,  0.0470,  0.0390,\n",
      "        -0.0027, -0.0399], grad_fn=<AddBackward0>)\n",
      "tensor(0.3651, grad_fn=<SumBackward0>)\n",
      "Epoch 686 loss is 0.3651347756385803\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7087, 0.7400, 0.7193, 0.6390, 0.6536, 0.6975, 0.7066, 0.7222, 0.6787,\n",
      "        0.6424, 0.7186], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0177, -0.0232, -0.0288, -0.0073,  0.1127,  0.1143, -0.0063, -0.0214,\n",
      "        -0.0012,  0.0665], grad_fn=<AddBackward0>)\n",
      "tensor(0.2230, grad_fn=<SumBackward0>)\n",
      "Epoch 687 loss is 0.2230270504951477\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7292, 0.6952, 0.6946, 0.7019, 0.6798, 0.7088, 0.6833, 0.7496, 0.6646,\n",
      "        0.7242, 0.6787], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0115, -0.0091, -0.0051,  0.0236, -0.0062,  0.1163, -0.0147,  0.0681,\n",
      "        -0.0236,  0.0235], grad_fn=<AddBackward0>)\n",
      "tensor(0.1612, grad_fn=<SumBackward0>)\n",
      "Epoch 688 loss is 0.16122937202453613\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7617, 0.7113, 0.6802, 0.7192, 0.6689, 0.6891, 0.6824, 0.6750, 0.6439,\n",
      "        0.6526, 0.7953], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0272, -0.0142, -0.0141,  0.0149, -0.0122,  0.0102, -0.0151, -0.0099,\n",
      "         0.2005,  0.2523], grad_fn=<AddBackward0>)\n",
      "tensor(0.3851, grad_fn=<SumBackward0>)\n",
      "Epoch 689 loss is 0.38512855768203735\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4522, 0.7808, 0.6269, 0.6782, 0.6761, 0.6937, 0.6917, 0.6380, 0.6796,\n",
      "        0.6792, 0.6914], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2912,  0.3767, -0.0349,  0.1114,  0.0225, -0.0127, -0.0047, -0.0041,\n",
      "         0.0891,  0.0197], grad_fn=<AddBackward0>)\n",
      "tensor(0.8541, grad_fn=<SumBackward0>)\n",
      "Epoch 690 loss is 0.8541173934936523\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8086, 0.7650, 0.6494, 0.7483, 0.7192, 0.7044, 0.6234, 0.7308, 0.6573,\n",
      "        0.6442, 0.6901], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0530, -0.0201, -0.0153,  0.0915, -0.0416,  0.0193, -0.0157,  0.0347,\n",
      "        -0.0136,  0.0546], grad_fn=<AddBackward0>)\n",
      "tensor(0.0408, grad_fn=<SumBackward0>)\n",
      "Epoch 691 loss is 0.04075199365615845\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8334, 0.7696, 0.8068, 0.7487, 0.6086, 0.6654, 0.6018, 0.6641, 0.6296,\n",
      "        0.6421, 0.7349], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0089, -0.0282, -0.0536, -0.0471, -0.0490,  0.0924, -0.0119,  0.0672,\n",
      "         0.1181,  0.1755], grad_fn=<AddBackward0>)\n",
      "tensor(0.2544, grad_fn=<SumBackward0>)\n",
      "Epoch 692 loss is 0.254397988319397\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5713, 0.7434, 0.6248, 0.8000, 0.7774, 0.7982, 0.5827, 0.7756, 0.7595,\n",
      "        0.6116, 0.6184], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0892,  0.3811,  0.0567,  0.2890, -0.0724, -0.0006, -0.0129,  0.0482,\n",
      "        -0.0524, -0.0470], grad_fn=<AddBackward0>)\n",
      "tensor(0.6788, grad_fn=<SumBackward0>)\n",
      "Epoch 693 loss is 0.6787877082824707\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8113, 0.5625, 0.8432, 0.7907, 0.8158, 0.4998, 0.5219, 0.8773, 0.7881,\n",
      "        0.5781, 0.5530], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0532, -0.0069,  0.4222, -0.1145, -0.0896,  0.1025,  0.4806,  0.0937,\n",
      "        -0.1081, -0.0784], grad_fn=<AddBackward0>)\n",
      "tensor(0.7548, grad_fn=<SumBackward0>)\n",
      "Epoch 694 loss is 0.7548376321792603\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8708, 0.5723, 0.8157, 0.8279, 0.8304, 0.5636, 0.8657, 0.8173, 0.7818,\n",
      "        0.7776, 0.8425], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0184, -0.0143,  0.4302, -0.0840,  0.0630, -0.0044,  0.3636, -0.0293,\n",
      "         0.0420,  0.1012], grad_fn=<AddBackward0>)\n",
      "tensor(0.8495, grad_fn=<SumBackward0>)\n",
      "Epoch 695 loss is 0.849471390247345\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8804, 0.8035, 0.6143, 0.6059, 0.7729, 0.7867, 0.8516, 0.5759, 0.7959,\n",
      "        0.6177, 0.8095], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0887, -0.0915, -0.0102,  0.2873,  0.4094, -0.0657,  0.0153, -0.0779,\n",
      "         0.3894,  0.0227], grad_fn=<AddBackward0>)\n",
      "tensor(0.7902, grad_fn=<SumBackward0>)\n",
      "Epoch 696 loss is 0.7901788949966431\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6020, 0.7849, 0.7732, 0.8032, 0.7646, 0.7478, 0.7272, 0.7662, 0.8146,\n",
      "        0.6058, 0.8182], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2853,  0.3353, -0.0068, -0.0085, -0.0253,  0.0027,  0.1113, -0.0405,\n",
      "         0.0866,  0.0059], grad_fn=<AddBackward0>)\n",
      "tensor(0.7462, grad_fn=<SumBackward0>)\n",
      "Epoch 697 loss is 0.746171236038208\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7536, 0.6624, 0.6989, 0.7415, 0.7537, 0.7238, 0.6440, 0.7549, 0.7176,\n",
      "        0.7583, 0.8155], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0182, -0.0040,  0.1521,  0.0416, -0.0325,  0.0021, -0.0021,  0.1904,\n",
      "         0.1009,  0.1632], grad_fn=<AddBackward0>)\n",
      "tensor(0.5935, grad_fn=<SumBackward0>)\n",
      "Epoch 698 loss is 0.5935440063476562\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6652, 0.6745, 0.6928, 0.6742, 0.6722, 0.6696, 0.7059, 0.7123, 0.7227,\n",
      "        0.6253, 0.6678], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0460,  0.0151, -0.0008, -0.0077,  0.0528,  0.0667,  0.0886, -0.0269,\n",
      "        -0.0148, -0.0183], grad_fn=<AddBackward0>)\n",
      "tensor(0.2007, grad_fn=<SumBackward0>)\n",
      "Epoch 699 loss is 0.2007354497909546\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5729, 0.9036, 0.8196, 0.6319, 0.7335, 0.6258, 0.7357, 0.7490, 0.7608,\n",
      "        0.5998, 0.7539], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4111,  0.0982, -0.0567, -0.0646,  0.1731,  0.0259,  0.2251, -0.0453,\n",
      "         0.0082, -0.0023], grad_fn=<AddBackward0>)\n",
      "tensor(0.7726, grad_fn=<SumBackward0>)\n",
      "Epoch 700 loss is 0.7726275324821472\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7085, 0.6102, 0.8013, 0.7862, 0.7837, 0.5987, 0.6052, 0.8478, 0.6111,\n",
      "        0.5903, 0.5549], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1546,  0.1294,  0.2892, -0.0675, -0.0603,  0.1068,  0.0207, -0.0050,\n",
      "        -0.0976, -0.0187], grad_fn=<AddBackward0>)\n",
      "tensor(0.4516, grad_fn=<SumBackward0>)\n",
      "Epoch 701 loss is 0.4515543580055237\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7157, 0.6057, 0.8059, 0.6217, 0.5612, 0.8329, 0.7707, 0.7797, 0.6111,\n",
      "        0.8324, 0.7363], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1504, -0.0313, -0.0148,  0.0450,  0.2484,  0.3642, -0.0739,  0.1028,\n",
      "        -0.0145,  0.2086], grad_fn=<AddBackward0>)\n",
      "tensor(0.9847, grad_fn=<SumBackward0>)\n",
      "Epoch 702 loss is 0.9847224354743958\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6384, 0.8282, 0.8622, 0.5612, 0.7670, 0.6048, 0.8355, 0.8226, 0.8072,\n",
      "        0.7777, 0.5946], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.3729, -0.0257, -0.0204, -0.0858,  0.4572,  0.0926,  0.3374, -0.0193,\n",
      "        -0.0760, -0.0709], grad_fn=<AddBackward0>)\n",
      "tensor(0.9620, grad_fn=<SumBackward0>)\n",
      "Epoch 703 loss is 0.9619659185409546\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6834, 0.6269, 0.8477, 0.8153, 0.8011, 0.5511, 0.8105, 0.5506, 0.5432,\n",
      "        0.8210, 0.8104], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2737,  0.2198,  0.2904, -0.0989, -0.0016, -0.0835, -0.0026,  0.0175,\n",
      "         0.4330,  0.4454], grad_fn=<AddBackward0>)\n",
      "tensor(1.4933, grad_fn=<SumBackward0>)\n",
      "Epoch 704 loss is 1.4932842254638672\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6351, 0.8986, 0.5543, 0.5567, 0.8464, 0.7833, 0.5755, 0.6030, 0.5765,\n",
      "        0.5991, 0.5883], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0269, -0.0261, -0.0174,  0.3816,  0.0313, -0.0811, -0.0689,  0.0393,\n",
      "        -0.0049,  0.0196], grad_fn=<AddBackward0>)\n",
      "tensor(0.2464, grad_fn=<SumBackward0>)\n",
      "Epoch 705 loss is 0.24636155366897583\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6876, 0.7626, 0.5887, 0.7756, 0.7342, 0.7219, 0.5956, 0.8424, 0.8552,\n",
      "        0.5776, 0.7959], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0330,  0.1467, -0.0095,  0.2219, -0.0600,  0.1803,  0.2222, -0.0060,\n",
      "        -0.0155, -0.0197], grad_fn=<AddBackward0>)\n",
      "tensor(0.6275, grad_fn=<SumBackward0>)\n",
      "Epoch 706 loss is 0.6274610161781311\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6653, 0.7586, 0.5927, 0.7931, 0.7791, 0.7595, 0.7815, 0.7375, 0.7493,\n",
      "        0.5906, 0.5921], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0242,  0.2129,  0.0341,  0.2780, -0.0038, -0.0139, -0.0034, -0.0636,\n",
      "        -0.0485, -0.0524], grad_fn=<AddBackward0>)\n",
      "tensor(0.3152, grad_fn=<SumBackward0>)\n",
      "Epoch 707 loss is 0.31522732973098755\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6865, 0.6637, 0.5849, 0.7602, 0.6095, 0.6067, 0.6431, 0.6191, 0.6139,\n",
      "        0.8796, 0.6548], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0339,  0.1229, -0.0181,  0.0364, -0.0390,  0.0160,  0.0120,  0.3942,\n",
      "         0.0595,  0.0682], grad_fn=<AddBackward0>)\n",
      "tensor(0.6182, grad_fn=<SumBackward0>)\n",
      "Epoch 708 loss is 0.6181900501251221\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6845, 0.7030, 0.6799, 0.7665, 0.6583, 0.6367, 0.6403, 0.6504, 0.6516,\n",
      "        0.7275, 0.6432], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0015,  0.1367, -0.0149, -0.0144, -0.0421, -0.0026,  0.0248,  0.1454,\n",
      "        -0.0024, -0.0028], grad_fn=<AddBackward0>)\n",
      "tensor(0.2262, grad_fn=<SumBackward0>)\n",
      "Epoch 709 loss is 0.2261611819267273\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5264, 0.5552, 0.8317, 0.6411, 0.7769, 0.7277, 0.6608, 0.6271, 0.8260,\n",
      "        0.5956, 0.5984], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.5090,  0.1912,  0.3696, -0.0347,  0.0329, -0.0499,  0.1639, -0.0218,\n",
      "        -0.0096, -0.0759], grad_fn=<AddBackward0>)\n",
      "tensor(1.0748, grad_fn=<SumBackward0>)\n",
      "Epoch 710 loss is 1.0747721195220947\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7184, 0.6767, 0.6869, 0.7219, 0.8138, 0.7453, 0.7424, 0.6544, 0.5924,\n",
      "        0.6230, 0.7333], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0105,  0.0059,  0.2285,  0.0974,  0.0341, -0.0531, -0.0510, -0.0398,\n",
      "         0.1316,  0.2349], grad_fn=<AddBackward0>)\n",
      "tensor(0.5780, grad_fn=<SumBackward0>)\n",
      "Epoch 711 loss is 0.5779593586921692\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7297, 0.6326, 0.7389, 0.6555, 0.6703, 0.6507, 0.6754, 0.6819, 0.6936,\n",
      "        0.7004, 0.6646], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0155, -0.0247,  0.0628, -0.0294,  0.0331,  0.0195,  0.0716,  0.0418,\n",
      "        -0.0058, -0.0097], grad_fn=<AddBackward0>)\n",
      "tensor(0.1747, grad_fn=<SumBackward0>)\n",
      "Epoch 712 loss is 0.17467308044433594\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6915, 0.6810, 0.6881, 0.6760, 0.7102, 0.7407, 0.6642, 0.7320, 0.7066,\n",
      "        0.7014, 0.6960], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0012, -0.0052,  0.0486,  0.0878, -0.0039,  0.0362, -0.0114,  0.0621,\n",
      "        -0.0120, -0.0035], grad_fn=<AddBackward0>)\n",
      "tensor(0.1976, grad_fn=<SumBackward0>)\n",
      "Epoch 713 loss is 0.19759011268615723\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7089, 0.6938, 0.6501, 0.7501, 0.6858, 0.7096, 0.7327, 0.6714, 0.7247,\n",
      "        0.6965, 0.6703], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0196,  0.0687, -0.0026,  0.0993, -0.0058, -0.0048,  0.0252, -0.0121,\n",
      "        -0.0004, -0.0181], grad_fn=<AddBackward0>)\n",
      "tensor(0.1297, grad_fn=<SumBackward0>)\n",
      "Epoch 714 loss is 0.12969636917114258\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6109, 0.6995, 0.7237, 0.6689, 0.6722, 0.7534, 0.7369, 0.6993, 0.6833,\n",
      "        0.6685, 0.7118], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1880,  0.0966, -0.0091,  0.0494,  0.1134,  0.0451, -0.0234, -0.0228,\n",
      "         0.0208,  0.0475], grad_fn=<AddBackward0>)\n",
      "tensor(0.5057, grad_fn=<SumBackward0>)\n",
      "Epoch 715 loss is 0.5056910514831543\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7594, 0.6189, 0.6758, 0.7264, 0.6454, 0.7204, 0.6646, 0.6990, 0.7337,\n",
      "        0.7431, 0.7246], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0279, -0.0110,  0.0442,  0.0744, -0.0206,  0.0893,  0.0222,  0.1309,\n",
      "         0.0427, -0.0030], grad_fn=<AddBackward0>)\n",
      "tensor(0.3411, grad_fn=<SumBackward0>)\n",
      "Epoch 716 loss is 0.3411327600479126\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6797, 0.6560, 0.5987, 0.6737, 0.6557, 0.7460, 0.7247, 0.6781, 0.6306,\n",
      "        0.6291, 0.7223], grad_fn=<ViewBackward0>)\n",
      "tensor([-2.7016e-02, -2.0124e-03, -1.1587e-04,  2.4549e-01,  8.5004e-02,\n",
      "         3.7333e-02, -3.8457e-02, -3.1866e-02,  7.3641e-02,  1.5275e-01],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.4947, grad_fn=<SumBackward0>)\n",
      "Epoch 717 loss is 0.4947490692138672\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6328, 0.7556, 0.7128, 0.7336, 0.6465, 0.5921, 0.7795, 0.6632, 0.6696,\n",
      "        0.6991, 0.6736], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1335,  0.1680, -0.0364, -0.0403,  0.0765,  0.0278,  0.1291, -0.0268,\n",
      "         0.0174,  0.0068], grad_fn=<AddBackward0>)\n",
      "tensor(0.4557, grad_fn=<SumBackward0>)\n",
      "Epoch 718 loss is 0.4556778073310852\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5754, 0.6376, 0.6340, 0.6067, 0.7710, 0.6420, 0.7283, 0.6540, 0.7500,\n",
      "        0.5957, 0.7643], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0976,  0.0520,  0.2223,  0.0134,  0.2027, -0.0390,  0.1800, -0.0442,\n",
      "         0.1838,  0.0238], grad_fn=<AddBackward0>)\n",
      "tensor(0.8925, grad_fn=<SumBackward0>)\n",
      "Epoch 719 loss is 0.8924611210823059\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.0817, 0.6349, 0.6956, 0.7720, 0.5817, 0.5927, 0.6166, 0.7482, 0.6361,\n",
      "        0.7364, 0.6975], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1287, -0.1032, -0.0177, -0.0343, -0.0518,  0.2775,  0.0722,  0.1996,\n",
      "        -0.0169,  0.1024], grad_fn=<AddBackward0>)\n",
      "tensor(0.2992, grad_fn=<SumBackward0>)\n",
      "Epoch 720 loss is 0.29919105768203735\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7618, 0.7862, 0.6491, 0.7145, 0.6525, 0.6197, 0.7433, 0.6511, 0.7096,\n",
      "        0.6033, 0.7273], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0376, -0.0158, -0.0446, -0.0098,  0.0481, -0.0005,  0.1500, -0.0467,\n",
      "         0.1271,  0.0295], grad_fn=<AddBackward0>)\n",
      "tensor(0.1997, grad_fn=<SumBackward0>)\n",
      "Epoch 721 loss is 0.19968611001968384\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5633, 0.7888, 0.7506, 0.7101, 0.5678, 0.7689, 0.7147, 0.6351, 0.7163,\n",
      "        0.7619, 0.7464], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.3122,  0.2447, -0.0737,  0.0304,  0.0077,  0.1122, -0.0175,  0.0787,\n",
      "         0.1855,  0.0502], grad_fn=<AddBackward0>)\n",
      "tensor(0.9304, grad_fn=<SumBackward0>)\n",
      "Epoch 722 loss is 0.9304096698760986\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7854, 0.5654, 0.6134, 0.6075, 0.6214, 0.6654, 0.7376, 0.6485, 0.6954,\n",
      "        0.6710, 0.7146], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0573, -0.0593,  0.0933,  0.0867,  0.2168,  0.0452,  0.0500, -0.0222,\n",
      "         0.1102,  0.0320], grad_fn=<AddBackward0>)\n",
      "tensor(0.4954, grad_fn=<SumBackward0>)\n",
      "Epoch 723 loss is 0.495445191860199\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7943, 0.6140, 0.7629, 0.7304, 0.5661, 0.8219, 0.5818, 0.5987, 0.5935,\n",
      "        0.6096, 0.7777], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0105, -0.0213, -0.0160,  0.0984, -0.0495,  0.0542, -0.0761,  0.0464,\n",
      "         0.2984,  0.3070], grad_fn=<AddBackward0>)\n",
      "tensor(0.6311, grad_fn=<SumBackward0>)\n",
      "Epoch 724 loss is 0.6310960054397583\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6643, 0.7501, 0.7494, 0.6172, 0.7665, 0.7178, 0.6663, 0.7784, 0.7374,\n",
      "        0.6473, 0.6276], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1419, -0.0157,  0.0275, -0.0105,  0.0818,  0.0198,  0.0327, -0.0063,\n",
      "        -0.0503, -0.0366], grad_fn=<AddBackward0>)\n",
      "tensor(0.1842, grad_fn=<SumBackward0>)\n",
      "Epoch 725 loss is 0.18421274423599243\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7551, 0.7470, 0.5730, 0.7622, 0.7214, 0.6744, 0.6861, 0.6368, 0.7574,\n",
      "        0.7410, 0.6875], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0607,  0.0119, -0.0085,  0.1689, -0.0254, -0.0282,  0.1383,  0.0914,\n",
      "         0.0845, -0.0233], grad_fn=<AddBackward0>)\n",
      "tensor(0.3489, grad_fn=<SumBackward0>)\n",
      "Epoch 726 loss is 0.3488694429397583\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7778, 0.6187, 0.7293, 0.6587, 0.6710, 0.7299, 0.6481, 0.6547, 0.6720,\n",
      "        0.6767, 0.6419], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0162, -0.0397,  0.0871,  0.0010, -0.0035, -0.0054, -0.0193,  0.0477,\n",
      "        -0.0043, -0.0100], grad_fn=<AddBackward0>)\n",
      "tensor(0.0373, grad_fn=<SumBackward0>)\n",
      "Epoch 727 loss is 0.03731018304824829\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6278, 0.7241, 0.6284, 0.6707, 0.7436, 0.7600, 0.7285, 0.7573, 0.7634,\n",
      "        0.7112, 0.7248], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0009,  0.0715,  0.0325,  0.2195,  0.0963,  0.0227,  0.0056, -0.0058,\n",
      "        -0.0108, -0.0129], grad_fn=<AddBackward0>)\n",
      "tensor(0.4196, grad_fn=<SumBackward0>)\n",
      "Epoch 728 loss is 0.4195616841316223\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6336, 0.6797, 0.7079, 0.6911, 0.7316, 0.6310, 0.6677, 0.6870, 0.6604,\n",
      "        0.7167, 0.7401], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1239,  0.0960,  0.0864, -0.0256, -0.0078, -0.0148,  0.0490,  0.0817,\n",
      "         0.0884,  0.1328], grad_fn=<AddBackward0>)\n",
      "tensor(0.6099, grad_fn=<SumBackward0>)\n",
      "Epoch 729 loss is 0.6098822951316833\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4517, 0.8277, 0.6201, 0.6555, 0.6949, 0.6978, 0.7130, 0.6946, 0.6688,\n",
      "        0.7105, 0.6584], grad_fn=<ViewBackward0>)\n",
      "tensor([ 2.8062e-01,  3.3959e-01, -4.4276e-02,  1.2952e-01,  9.5804e-02,\n",
      "        -1.1325e-04, -9.6666e-03, -8.2630e-04, -1.2052e-02, -3.4696e-03],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.7751, grad_fn=<SumBackward0>)\n",
      "Epoch 730 loss is 0.7751265168190002\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7075, 0.7310, 0.6731, 0.6551, 0.6598, 0.6577, 0.6467, 0.7167, 0.7397,\n",
      "        0.7299, 0.7145], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0115, -0.0175, -0.0237, -0.0051, -0.0028,  0.0947,  0.1367,  0.1387,\n",
      "        -0.0007, -0.0084], grad_fn=<AddBackward0>)\n",
      "tensor(0.3004, grad_fn=<SumBackward0>)\n",
      "Epoch 731 loss is 0.3004136085510254\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7214, 0.6766, 0.6880, 0.7669, 0.6968, 0.6823, 0.6394, 0.6740, 0.6988,\n",
      "        0.6629, 0.6603], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0111,  0.0758,  0.0336, -0.0019, -0.0425, -0.0076,  0.0274,  0.0391,\n",
      "        -0.0046, -0.0128], grad_fn=<AddBackward0>)\n",
      "tensor(0.0954, grad_fn=<SumBackward0>)\n",
      "Epoch 732 loss is 0.09541893005371094\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7341, 0.6803, 0.7211, 0.7621, 0.7593, 0.6996, 0.6222, 0.6723, 0.7192,\n",
      "        0.6583, 0.6177], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0043,  0.0467,  0.1317, -0.0072, -0.0466, -0.0290,  0.0326,  0.0600,\n",
      "        -0.0182, -0.0338], grad_fn=<AddBackward0>)\n",
      "tensor(0.1320, grad_fn=<SumBackward0>)\n",
      "Epoch 733 loss is 0.13195788860321045\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7981, 0.6057, 0.6951, 0.7221, 0.7591, 0.7102, 0.7033, 0.6658, 0.6793,\n",
      "        0.7074, 0.6695], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0344, -0.0254,  0.2558,  0.0252, -0.0062, -0.0311, -0.0103,  0.0068,\n",
      "         0.0061, -0.0033], grad_fn=<AddBackward0>)\n",
      "tensor(0.1833, grad_fn=<SumBackward0>)\n",
      "Epoch 734 loss is 0.18326729536056519\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7240, 0.7080, 0.7002, 0.6893, 0.6773, 0.6934, 0.6878, 0.7137, 0.6683,\n",
      "        0.7173, 0.6897], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0079, -0.0116, -0.0102, -0.0023, -0.0005,  0.0608, -0.0084,  0.0491,\n",
      "        -0.0080,  0.0357], grad_fn=<AddBackward0>)\n",
      "tensor(0.0967, grad_fn=<SumBackward0>)\n",
      "Epoch 735 loss is 0.09670937061309814\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7473, 0.6836, 0.6739, 0.7194, 0.7595, 0.6852, 0.7120, 0.6686, 0.6979,\n",
      "        0.6922, 0.6482], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0245, -0.0093,  0.1265,  0.0188, -0.0025, -0.0303,  0.0213, -0.0066,\n",
      "        -0.0068, -0.0166], grad_fn=<AddBackward0>)\n",
      "tensor(0.0700, grad_fn=<SumBackward0>)\n",
      "Epoch 736 loss is 0.06999880075454712\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7195, 0.7274, 0.6874, 0.6715, 0.7138, 0.7045, 0.7357, 0.7040, 0.7262,\n",
      "        0.7418, 0.7290], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0107, -0.0160, -0.0045,  0.0285,  0.1070, -0.0033,  0.0361,  0.0101,\n",
      "         0.0416,  0.0046], grad_fn=<AddBackward0>)\n",
      "tensor(0.1935, grad_fn=<SumBackward0>)\n",
      "Epoch 737 loss is 0.19345253705978394\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6288, 0.7248, 0.7562, 0.7215, 0.7233, 0.7069, 0.6969, 0.7111, 0.7097,\n",
      "        0.7186, 0.6666], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2123,  0.1545, -0.0005, -0.0164, -0.0082, -0.0041,  0.0047,  0.0362,\n",
      "        -0.0148, -0.0144], grad_fn=<AddBackward0>)\n",
      "tensor(0.3494, grad_fn=<SumBackward0>)\n",
      "Epoch 738 loss is 0.3494056463241577\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7371, 0.6786, 0.6297, 0.6654, 0.6819, 0.6859, 0.6566, 0.6489, 0.6630,\n",
      "        0.6865, 0.6913], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0358, -0.0239,  0.0055,  0.0936, -0.0029, -0.0110, -0.0076,  0.0498,\n",
      "         0.0707,  0.0472], grad_fn=<AddBackward0>)\n",
      "tensor(0.1856, grad_fn=<SumBackward0>)\n",
      "Epoch 739 loss is 0.18560653924942017\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9381, 0.5834, 0.8024, 0.7847, 0.7111, 0.6635, 0.7141, 0.7050, 0.7242,\n",
      "        0.6506, 0.6335], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0452, -0.0511,  0.2128, -0.0463, -0.0236, -0.0020,  0.1012, -0.0212,\n",
      "        -0.0238, -0.0302], grad_fn=<AddBackward0>)\n",
      "tensor(0.0705, grad_fn=<SumBackward0>)\n",
      "Epoch 740 loss is 0.07053267955780029\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6320, 0.6464, 0.6818, 0.7232, 0.6730, 0.6959, 0.7292, 0.6418, 0.6851,\n",
      "        0.7064, 0.6635], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0831,  0.1520,  0.0443,  0.0234,  0.0100, -0.0104, -0.0036, -0.0076,\n",
      "         0.0361, -0.0072], grad_fn=<AddBackward0>)\n",
      "tensor(0.3201, grad_fn=<SumBackward0>)\n",
      "Epoch 741 loss is 0.3201339840888977\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6473, 0.7211, 0.6270, 0.7112, 0.6506, 0.7133, 0.7043, 0.6653, 0.7517,\n",
      "        0.7154, 0.6659], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0068,  0.1066, -0.0235,  0.1439, -0.0023,  0.0246,  0.0640,  0.0186,\n",
      "         0.0009, -0.0286], grad_fn=<AddBackward0>)\n",
      "tensor(0.2975, grad_fn=<SumBackward0>)\n",
      "Epoch 742 loss is 0.29746007919311523\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7326, 0.6321, 0.6549, 0.6834, 0.6794, 0.6782, 0.6645, 0.7149, 0.7049,\n",
      "        0.7212, 0.6478], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0259, -0.0164,  0.0787,  0.0388, -0.0063,  0.0593,  0.0445,  0.0945,\n",
      "        -0.0224, -0.0190], grad_fn=<AddBackward0>)\n",
      "tensor(0.2258, grad_fn=<SumBackward0>)\n",
      "Epoch 743 loss is 0.22584855556488037\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7336, 0.7010, 0.6924, 0.6970, 0.7250, 0.6993, 0.6506, 0.6816, 0.6654,\n",
      "        0.6572, 0.6266], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0137, -0.0122,  0.0400,  0.0115, -0.0155, -0.0145, -0.0113,  0.0109,\n",
      "        -0.0183, -0.0129], grad_fn=<AddBackward0>)\n",
      "tensor(-0.0361, grad_fn=<SumBackward0>)\n",
      "Epoch 744 loss is -0.03606009483337402\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7015, 0.6860, 0.6804, 0.6907, 0.7500, 0.6551, 0.6608, 0.7343, 0.7049,\n",
      "        0.6916, 0.7365], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0070, -0.0036,  0.1067, -0.0084, -0.0099, -0.0052,  0.0830,  0.0513,\n",
      "         0.0036,  0.0526], grad_fn=<AddBackward0>)\n",
      "tensor(0.2629, grad_fn=<SumBackward0>)\n",
      "Epoch 745 loss is 0.26289474964141846\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6553, 0.6231, 0.6944, 0.7610, 0.7647, 0.6072, 0.7521, 0.6368, 0.7357,\n",
      "        0.6988, 0.6449], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0651,  0.1762,  0.2361, -0.0291, -0.0030, -0.0427,  0.2142, -0.0178,\n",
      "         0.0135, -0.0303], grad_fn=<AddBackward0>)\n",
      "tensor(0.5824, grad_fn=<SumBackward0>)\n",
      "Epoch 746 loss is 0.5823699235916138\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7068, 0.6944, 0.6789, 0.7018, 0.6346, 0.6344, 0.7526, 0.7379, 0.6181,\n",
      "        0.6647, 0.6447], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0093, -0.0017, -0.0199, -0.0148,  0.0847,  0.1720, -0.0054, -0.0293,\n",
      "        -0.0311,  0.0444], grad_fn=<AddBackward0>)\n",
      "tensor(0.1896, grad_fn=<SumBackward0>)\n",
      "Epoch 747 loss is 0.1896006464958191\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6752, 0.6971, 0.7206, 0.6466, 0.6410, 0.6403, 0.7143, 0.6684, 0.7279,\n",
      "        0.6965, 0.6295], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0757, -0.0095, -0.0187, -0.0268,  0.1128,  0.0457,  0.1460, -0.0059,\n",
      "        -0.0130, -0.0328], grad_fn=<AddBackward0>)\n",
      "tensor(0.2734, grad_fn=<SumBackward0>)\n",
      "Epoch 748 loss is 0.27341926097869873\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6848, 0.7322, 0.7748, 0.6886, 0.7320, 0.7502, 0.6380, 0.6757, 0.6502,\n",
      "        0.7726, 0.6165], grad_fn=<ViewBackward0>)\n",
      "tensor([ 1.4998e-01,  6.2761e-03, -7.1049e-05, -8.2149e-03, -1.6865e-02,\n",
      "        -1.8770e-02, -3.3321e-02,  2.2429e-01, -1.9741e-02, -1.1243e-02],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.2723, grad_fn=<SumBackward0>)\n",
      "Epoch 749 loss is 0.272327184677124\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4670, 0.8578, 0.5881, 0.6558, 0.6248, 0.7299, 0.5894, 0.7495, 0.6522,\n",
      "        0.7008, 0.7041], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2020,  0.3147, -0.0777,  0.2363, -0.0221,  0.2078, -0.0259,  0.1857,\n",
      "        -0.0151,  0.0865], grad_fn=<AddBackward0>)\n",
      "tensor(1.0922, grad_fn=<SumBackward0>)\n",
      "Epoch 750 loss is 1.0922026634216309\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7251, 0.6954, 0.7424, 0.6771, 0.7030, 0.7342, 0.7818, 0.7411, 0.6294,\n",
      "        0.7371, 0.6477], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0289, -0.0160,  0.0127, -0.0028,  0.1745,  0.0636, -0.0349, -0.0149,\n",
      "        -0.0312,  0.0304], grad_fn=<AddBackward0>)\n",
      "tensor(0.2103, grad_fn=<SumBackward0>)\n",
      "Epoch 751 loss is 0.21027028560638428\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6172, 0.6992, 0.6677, 0.7059, 0.7084, 0.7565, 0.7103, 0.6573, 0.6627,\n",
      "        0.6428, 0.6369], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0841,  0.1478,  0.0153,  0.1480,  0.0074, -0.0170, -0.0313, -0.0225,\n",
      "        -0.0068, -0.0086], grad_fn=<AddBackward0>)\n",
      "tensor(0.3165, grad_fn=<SumBackward0>)\n",
      "Epoch 752 loss is 0.3164898157119751\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6069, 0.6649, 0.6909, 0.6904, 0.6650, 0.6730, 0.6511, 0.6914, 0.6872,\n",
      "        0.6676, 0.6621], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1400,  0.1392,  0.0002, -0.0060, -0.0131,  0.0440,  0.0236,  0.0276,\n",
      "        -0.0098, -0.0083], grad_fn=<AddBackward0>)\n",
      "tensor(0.3373, grad_fn=<SumBackward0>)\n",
      "Epoch 753 loss is 0.33733993768692017\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6480, 0.6634, 0.7207, 0.7799, 0.6489, 0.6786, 0.7010, 0.7151, 0.7051,\n",
      "        0.7363, 0.6934], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1211,  0.2198, -0.0048, -0.0140, -0.0263,  0.1103,  0.0442,  0.0589,\n",
      "        -0.0072, -0.0039], grad_fn=<AddBackward0>)\n",
      "tensor(0.4980, grad_fn=<SumBackward0>)\n",
      "Epoch 754 loss is 0.4980183243751526\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7164, 0.6566, 0.6663, 0.6659, 0.7603, 0.7138, 0.6928, 0.7335, 0.6700,\n",
      "        0.6845, 0.7033], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0167, -0.0168,  0.1727,  0.0791,  0.0449, -0.0089, -0.0146, -0.0028,\n",
      "        -0.0101,  0.0556], grad_fn=<AddBackward0>)\n",
      "tensor(0.2825, grad_fn=<SumBackward0>)\n",
      "Epoch 755 loss is 0.28246939182281494\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7428, 0.7492, 0.7163, 0.6749, 0.7302, 0.7451, 0.6788, 0.7543, 0.7362,\n",
      "        0.6900, 0.7198], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0088, -0.0226, -0.0063,  0.0480,  0.0066,  0.0401, -0.0030,  0.0186,\n",
      "        -0.0115, -0.0055], grad_fn=<AddBackward0>)\n",
      "tensor(0.0555, grad_fn=<SumBackward0>)\n",
      "Epoch 756 loss is 0.055507123470306396\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6221, 0.7745, 0.7450, 0.7552, 0.7712, 0.7030, 0.6985, 0.7462, 0.7285,\n",
      "        0.6657, 0.7322], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2048,  0.2218, -0.0011, -0.0140, -0.0189, -0.0083,  0.0424, -0.0109,\n",
      "        -0.0047,  0.0061], grad_fn=<AddBackward0>)\n",
      "tensor(0.4172, grad_fn=<SumBackward0>)\n",
      "Epoch 757 loss is 0.4172138571739197\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6666, 0.6217, 0.7418, 0.6842, 0.6861, 0.7200, 0.7201, 0.7343, 0.7146,\n",
      "        0.7135, 0.6604], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1253,  0.0292,  0.1074, -0.0073,  0.0599,  0.0803, -0.0018, -0.0022,\n",
      "        -0.0246, -0.0181], grad_fn=<AddBackward0>)\n",
      "tensor(0.3481, grad_fn=<SumBackward0>)\n",
      "Epoch 758 loss is 0.3481351137161255\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7638, 0.7654, 0.7249, 0.7431, 0.7079, 0.6914, 0.6455, 0.6917, 0.6658,\n",
      "        0.6719, 0.7199], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0130, -0.0069, -0.0192, -0.0112, -0.0325, -0.0054, -0.0085,  0.0440,\n",
      "         0.0471,  0.0903], grad_fn=<AddBackward0>)\n",
      "tensor(0.0847, grad_fn=<SumBackward0>)\n",
      "Epoch 759 loss is 0.08468925952911377\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.0582, 0.7668, 0.8404, 0.7773, 0.6454, 0.7049, 0.7337, 0.7026, 0.6641,\n",
      "        0.6902, 0.7025], grad_fn=<ViewBackward0>)\n",
      "tensor([-7.2621e-02, -9.3648e-02, -4.0463e-02, -4.5149e-02, -1.4543e-02,\n",
      "         9.5420e-02, -1.3611e-02, -1.4474e-02, -5.3406e-05,  6.3930e-02],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(-0.1352, grad_fn=<SumBackward0>)\n",
      "Epoch 760 loss is -0.13521182537078857\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7109, 0.6854, 0.6531, 0.7421, 0.7043, 0.7034, 0.7038, 0.7007, 0.7155,\n",
      "        0.7151, 0.7099], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0193,  0.0519,  0.0315,  0.0838, -0.0128, -0.0012,  0.0201,  0.0189,\n",
      "         0.0154, -0.0019], grad_fn=<AddBackward0>)\n",
      "tensor(0.1865, grad_fn=<SumBackward0>)\n",
      "Epoch 761 loss is 0.18652242422103882\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6213, 0.7062, 0.6766, 0.6861, 0.6475, 0.8303, 0.7094, 0.7573, 0.6447,\n",
      "        0.7166, 0.7381], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0921,  0.1080, -0.0196,  0.2562,  0.0388,  0.1830, -0.0619,  0.0120,\n",
      "        -0.0064,  0.1556], grad_fn=<AddBackward0>)\n",
      "tensor(0.7578, grad_fn=<SumBackward0>)\n",
      "Epoch 762 loss is 0.7578195333480835\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7181, 0.7024, 0.6960, 0.7182, 0.6760, 0.6825, 0.6763, 0.6995, 0.6927,\n",
      "        0.6911, 0.6897], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0074,  0.0002, -0.0088, -0.0045, -0.0140,  0.0393,  0.0170,  0.0247,\n",
      "        -0.0033, -0.0010], grad_fn=<AddBackward0>)\n",
      "tensor(0.0422, grad_fn=<SumBackward0>)\n",
      "Epoch 763 loss is 0.042239606380462646\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7296, 0.7063, 0.7092, 0.6753, 0.6928, 0.6838, 0.6731, 0.6361, 0.7216,\n",
      "        0.7477, 0.6736], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0068, -0.0181, -0.0045, -0.0085, -0.0007, -0.0189,  0.0629,  0.1244,\n",
      "         0.0624, -0.0160], grad_fn=<AddBackward0>)\n",
      "tensor(0.1762, grad_fn=<SumBackward0>)\n",
      "Epoch 764 loss is 0.1762009859085083\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7674, 0.6815, 0.6903, 0.6020, 0.6727, 0.7032, 0.7008, 0.6859, 0.7010,\n",
      "        0.6382, 0.7038], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0257, -0.0551, -0.0029,  0.0215,  0.1647,  0.0220, -0.0007, -0.0209,\n",
      "         0.0299,  0.0047], grad_fn=<AddBackward0>)\n",
      "tensor(0.1375, grad_fn=<SumBackward0>)\n",
      "Epoch 765 loss is 0.1374620795249939\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7703, 0.7566, 0.7116, 0.6405, 0.7094, 0.6256, 0.6632, 0.6583, 0.7164,\n",
      "        0.6425, 0.7261], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0196, -0.0433, -0.0157, -0.0287,  0.0378, -0.0170,  0.1515, -0.0069,\n",
      "         0.1129,  0.0160], grad_fn=<AddBackward0>)\n",
      "tensor(0.1870, grad_fn=<SumBackward0>)\n",
      "Epoch 766 loss is 0.18700248003005981\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5981, 0.6467, 0.6202, 0.7352, 0.6984, 0.7303, 0.7057, 0.6736, 0.7490,\n",
      "        0.6193, 0.6995], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0369,  0.2285,  0.0861,  0.1834, -0.0098, -0.0083,  0.0312, -0.0288,\n",
      "         0.0432, -0.0165], grad_fn=<AddBackward0>)\n",
      "tensor(0.5460, grad_fn=<SumBackward0>)\n",
      "Epoch 767 loss is 0.5459868311882019\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6158, 0.6816, 0.6998, 0.7048, 0.6865, 0.7030, 0.6775, 0.6625, 0.7397,\n",
      "        0.6788, 0.7060], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1400,  0.1483,  0.0081,  0.0053, -0.0091, -0.0080,  0.0612,  0.0022,\n",
      "         0.0725, -0.0112], grad_fn=<AddBackward0>)\n",
      "tensor(0.4093, grad_fn=<SumBackward0>)\n",
      "Epoch 768 loss is 0.40933293104171753\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7511, 0.6376, 0.7994, 0.6227, 0.6587, 0.6483, 0.6485, 0.6263, 0.7098,\n",
      "        0.7460, 0.7637], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0805, -0.0428,  0.0350, -0.0504,  0.0430, -0.0108,  0.1024,  0.1624,\n",
      "         0.2289,  0.0898], grad_fn=<AddBackward0>)\n",
      "tensor(0.6383, grad_fn=<SumBackward0>)\n",
      "Epoch 769 loss is 0.6383323073387146\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.3589, 0.6583, 0.6554, 0.6357, 0.7597, 0.6039, 0.7593, 0.7728, 0.7701,\n",
      "        0.5970, 0.7466], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4941,  0.4613,  0.1689, -0.0172,  0.2059,  0.0219,  0.2770, -0.0541,\n",
      "        -0.0087, -0.0078], grad_fn=<AddBackward0>)\n",
      "tensor(1.5413, grad_fn=<SumBackward0>)\n",
      "Epoch 770 loss is 1.5413174629211426\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7457, 0.7174, 0.7392, 0.5920, 0.7034, 0.6410, 0.7815, 0.6605, 0.6715,\n",
      "        0.7352, 0.6641], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0022, -0.0512, -0.0047, -0.0327,  0.3157, -0.0143,  0.0508, -0.0154,\n",
      "         0.0059, -0.0025], grad_fn=<AddBackward0>)\n",
      "tensor(0.2494, grad_fn=<SumBackward0>)\n",
      "Epoch 771 loss is 0.24939948320388794\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6149, 0.6470, 0.6097, 0.6437, 0.7244, 0.6862, 0.7013, 0.6629, 0.7381,\n",
      "        0.6618, 0.6448], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0017,  0.0479,  0.1291,  0.1274,  0.0960, -0.0205,  0.0865, -0.0132,\n",
      "        -0.0061, -0.0311], grad_fn=<AddBackward0>)\n",
      "tensor(0.4144, grad_fn=<SumBackward0>)\n",
      "Epoch 772 loss is 0.414375364780426\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7632, 0.6843, 0.7029, 0.6148, 0.7604, 0.6918, 0.6557, 0.7332, 0.7418,\n",
      "        0.6924, 0.7125], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0201, -0.0495,  0.1268, -0.0037,  0.0682, -0.0091,  0.0833,  0.0611,\n",
      "        -0.0069, -0.0098], grad_fn=<AddBackward0>)\n",
      "tensor(0.2404, grad_fn=<SumBackward0>)\n",
      "Epoch 773 loss is 0.2404232621192932\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7583, 0.6179, 0.7294, 0.6486, 0.6568, 0.6910, 0.7047, 0.7128, 0.7272,\n",
      "        0.7185, 0.6556], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0096, -0.0366,  0.0649, -0.0128,  0.0935,  0.0933,  0.0603,  0.0230,\n",
      "        -0.0191, -0.0239], grad_fn=<AddBackward0>)\n",
      "tensor(0.2330, grad_fn=<SumBackward0>)\n",
      "Epoch 774 loss is 0.23304134607315063\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7588, 0.7321, 0.5911, 0.7289, 0.7668, 0.6667, 0.6886, 0.7157, 0.7193,\n",
      "        0.7044, 0.7212], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0559, -0.0100,  0.0578,  0.1260, -0.0134, -0.0170,  0.0878,  0.0262,\n",
      "         0.0092,  0.0031], grad_fn=<AddBackward0>)\n",
      "tensor(0.2137, grad_fn=<SumBackward0>)\n",
      "Epoch 775 loss is 0.21365445852279663\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6204, 0.6984, 0.5947, 0.7555, 0.6057, 0.5871, 0.7754, 0.7003, 0.6669,\n",
      "        0.7655, 0.6863], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0085,  0.2252, -0.0309, -0.0025,  0.0332,  0.1577,  0.1329, -0.0033,\n",
      "        -0.0047,  0.0325], grad_fn=<AddBackward0>)\n",
      "tensor(0.5315, grad_fn=<SumBackward0>)\n",
      "Epoch 776 loss is 0.5315486192703247\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6022, 0.6940, 0.6385, 0.7389, 0.6376, 0.6853, 0.6784, 0.6815, 0.6832,\n",
      "        0.6847, 0.7012], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0605,  0.2278, -0.0188,  0.0780, -0.0202,  0.0731, -0.0007,  0.0105,\n",
      "         0.0330,  0.0301], grad_fn=<AddBackward0>)\n",
      "tensor(0.4733, grad_fn=<SumBackward0>)\n",
      "Epoch 777 loss is 0.4733160734176636\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7372, 0.6919, 0.7078, 0.7316, 0.6749, 0.6801, 0.6733, 0.6591, 0.6567,\n",
      "        0.7324, 0.7251], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0098, -0.0019, -0.0057, -0.0092, -0.0194, -0.0053, -0.0078,  0.0986,\n",
      "         0.1099,  0.1139], grad_fn=<AddBackward0>)\n",
      "tensor(0.2633, grad_fn=<SumBackward0>)\n",
      "Epoch 778 loss is 0.26330357789993286\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6705, 0.7096, 0.6511, 0.7165, 0.7104, 0.7102, 0.7051, 0.6778, 0.6496,\n",
      "        0.7214, 0.6714], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0064,  0.0768,  0.0012,  0.0985, -0.0038, -0.0108, -0.0202,  0.0273,\n",
      "        -0.0021,  0.0363], grad_fn=<AddBackward0>)\n",
      "tensor(0.1967, grad_fn=<SumBackward0>)\n",
      "Epoch 779 loss is 0.19671934843063354\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9451, 0.5526, 0.7802, 0.6714, 0.6559, 0.7217, 0.6666, 0.6865, 0.7217,\n",
      "        0.6190, 0.6311], grad_fn=<ViewBackward0>)\n",
      "tensor([-5.4974e-02, -9.1239e-02,  1.7216e-01, -1.9494e-02, -1.6067e-03,\n",
      "         5.0958e-02, -1.0133e-05, -1.5842e-02, -1.8468e-02, -3.0202e-02],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(-0.0087, grad_fn=<SumBackward0>)\n",
      "Epoch 780 loss is -0.008721709251403809\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6288, 0.5700, 0.6597, 0.6599, 0.6540, 0.7311, 0.6758, 0.6624, 0.7686,\n",
      "        0.6964, 0.7085], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0514,  0.0519,  0.1400,  0.1191,  0.0264,  0.0140,  0.0625,  0.0343,\n",
      "         0.0768, -0.0201], grad_fn=<AddBackward0>)\n",
      "tensor(0.5563, grad_fn=<SumBackward0>)\n",
      "Epoch 781 loss is 0.5563209056854248\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7126, 0.7058, 0.7049, 0.6835, 0.7748, 0.7769, 0.7280, 0.6703, 0.7307,\n",
      "        0.6688, 0.6256], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0026, -0.0097,  0.1150,  0.1200,  0.0742, -0.0348, -0.0154, -0.0197,\n",
      "        -0.0149, -0.0351], grad_fn=<AddBackward0>)\n",
      "tensor(0.1771, grad_fn=<SumBackward0>)\n",
      "Epoch 782 loss is 0.1770980954170227\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6781, 0.6842, 0.6721, 0.6721, 0.6940, 0.6677, 0.7427, 0.7103, 0.6649,\n",
      "        0.7365, 0.6690], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0020, -0.0020,  0.0163, -0.0014,  0.1178,  0.0272, -0.0010, -0.0021,\n",
      "        -0.0138,  0.0069], grad_fn=<AddBackward0>)\n",
      "tensor(0.1459, grad_fn=<SumBackward0>)\n",
      "Epoch 783 loss is 0.14587384462356567\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6425, 0.6816, 0.7256, 0.7317, 0.6371, 0.6915, 0.6792, 0.7504, 0.6674,\n",
      "        0.7790, 0.7887], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1385,  0.1486, -0.0148, -0.0114, -0.0175,  0.1889, -0.0080,  0.1663,\n",
      "         0.0638,  0.2021], grad_fn=<AddBackward0>)\n",
      "tensor(0.8566, grad_fn=<SumBackward0>)\n",
      "Epoch 784 loss is 0.8565504550933838\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6651, 0.6716, 0.6841, 0.6674, 0.6824, 0.6728, 0.7296, 0.6683, 0.7052,\n",
      "        0.6887, 0.6965], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0317,  0.0039,  0.0180, -0.0038,  0.1036, -0.0047,  0.0540, -0.0136,\n",
      "         0.0470, -0.0029], grad_fn=<AddBackward0>)\n",
      "tensor(0.2332, grad_fn=<SumBackward0>)\n",
      "Epoch 785 loss is 0.23319941759109497\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7334, 0.6939, 0.7358, 0.6887, 0.6836, 0.6915, 0.7222, 0.7166, 0.6646,\n",
      "        0.7393, 0.7293], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0040, -0.0149, -0.0034, -0.0148,  0.0558,  0.0550, -0.0090,  0.0285,\n",
      "         0.0211,  0.1078], grad_fn=<AddBackward0>)\n",
      "tensor(0.2302, grad_fn=<SumBackward0>)\n",
      "Epoch 786 loss is 0.23017185926437378\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6266, 0.6800, 0.6753, 0.6886, 0.6697, 0.6753, 0.6669, 0.6428, 0.7128,\n",
      "        0.7283, 0.7051], grad_fn=<ViewBackward0>)\n",
      "tensor([ 8.1026e-02,  1.0331e-01, -3.4434e-03,  8.7321e-05, -7.2435e-03,\n",
      "        -8.9577e-03,  6.2502e-02,  1.0240e-01,  1.0390e-01, -2.5561e-03],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.4310, grad_fn=<SumBackward0>)\n",
      "Epoch 787 loss is 0.4310300350189209\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6504, 0.6880, 0.6890, 0.6797, 0.6913, 0.7293, 0.7496, 0.7329, 0.6710,\n",
      "        0.6853, 0.6755], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0643,  0.0489,  0.0054,  0.0672,  0.1165,  0.0694, -0.0194, -0.0215,\n",
      "        -0.0191,  0.0074], grad_fn=<AddBackward0>)\n",
      "tensor(0.3191, grad_fn=<SumBackward0>)\n",
      "Epoch 788 loss is 0.31908053159713745\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6782, 0.6445, 0.6691, 0.6890, 0.6641, 0.6987, 0.6847, 0.7188, 0.6474,\n",
      "        0.7659, 0.7129], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0030,  0.0180,  0.0327,  0.0493, -0.0014,  0.0912, -0.0171,  0.1353,\n",
      "        -0.0020,  0.1092], grad_fn=<AddBackward0>)\n",
      "tensor(0.4122, grad_fn=<SumBackward0>)\n",
      "Epoch 789 loss is 0.4121515154838562\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5162, 0.8392, 0.7742, 0.6181, 0.6373, 0.7329, 0.6518, 0.6785, 0.7241,\n",
      "        0.6949, 0.6955], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4301,  0.1699, -0.0673, -0.0138,  0.0561,  0.0686, -0.0029,  0.0719,\n",
      "         0.0284, -0.0095], grad_fn=<AddBackward0>)\n",
      "tensor(0.7315, grad_fn=<SumBackward0>)\n",
      "Epoch 790 loss is 0.7315311431884766\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6327, 0.6705, 0.6810, 0.7633, 0.7094, 0.7001, 0.6815, 0.6888, 0.6783,\n",
      "        0.6946, 0.6673], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0805,  0.2177,  0.0649,  0.0318, -0.0273, -0.0069, -0.0073,  0.0218,\n",
      "        -0.0072, -0.0037], grad_fn=<AddBackward0>)\n",
      "tensor(0.3644, grad_fn=<SumBackward0>)\n",
      "Epoch 791 loss is 0.36443424224853516\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7344, 0.6247, 0.6683, 0.6843, 0.6877, 0.7008, 0.6615, 0.7369, 0.6662,\n",
      "        0.6514, 0.7531], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0220, -0.0167,  0.1050,  0.0542, -0.0076,  0.0820, -0.0115, -0.0034,\n",
      "         0.0269,  0.1448], grad_fn=<AddBackward0>)\n",
      "tensor(0.3516, grad_fn=<SumBackward0>)\n",
      "Epoch 792 loss is 0.3516107201576233\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6223, 0.6160, 0.6816, 0.6699, 0.6458, 0.6957, 0.6741, 0.7166, 0.7460,\n",
      "        0.6628, 0.6957], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0987,  0.0794,  0.0497,  0.0236,  0.0069,  0.1179,  0.0838, -0.0037,\n",
      "        -0.0070, -0.0168], grad_fn=<AddBackward0>)\n",
      "tensor(0.4325, grad_fn=<SumBackward0>)\n",
      "Epoch 793 loss is 0.4324706792831421\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7160, 0.7286, 0.6690, 0.7302, 0.7299, 0.7154, 0.6817, 0.6910, 0.6613,\n",
      "        0.6515, 0.6866], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0157,  0.0237,  0.0022,  0.0773, -0.0162, -0.0130, -0.0180, -0.0101,\n",
      "        -0.0015,  0.0421], grad_fn=<AddBackward0>)\n",
      "tensor(0.0708, grad_fn=<SumBackward0>)\n",
      "Epoch 794 loss is 0.07084131240844727\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7337, 0.7321, 0.6939, 0.6800, 0.7180, 0.7200, 0.7211, 0.6469, 0.6771,\n",
      "        0.7371, 0.7454], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0133, -0.0179, -0.0047,  0.0435,  0.0685, -0.0237, -0.0143,  0.0268,\n",
      "         0.1641,  0.1138], grad_fn=<AddBackward0>)\n",
      "tensor(0.3428, grad_fn=<SumBackward0>)\n",
      "Epoch 795 loss is 0.3428301215171814\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7371, 0.6779, 0.6340, 0.7237, 0.7311, 0.6670, 0.6342, 0.6800, 0.7081,\n",
      "        0.6898, 0.7160], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0344, -0.0045,  0.0888,  0.0549, -0.0298, -0.0171,  0.0686,  0.0926,\n",
      "         0.0600,  0.0131], grad_fn=<AddBackward0>)\n",
      "tensor(0.2923, grad_fn=<SumBackward0>)\n",
      "Epoch 796 loss is 0.292297899723053\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6380, 0.6829, 0.6775, 0.6385, 0.7237, 0.6662, 0.6781, 0.6688, 0.6804,\n",
      "        0.7067, 0.6909], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0658,  0.0009,  0.0680, -0.0038,  0.0660, -0.0183,  0.0238,  0.0477,\n",
      "         0.0369,  0.0175], grad_fn=<AddBackward0>)\n",
      "tensor(0.3044, grad_fn=<SumBackward0>)\n",
      "Epoch 797 loss is 0.3044155240058899\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6116, 0.6969, 0.6825, 0.6891, 0.6520, 0.6937, 0.6507, 0.6925, 0.6546,\n",
      "        0.6846, 0.6920], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1183,  0.1293, -0.0150,  0.0185, -0.0128,  0.0675, -0.0130,  0.0565,\n",
      "        -0.0002,  0.0622], grad_fn=<AddBackward0>)\n",
      "tensor(0.4114, grad_fn=<SumBackward0>)\n",
      "Epoch 798 loss is 0.4113730192184448\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6654, 0.7132, 0.6990, 0.7450, 0.6623, 0.7274, 0.6951, 0.7072, 0.7035,\n",
      "        0.6892, 0.6167], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0560,  0.1327, -0.0170,  0.0474, -0.0166,  0.0748, -0.0079, -0.0020,\n",
      "        -0.0302, -0.0289], grad_fn=<AddBackward0>)\n",
      "tensor(0.2083, grad_fn=<SumBackward0>)\n",
      "Epoch 799 loss is 0.2082633376121521\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4216, 0.7283, 0.6814, 0.6571, 0.6562, 0.6960, 0.6486, 0.7059, 0.7231,\n",
      "        0.6769, 0.7132], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4330,  0.3924, -0.0240,  0.0242, -0.0028,  0.0829,  0.0451,  0.0473,\n",
      "         0.0122, -0.0033], grad_fn=<AddBackward0>)\n",
      "tensor(1.0070, grad_fn=<SumBackward0>)\n",
      "Epoch 800 loss is 1.0070019960403442\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7070, 0.7035, 0.7019, 0.7106, 0.7317, 0.6920, 0.7120, 0.6471, 0.7414,\n",
      "        0.6895, 0.7121], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0017,  0.0061,  0.0470, -0.0033,  0.0023, -0.0282,  0.0823, -0.0075,\n",
      "         0.1084, -0.0097], grad_fn=<AddBackward0>)\n",
      "tensor(0.1956, grad_fn=<SumBackward0>)\n",
      "Epoch 801 loss is 0.19563478231430054\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7400, 0.7331, 0.6504, 0.7176, 0.6921, 0.6730, 0.6629, 0.7171, 0.6862,\n",
      "        0.7159, 0.6665], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0299, -0.0075, -0.0137,  0.0376, -0.0182,  0.0416,  0.0221,  0.0882,\n",
      "        -0.0169, -0.0066], grad_fn=<AddBackward0>)\n",
      "tensor(0.0969, grad_fn=<SumBackward0>)\n",
      "Epoch 802 loss is 0.09694170951843262\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7545, 0.6405, 0.6699, 0.6530, 0.6312, 0.7133, 0.7132, 0.6874, 0.7080,\n",
      "        0.6456, 0.6813], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0282, -0.0338, -0.0031,  0.0724,  0.1003,  0.0936, -0.0018, -0.0225,\n",
      "        -0.0020, -0.0089], grad_fn=<AddBackward0>)\n",
      "tensor(0.1658, grad_fn=<SumBackward0>)\n",
      "Epoch 803 loss is 0.1658470630645752\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7063, 0.7190, 0.6850, 0.6818, 0.6924, 0.6795, 0.6496, 0.6604, 0.6402,\n",
      "        0.7045, 0.7241], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0071, -0.0082, -0.0089, -0.0018, -0.0107, -0.0107, -0.0131,  0.0914,\n",
      "         0.1062,  0.1399], grad_fn=<AddBackward0>)\n",
      "tensor(0.2771, grad_fn=<SumBackward0>)\n",
      "Epoch 804 loss is 0.2771148085594177\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6995, 0.6665, 0.6706, 0.7236, 0.6280, 0.6228, 0.6508, 0.6063, 0.5976,\n",
      "        0.7400, 0.7842], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0096,  0.0402, -0.0129, -0.0159, -0.0243, -0.0072, -0.0084,  0.1488,\n",
      "         0.2965,  0.3111], grad_fn=<AddBackward0>)\n",
      "tensor(0.7182, grad_fn=<SumBackward0>)\n",
      "Epoch 805 loss is 0.7181527614593506\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7053, 0.7549, 0.6320, 0.7095, 0.6269, 0.6370, 0.6780, 0.6547, 0.6486,\n",
      "        0.6464, 0.6548], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0244,  0.0070, -0.0426,  0.0084, -0.0105,  0.0463,  0.0192, -0.0105,\n",
      "         0.0001,  0.0104], grad_fn=<AddBackward0>)\n",
      "tensor(0.0033, grad_fn=<SumBackward0>)\n",
      "Epoch 806 loss is 0.0032729506492614746\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7569, 0.8033, 0.6163, 0.5879, 0.6056, 0.5910, 0.6224, 0.7959, 0.6112,\n",
      "        0.7345, 0.6203], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0469, -0.0563, -0.0659, -0.0084,  0.0576,  0.3171,  0.0337,  0.1869,\n",
      "        -0.0585,  0.0151], grad_fn=<AddBackward0>)\n",
      "tensor(0.3744, grad_fn=<SumBackward0>)\n",
      "Epoch 807 loss is 0.374356746673584\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6352, 0.5888, 0.7954, 0.5381, 0.8004, 0.5463, 0.5527, 0.5738, 0.5634,\n",
      "        0.7736, 0.8031], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2670, -0.0324,  0.3527, -0.0830,  0.0244, -0.0755,  0.0285,  0.3682,\n",
      "         0.3822,  0.3994], grad_fn=<AddBackward0>)\n",
      "tensor(1.6314, grad_fn=<SumBackward0>)\n",
      "Epoch 808 loss is 1.6313798427581787\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6300, 0.8511, 0.5726, 0.5601, 0.9087, 0.5194, 0.5570, 0.5555, 0.5577,\n",
      "        0.7550, 0.5653], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0191, -0.0233,  0.0960, -0.0177, -0.0010, -0.1178,  0.0638,  0.3301,\n",
      "         0.0164,  0.0127], grad_fn=<AddBackward0>)\n",
      "tensor(0.3400, grad_fn=<SumBackward0>)\n",
      "Epoch 809 loss is 0.34003424644470215\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6870, 0.4482, 0.9338, 0.9128, 0.9397, 0.5000, 0.8775, 0.5067, 0.5052,\n",
      "        0.4736, 0.5263], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4114,  0.3764,  0.8191, -0.1446, -0.0118, -0.1443,  0.0087, -0.1346,\n",
      "         0.0326,  0.0351], grad_fn=<AddBackward0>)\n",
      "tensor(1.2480, grad_fn=<SumBackward0>)\n",
      "Epoch 810 loss is 1.2480098009109497\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7818, 0.5346, 0.9146, 0.8738, 0.5479, 0.5390, 0.5106, 0.9066, 0.9434,\n",
      "        0.9481, 0.9229], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2213,  0.1533,  0.0222, -0.1252, -0.1211,  0.5979,  0.6741,  0.7293,\n",
      "         0.0271, -0.0069], grad_fn=<AddBackward0>)\n",
      "tensor(2.1721, grad_fn=<SumBackward0>)\n",
      "Epoch 811 loss is 2.1720848083496094\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7850, 0.4699, 0.5064, 0.5019, 0.5048, 0.9683, 0.9875, 0.5062, 0.9622,\n",
      "        0.9636, 0.4891], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0929, -0.0944,  0.0582,  0.7698,  0.8094,  0.0023, -0.0020, -0.0080,\n",
      "        -0.0057, -0.1577], grad_fn=<AddBackward0>)\n",
      "tensor(1.2790, grad_fn=<SumBackward0>)\n",
      "Epoch 812 loss is 1.2790074348449707\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5332, 0.5364, 0.4986, 0.8822, 0.9015, 0.4955, 0.5625, 0.5102, 0.4774,\n",
      "        0.9063, 0.4933], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0115,  0.5817,  0.6085, -0.0010, -0.1066, -0.1304, -0.0060,  0.5730,\n",
      "        -0.0056,  0.0265], grad_fn=<AddBackward0>)\n",
      "tensor(1.5285, grad_fn=<SumBackward0>)\n",
      "Epoch 813 loss is 1.5284883975982666\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8561, 0.4778, 0.9033, 0.4527, 0.9759, 0.9485, 0.5016, 0.4917, 0.4776,\n",
      "        0.9990, 0.4628], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0786, -0.1345,  0.8301,  0.0754,  0.0815, -0.1614, -0.1570,  0.8290,\n",
      "        -0.0096, -0.0049], grad_fn=<AddBackward0>)\n",
      "tensor(1.4272, grad_fn=<SumBackward0>)\n",
      "Epoch 814 loss is 1.4272290468215942\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5377, 0.4894, 0.9065, 0.9609, 0.5138, 0.5034, 0.9483, 0.4649, 0.4703,\n",
      "        0.9617, 0.9368], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.6146,  0.7054,  0.0407, -0.1344, -0.0042, -0.0163, -0.0110,  0.0223,\n",
      "         0.7865,  0.7776], grad_fn=<AddBackward0>)\n",
      "tensor(2.7812, grad_fn=<SumBackward0>)\n",
      "Epoch 815 loss is 2.781223773956299\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8487, 0.5047, 0.9252, 0.9876, 0.9997, 0.8936, 0.5333, 0.5021, 0.4883,\n",
      "        0.4917, 0.9658], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1275,  0.2315,  0.8251, -0.0105, -0.1515, -0.1659, -0.1351, -0.0139,\n",
      "         0.7727,  0.7957], grad_fn=<AddBackward0>)\n",
      "tensor(2.2756, grad_fn=<SumBackward0>)\n",
      "Epoch 816 loss is 2.2756214141845703\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8188, 0.8503, 0.5131, 0.5140, 0.8983, 0.9355, 0.9723, 0.5169, 0.5193,\n",
      "        0.5142, 0.5144], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1019, -0.1016,  0.0799,  0.7040,  0.7639, -0.1271, -0.1387, -0.1527,\n",
      "        -0.0009, -0.0016], grad_fn=<AddBackward0>)\n",
      "tensor(0.9233, grad_fn=<SumBackward0>)\n",
      "Epoch 817 loss is 0.9232557415962219\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6355, 0.5460, 0.8438, 0.9845, 0.5088, 0.5390, 0.8858, 0.9099, 0.8835,\n",
      "        0.5570, 0.8149], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.3472,  0.5817, -0.0124, -0.1016, -0.0329,  0.6685,  0.5742, -0.1096,\n",
      "        -0.0317, -0.0229], grad_fn=<AddBackward0>)\n",
      "tensor(1.8605, grad_fn=<SumBackward0>)\n",
      "Epoch 818 loss is 1.8605258464813232\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6070, 0.8440, 0.8909, 0.5357, 0.5685, 0.5733, 0.5662, 0.8779, 0.9216,\n",
      "        0.8704, 0.8131], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4732, -0.0238, -0.0919, -0.1059,  0.0509,  0.5157,  0.5804,  0.5070,\n",
      "        -0.0216, -0.0362], grad_fn=<AddBackward0>)\n",
      "tensor(1.8479, grad_fn=<SumBackward0>)\n",
      "Epoch 819 loss is 1.8478612899780273\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6405, 0.9669, 0.8684, 0.8526, 0.7915, 0.8179, 0.8371, 0.7991, 0.5972,\n",
      "        0.8271, 0.8227], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.3799,  0.3535, -0.0585, -0.0168, -0.0051,  0.0127, -0.0735, -0.0033,\n",
      "         0.0393,  0.3757], grad_fn=<AddBackward0>)\n",
      "tensor(1.0038, grad_fn=<SumBackward0>)\n",
      "Epoch 820 loss is 1.0037873983383179\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7159, 0.6393, 0.6975, 0.6486, 0.8020, 0.6038, 0.7402, 0.7393, 0.6385,\n",
      "        0.7553, 0.6194], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0061, -0.0224,  0.2711, -0.0312,  0.1526, -0.0209,  0.0577,  0.0253,\n",
      "        -0.0399, -0.0063], grad_fn=<AddBackward0>)\n",
      "tensor(0.3797, grad_fn=<SumBackward0>)\n",
      "Epoch 821 loss is 0.3796905279159546\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7307, 0.6704, 0.6706, 0.6868, 0.6877, 0.7341, 0.7697, 0.6801, 0.6839,\n",
      "        0.6572, 0.7095], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0200, -0.0146,  0.0288,  0.1057,  0.1381, -0.0025, -0.0167, -0.0375,\n",
      "         0.0490,  0.0426], grad_fn=<AddBackward0>)\n",
      "tensor(0.2729, grad_fn=<SumBackward0>)\n",
      "Epoch 822 loss is 0.2728561758995056\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6236, 0.5928, 0.6006, 0.6721, 0.7504, 0.6524, 0.6544, 0.6374, 0.6303,\n",
      "        0.8026, 0.7874], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0077,  0.0808,  0.2626,  0.0863, -0.0059, -0.0377, -0.0073,  0.2470,\n",
      "         0.2500,  0.2617], grad_fn=<AddBackward0>)\n",
      "tensor(1.1297, grad_fn=<SumBackward0>)\n",
      "Epoch 823 loss is 1.1297225952148438\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5849, 0.7435, 0.7999, 0.5742, 0.7851, 0.7853, 0.7908, 0.7949, 0.6055,\n",
      "        0.7442, 0.6092], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.3584, -0.0036,  0.0693, -0.0049,  0.3610,  0.0164, -0.0599, -0.0155,\n",
      "        -0.0619,  0.0061], grad_fn=<AddBackward0>)\n",
      "tensor(0.6654, grad_fn=<SumBackward0>)\n",
      "Epoch 824 loss is 0.6653985977172852\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8048, 0.5763, 0.8097, 0.8243, 0.8034, 0.5996, 0.5177, 0.7871, 0.5733,\n",
      "        0.5728, 0.8518], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0082,  0.0326,  0.3784, -0.0700, -0.1022, -0.0054, -0.0088,  0.0919,\n",
      "         0.1077,  0.4640], grad_fn=<AddBackward0>)\n",
      "tensor(0.8963, grad_fn=<SumBackward0>)\n",
      "Epoch 825 loss is 0.8963379859924316\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8924, 0.5370, 0.5360, 0.5787, 0.8662, 0.8679, 0.8348, 0.8634, 0.8834,\n",
      "        0.9124, 0.8449], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1188, -0.1046,  0.5487,  0.5532,  0.4268, -0.0009,  0.0258,  0.1293,\n",
      "        -0.0062, -0.0129], grad_fn=<AddBackward0>)\n",
      "tensor(1.4404, grad_fn=<SumBackward0>)\n",
      "Epoch 826 loss is 1.440412163734436\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9068, 0.9255, 0.9199, 0.8429, 0.5285, 0.5217, 0.8513, 0.5582, 0.8503,\n",
      "        0.5085, 0.9214], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0218, -0.0213, -0.1323, -0.1328,  0.0140,  0.0496,  0.5477, -0.1143,\n",
      "         0.6054,  0.1185], grad_fn=<AddBackward0>)\n",
      "tensor(0.9564, grad_fn=<SumBackward0>)\n",
      "Epoch 827 loss is 0.9563557505607605\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5062, 0.8782, 0.8721, 0.8616, 0.5373, 0.8787, 0.5176, 0.8611, 0.7961,\n",
      "        0.5503, 0.8963], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.6098,  0.5924, -0.1137,  0.0110, -0.1147,  0.5397, -0.0276,  0.0545,\n",
      "         0.0587,  0.1670], grad_fn=<AddBackward0>)\n",
      "tensor(1.7772, grad_fn=<SumBackward0>)\n",
      "Epoch 828 loss is 1.777240514755249\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5251, 0.5628, 0.8525, 0.8330, 0.8328, 0.8088, 0.8148, 0.8708, 0.6207,\n",
      "        0.8170, 0.8528], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.5457,  0.5130,  0.4500, -0.0146, -0.0061,  0.0632, -0.0627,  0.0037,\n",
      "        -0.0060,  0.3868], grad_fn=<AddBackward0>)\n",
      "tensor(1.8731, grad_fn=<SumBackward0>)\n",
      "Epoch 829 loss is 1.8730723857879639\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.1015, 0.7004, 0.7641, 0.7923, 0.7810, 0.5481, 0.5562, 0.7968, 0.5846,\n",
      "        0.7715, 0.5921], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1125, -0.1031,  0.1343, -0.0720, -0.0787,  0.0264,  0.0609,  0.3588,\n",
      "        -0.0683,  0.0125], grad_fn=<AddBackward0>)\n",
      "tensor(0.1584, grad_fn=<SumBackward0>)\n",
      "Epoch 830 loss is 0.15836918354034424\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5842, 0.8319, 0.8248, 0.5699, 0.7811, 0.7937, 0.6722, 0.6963, 0.6254,\n",
      "        0.7448, 0.6499], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4010, -0.0047, -0.0169, -0.0104,  0.1705, -0.0282, -0.0561,  0.1210,\n",
      "        -0.0155,  0.0409], grad_fn=<AddBackward0>)\n",
      "tensor(0.6015, grad_fn=<SumBackward0>)\n",
      "Epoch 831 loss is 0.6015060544013977\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7449, 0.7726, 0.7650, 0.6342, 0.7634, 0.7161, 0.6312, 0.6512, 0.6983,\n",
      "        0.6518, 0.6886], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0336, -0.0369, -0.0031, -0.0163, -0.0010, -0.0374, -0.0059,  0.0344,\n",
      "         0.0622, -0.0033], grad_fn=<AddBackward0>)\n",
      "tensor(0.0263, grad_fn=<SumBackward0>)\n",
      "Epoch 832 loss is 0.02628040313720703\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6867, 0.6860, 0.6708, 0.7313, 0.7124, 0.7211, 0.6672, 0.6161, 0.7413,\n",
      "        0.7114, 0.6984], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0053,  0.0744,  0.0441,  0.0838, -0.0214, -0.0321,  0.0338,  0.0738,\n",
      "         0.1373, -0.0143], grad_fn=<AddBackward0>)\n",
      "tensor(0.3740, grad_fn=<SumBackward0>)\n",
      "Epoch 833 loss is 0.37395328283309937\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6930, 0.7179, 0.7149, 0.7096, 0.7132, 0.6859, 0.7754, 0.8009, 0.7714,\n",
      "        0.6532, 0.6975], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0364,  0.0277, -0.0015, -0.0097,  0.1096,  0.1462,  0.1426, -0.0407,\n",
      "        -0.0345, -0.0246], grad_fn=<AddBackward0>)\n",
      "tensor(0.3514, grad_fn=<SumBackward0>)\n",
      "Epoch 834 loss is 0.3513942360877991\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6173, 0.6594, 0.7147, 0.6600, 0.7096, 0.6348, 0.5960, 0.6355, 0.6108,\n",
      "        0.6111, 0.7986], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1623,  0.0711,  0.0837, -0.0266, -0.0213, -0.0247, -0.0080,  0.0251,\n",
      "         0.2718,  0.3130], grad_fn=<AddBackward0>)\n",
      "tensor(0.8464, grad_fn=<SumBackward0>)\n",
      "Epoch 835 loss is 0.8463571071624756\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6802, 0.6800, 0.6804, 0.7443, 0.7039, 0.7155, 0.7857, 0.6980, 0.6788,\n",
      "        0.7892, 0.6350], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0003,  0.1068,  0.0398,  0.0585,  0.0691, -0.0020, -0.0122,  0.0059,\n",
      "        -0.0210, -0.0146], grad_fn=<AddBackward0>)\n",
      "tensor(0.2305, grad_fn=<SumBackward0>)\n",
      "Epoch 836 loss is 0.23053061962127686\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6611, 0.7324, 0.6094, 0.6731, 0.6147, 0.7393, 0.8067, 0.6197, 0.6404,\n",
      "        0.6651, 0.7262], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0172,  0.0199, -0.0392,  0.2165,  0.2227,  0.0084, -0.0330, -0.0472,\n",
      "         0.1775,  0.1430], grad_fn=<AddBackward0>)\n",
      "tensor(0.6514, grad_fn=<SumBackward0>)\n",
      "Epoch 837 loss is 0.6513912081718445\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6816, 0.6836, 0.6333, 0.6558, 0.7516, 0.7201, 0.6428, 0.7853, 0.7714,\n",
      "        0.7468, 0.6483], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0161, -0.0086,  0.1134,  0.1447, -0.0044,  0.0562,  0.0856,  0.1734,\n",
      "        -0.0457, -0.0410], grad_fn=<AddBackward0>)\n",
      "tensor(0.4574, grad_fn=<SumBackward0>)\n",
      "Epoch 838 loss is 0.45744025707244873\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7095, 0.6945, 0.7456, 0.7530, 0.5998, 0.7812, 0.6250, 0.7672, 0.6414,\n",
      "        0.6612, 0.7293], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0602,  0.0725, -0.0316,  0.0593, -0.0426,  0.2791, -0.0466,  0.0604,\n",
      "        -0.0127,  0.1464], grad_fn=<AddBackward0>)\n",
      "tensor(0.5444, grad_fn=<SumBackward0>)\n",
      "Epoch 839 loss is 0.5444045662879944\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4773, 0.8815, 0.6076, 0.7583, 0.7389, 0.6623, 0.7783, 0.6940, 0.7036,\n",
      "        0.7680, 0.6758], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2171,  0.4682, -0.0475,  0.0911,  0.0334, -0.0150,  0.0688, -0.0034,\n",
      "        -0.0061, -0.0093], grad_fn=<AddBackward0>)\n",
      "tensor(0.7974, grad_fn=<SumBackward0>)\n",
      "Epoch 840 loss is 0.7973978519439697\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6019, 0.7834, 0.7794, 0.7170, 0.6276, 0.6851, 0.7341, 0.6841, 0.7113,\n",
      "        0.6991, 0.6932], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2959,  0.1917, -0.0519, -0.0314,  0.0286,  0.0941,  0.0437, -0.0117,\n",
      "         0.0152, -0.0061], grad_fn=<AddBackward0>)\n",
      "tensor(0.5681, grad_fn=<SumBackward0>)\n",
      "Epoch 841 loss is 0.5681074857711792\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7196, 0.6869, 0.7213, 0.7024, 0.6631, 0.7176, 0.6839, 0.6929, 0.6904,\n",
      "        0.6465, 0.6683], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0028, -0.0057, -0.0079, -0.0012, -0.0062,  0.0497, -0.0090, -0.0124,\n",
      "        -0.0082, -0.0074], grad_fn=<AddBackward0>)\n",
      "tensor(-0.0056, grad_fn=<SumBackward0>)\n",
      "Epoch 842 loss is -0.005612194538116455\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7665, 0.7239, 0.7572, 0.7526, 0.6094, 0.7287, 0.7193, 0.7230, 0.6354,\n",
      "        0.6823, 0.6920], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0031, -0.0047, -0.0381, -0.0095, -0.0111,  0.1893, -0.0311, -0.0123,\n",
      "        -0.0103,  0.0942], grad_fn=<AddBackward0>)\n",
      "tensor(0.1632, grad_fn=<SumBackward0>)\n",
      "Epoch 843 loss is 0.16321593523025513\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7357, 0.6644, 0.7357, 0.6328, 0.7336, 0.6245, 0.7593, 0.6018, 0.6088,\n",
      "        0.7739, 0.6999], grad_fn=<ViewBackward0>)\n",
      "tensor([-2.9206e-06, -3.4290e-02,  1.1539e-01, -3.7068e-02,  2.1080e-01,\n",
      "        -4.3953e-02, -5.2351e-03,  2.4396e-02,  1.6363e-01,  1.5197e-01],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.5456, grad_fn=<SumBackward0>)\n",
      "Epoch 844 loss is 0.5456405878067017\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7770, 0.6135, 0.7231, 0.7272, 0.6354, 0.7375, 0.7506, 0.7792, 0.6137,\n",
      "        0.6299, 0.6863], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0180, -0.0166,  0.0365,  0.0241,  0.0390,  0.2397, -0.0413, -0.0402,\n",
      "        -0.0310,  0.1211], grad_fn=<AddBackward0>)\n",
      "tensor(0.3133, grad_fn=<SumBackward0>)\n",
      "Epoch 845 loss is 0.31326115131378174\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5980, 0.7487, 0.6434, 0.6345, 0.7216, 0.6080, 0.6638, 0.7228, 0.7661,\n",
      "        0.6644, 0.7058], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0757,  0.0609, -0.0090, -0.0118,  0.0488,  0.0019,  0.2636,  0.0009,\n",
      "        -0.0057, -0.0201], grad_fn=<AddBackward0>)\n",
      "tensor(0.4052, grad_fn=<SumBackward0>)\n",
      "Epoch 846 loss is 0.4052075743675232\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5876, 0.6284, 0.7216, 0.6186, 0.6454, 0.7574, 0.6505, 0.6605, 0.7351,\n",
      "        0.6269, 0.6218], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2234,  0.0517,  0.0284,  0.0597,  0.0532,  0.0251, -0.0074, -0.0079,\n",
      "        -0.0129, -0.0378], grad_fn=<AddBackward0>)\n",
      "tensor(0.3755, grad_fn=<SumBackward0>)\n",
      "Epoch 847 loss is 0.37545305490493774\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5740, 0.7497, 0.7353, 0.7764, 0.7780, 0.6194, 0.7621, 0.5944, 0.6639,\n",
      "        0.7706, 0.7719], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2689,  0.3374,  0.0471, -0.0386, -0.0048, -0.0612,  0.0741,  0.0142,\n",
      "         0.2959,  0.1799], grad_fn=<AddBackward0>)\n",
      "tensor(1.1130, grad_fn=<SumBackward0>)\n",
      "Epoch 848 loss is 1.1129601001739502\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5444, 0.7693, 0.6888, 0.6490, 0.7279, 0.6763, 0.6468, 0.6666, 0.7864,\n",
      "        0.6205, 0.5947], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2407,  0.1744, -0.0138, -0.0042, -0.0008, -0.0204,  0.1834, -0.0088,\n",
      "        -0.0240, -0.0639], grad_fn=<AddBackward0>)\n",
      "tensor(0.4627, grad_fn=<SumBackward0>)\n",
      "Epoch 849 loss is 0.46266376972198486\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4335, 0.6926, 0.7253, 0.6365, 0.7629, 0.5505, 0.7755, 0.6427, 0.7982,\n",
      "        0.5606, 0.5871], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4863,  0.3384,  0.1172, -0.0583,  0.2316, -0.0401,  0.4130, -0.0716,\n",
      "        -0.0186, -0.0704], grad_fn=<AddBackward0>)\n",
      "tensor(1.3276, grad_fn=<SumBackward0>)\n",
      "Epoch 850 loss is 1.3276193141937256\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5446, 0.7664, 0.5818, 0.7527, 0.7449, 0.6355, 0.5922, 0.6135, 0.7746,\n",
      "        0.7539, 0.7554], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0619,  0.3469, -0.0072,  0.0895, -0.0535, -0.0438,  0.2318,  0.2694,\n",
      "         0.2366, -0.0064], grad_fn=<AddBackward0>)\n",
      "tensor(1.1252, grad_fn=<SumBackward0>)\n",
      "Epoch 851 loss is 1.125174880027771\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8345, 0.8331, 0.7823, 0.7242, 0.6959, 0.5991, 0.7603, 0.6002, 0.7780,\n",
      "        0.6181, 0.7480], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0174, -0.0368, -0.0457, -0.0611,  0.0603, -0.0319,  0.2981, -0.0474,\n",
      "         0.2463, -0.0100], grad_fn=<AddBackward0>)\n",
      "tensor(0.3544, grad_fn=<SumBackward0>)\n",
      "Epoch 852 loss is 0.35444211959838867\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6104, 0.7352, 0.7858, 0.7558, 0.7965, 0.6381, 0.7646, 0.6014, 0.6241,\n",
      "        0.6142, 0.7702], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2922,  0.2423,  0.1022, -0.0492,  0.0147, -0.0651, -0.0047, -0.0502,\n",
      "         0.2814,  0.2436], grad_fn=<AddBackward0>)\n",
      "tensor(1.0073, grad_fn=<SumBackward0>)\n",
      "Epoch 853 loss is 1.0073251724243164\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5867, 0.7297, 0.7272, 0.6654, 0.7572, 0.6352, 0.7218, 0.7227, 0.7387,\n",
      "        0.7663, 0.7768], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2342,  0.1312,  0.0459, -0.0307,  0.0940, -0.0115,  0.1724,  0.0743,\n",
      "         0.0901,  0.0636], grad_fn=<AddBackward0>)\n",
      "tensor(0.8636, grad_fn=<SumBackward0>)\n",
      "Epoch 854 loss is 0.8635597229003906\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7365, 0.6809, 0.6951, 0.6898, 0.6851, 0.7227, 0.7154, 0.6940, 0.7131,\n",
      "        0.6542, 0.7239], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0138, -0.0156,  0.0070,  0.0460,  0.0427,  0.0147, -0.0032, -0.0204,\n",
      "         0.0499,  0.0181], grad_fn=<AddBackward0>)\n",
      "tensor(0.1254, grad_fn=<SumBackward0>)\n",
      "Epoch 855 loss is 0.12539607286453247\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6931, 0.6965, 0.6795, 0.7389, 0.6348, 0.6565, 0.7253, 0.6532, 0.7447,\n",
      "        0.7171, 0.7058], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0045,  0.0764, -0.0206, -0.0077, -0.0045,  0.0307,  0.1470, -0.0027,\n",
      "         0.0877, -0.0130], grad_fn=<AddBackward0>)\n",
      "tensor(0.2889, grad_fn=<SumBackward0>)\n",
      "Epoch 856 loss is 0.28885161876678467\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7428, 0.6420, 0.7571, 0.8322, 0.7400, 0.7247, 0.7666, 0.6029, 0.7674,\n",
      "        0.6957, 0.6476], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0238,  0.1490,  0.1633, -0.0108, -0.0219, -0.0457,  0.0711, -0.0236,\n",
      "         0.0745, -0.0399], grad_fn=<AddBackward0>)\n",
      "tensor(0.3398, grad_fn=<SumBackward0>)\n",
      "Epoch 857 loss is 0.3397781252861023\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6364, 0.5899, 0.7525, 0.6005, 0.5755, 0.7522, 0.5435, 0.5839, 0.8064,\n",
      "        0.5752, 0.6261], grad_fn=<ViewBackward0>)\n",
      "tensor([ 1.9358e-01, -1.1948e-02, -4.8303e-03, -1.2141e-04, -1.9019e-02,\n",
      "         1.4126e-02,  9.0483e-02,  5.2930e-02,  7.0313e-02, -6.0110e-02],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.3254, grad_fn=<SumBackward0>)\n",
      "Epoch 858 loss is 0.3254074454307556\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6466, 0.6110, 0.6028, 0.6103, 0.7885, 0.7331, 0.5899, 0.8514, 0.8310,\n",
      "        0.5872, 0.7353], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0146, -0.0121,  0.2958,  0.2172, -0.0068,  0.1049,  0.1631, -0.0009,\n",
      "        -0.0387, -0.0319], grad_fn=<AddBackward0>)\n",
      "tensor(0.6761, grad_fn=<SumBackward0>)\n",
      "Epoch 859 loss is 0.6761155128479004\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5833, 0.8993, 0.8936, 0.5674, 0.8328, 0.8998, 0.8496, 0.8630, 0.5490,\n",
      "        0.8565, 0.8607], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.5172, -0.0053, -0.0222,  0.0104,  0.4704,  0.0504, -0.1169,  0.0115,\n",
      "        -0.0008,  0.5195], grad_fn=<AddBackward0>)\n",
      "tensor(1.4341, grad_fn=<SumBackward0>)\n",
      "Epoch 860 loss is 1.4341466426849365\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6241, 0.5796, 0.5697, 0.5514, 0.8074, 0.5600, 0.8127, 0.8776, 0.8645,\n",
      "        0.5724, 0.8573], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0181, -0.0242,  0.3797, -0.0032,  0.4355,  0.1170,  0.5075, -0.0801,\n",
      "        -0.0067, -0.0024], grad_fn=<AddBackward0>)\n",
      "tensor(1.3048, grad_fn=<SumBackward0>)\n",
      "Epoch 861 loss is 1.3048303127288818\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5920, 0.5593, 0.7605, 0.8558, 0.7970, 0.5862, 0.7948, 0.7585, 0.5621,\n",
      "        0.8702, 0.5732], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2808,  0.4397,  0.3962, -0.0581, -0.0203, -0.0128, -0.0080,  0.1257,\n",
      "        -0.0618,  0.0185], grad_fn=<AddBackward0>)\n",
      "tensor(1.1000, grad_fn=<SumBackward0>)\n",
      "Epoch 862 loss is 1.0999846458435059\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6261, 0.8205, 0.5762, 0.7592, 0.6077, 0.5964, 0.6017, 0.8005, 0.7648,\n",
      "        0.5825, 0.5726], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0166,  0.2219, -0.0709,  0.0337, -0.0525,  0.3213,  0.2806, -0.0064,\n",
      "        -0.0760, -0.0641], grad_fn=<AddBackward0>)\n",
      "tensor(0.5710, grad_fn=<SumBackward0>)\n",
      "Epoch 863 loss is 0.5709748268127441\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7520, 0.5904, 0.8285, 0.5754, 0.8089, 0.6079, 0.6131, 0.5826, 0.5497,\n",
      "        0.8362, 0.5842], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1274, -0.0589,  0.3642, -0.0735,  0.0629, -0.0755, -0.0194,  0.3719,\n",
      "         0.0028,  0.0574], grad_fn=<AddBackward0>)\n",
      "tensor(0.7594, grad_fn=<SumBackward0>)\n",
      "Epoch 864 loss is 0.7594094276428223\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7354, 0.7145, 0.7325, 0.7823, 0.7935, 0.5873, 0.7742, 0.8029, 0.5849,\n",
      "        0.8054, 0.6428], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0010,  0.0782,  0.1316, -0.0484, -0.0027,  0.0156, -0.0008,  0.0520,\n",
      "        -0.0534,  0.0964], grad_fn=<AddBackward0>)\n",
      "tensor(0.2676, grad_fn=<SumBackward0>)\n",
      "Epoch 865 loss is 0.26755207777023315\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6944, 0.6390, 0.7895, 0.6274, 0.6983, 0.6755, 0.8228, 0.7574, 0.6496,\n",
      "        0.8165, 0.6076], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1585, -0.0223,  0.0989, -0.0380,  0.3257,  0.0984, -0.0086, -0.0021,\n",
      "        -0.0499, -0.0140], grad_fn=<AddBackward0>)\n",
      "tensor(0.5465, grad_fn=<SumBackward0>)\n",
      "Epoch 866 loss is 0.5465183258056641\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7135, 0.6473, 0.7601, 0.6207, 0.6232, 0.6594, 0.7291, 0.6701, 0.7451,\n",
      "        0.6227, 0.7665], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0776, -0.0309, -0.0080, -0.0336,  0.1807,  0.0782,  0.1429, -0.0355,\n",
      "         0.1605,  0.0355], grad_fn=<AddBackward0>)\n",
      "tensor(0.5674, grad_fn=<SumBackward0>)\n",
      "Epoch 867 loss is 0.5674028396606445\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7229, 0.6820, 0.7238, 0.6956, 0.6848, 0.6666, 0.7200, 0.7229, 0.6554,\n",
      "        0.7347, 0.7363], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0015, -0.0091,  0.0046, -0.0190,  0.0407,  0.0635, -0.0037,  0.0245,\n",
      "         0.0224,  0.1348], grad_fn=<AddBackward0>)\n",
      "tensor(0.2601, grad_fn=<SumBackward0>)\n",
      "Epoch 868 loss is 0.2601003646850586\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6836, 0.7094, 0.6757, 0.6706, 0.6859, 0.6548, 0.6986, 0.6777, 0.6602,\n",
      "        0.7455, 0.7245], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0026, -0.0043, -0.0078, -0.0069,  0.0466, -0.0028,  0.0089,  0.0782,\n",
      "         0.0780,  0.1071], grad_fn=<AddBackward0>)\n",
      "tensor(0.2943, grad_fn=<SumBackward0>)\n",
      "Epoch 869 loss is 0.294333815574646\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.3967, 0.7428, 0.6950, 0.6495, 0.6870, 0.6441, 0.6262, 0.7771, 0.8327,\n",
      "        0.6137, 0.8243], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4972,  0.4213, -0.0186, -0.0170, -0.0078,  0.1503,  0.3144, -0.0041,\n",
      "         0.0786, -0.0028], grad_fn=<AddBackward0>)\n",
      "tensor(1.4114, grad_fn=<SumBackward0>)\n",
      "Epoch 870 loss is 1.4114186763763428\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5498, 0.7904, 0.6056, 0.7606, 0.7747, 0.7900, 0.7610, 0.7671, 0.7662,\n",
      "        0.6124, 0.6933], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0930,  0.3513, -0.0053,  0.3073,  0.0008, -0.0025, -0.0079, -0.0495,\n",
      "        -0.0246, -0.0243], grad_fn=<AddBackward0>)\n",
      "tensor(0.6382, grad_fn=<SumBackward0>)\n",
      "Epoch 871 loss is 0.6382187008857727\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5904, 0.7964, 0.5610, 0.5999, 0.6112, 0.5696, 0.6107, 0.7610, 0.6173,\n",
      "        0.8150, 0.8348], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0098,  0.0158, -0.0618,  0.0143,  0.0180,  0.2497,  0.0796,  0.3404,\n",
      "         0.1230,  0.3624], grad_fn=<AddBackward0>)\n",
      "tensor(1.1316, grad_fn=<SumBackward0>)\n",
      "Epoch 872 loss is 1.1316454410552979\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5272, 0.8473, 0.8609, 0.5635, 0.7975, 0.8037, 0.5937, 0.6335, 0.5259,\n",
      "        0.5851, 0.7884], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.5562,  0.0604, -0.0166, -0.0191,  0.0503, -0.0546, -0.0926, -0.0028,\n",
      "         0.2580,  0.4375], grad_fn=<AddBackward0>)\n",
      "tensor(1.1766, grad_fn=<SumBackward0>)\n",
      "Epoch 873 loss is 1.176601529121399\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5512, 0.8349, 0.8413, 0.8516, 0.8258, 0.5552, 0.5477, 0.8476, 0.5318,\n",
      "        0.7924, 0.8823], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4834,  0.5006, -0.0030, -0.0954, -0.1013,  0.0362, -0.0078,  0.4077,\n",
      "         0.0579,  0.5842], grad_fn=<AddBackward0>)\n",
      "tensor(1.8625, grad_fn=<SumBackward0>)\n",
      "Epoch 874 loss is 1.8625483512878418\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5248, 0.8002, 0.8172, 0.5568, 0.6010, 0.7825, 0.8331, 0.8568, 0.8131,\n",
      "        0.7627, 0.6293], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4874,  0.0533, -0.0664, -0.0116,  0.4605,  0.4263,  0.0510, -0.0234,\n",
      "        -0.0758, -0.0613], grad_fn=<AddBackward0>)\n",
      "tensor(1.2400, grad_fn=<SumBackward0>)\n",
      "Epoch 875 loss is 1.239974021911621\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5858, 0.5900, 0.5715, 0.5845, 0.7885, 0.7879, 0.7920, 0.8042, 0.6097,\n",
      "        0.7687, 0.8072], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0048, -0.0004,  0.3308,  0.3606,  0.3458,  0.0261, -0.0594, -0.0077,\n",
      "         0.0050,  0.3292], grad_fn=<AddBackward0>)\n",
      "tensor(1.3252, grad_fn=<SumBackward0>)\n",
      "Epoch 876 loss is 1.3251891136169434\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8452, 0.5624, 0.7944, 0.8311, 0.8056, 0.7864, 0.6037, 0.5809, 0.5608,\n",
      "        0.6032, 0.7667], grad_fn=<ViewBackward0>)\n",
      "tensor([-1.6939e-02, -4.7233e-03,  4.0537e-01, -2.6802e-03, -7.5785e-02,\n",
      "        -7.4900e-02, -7.5201e-02, -1.7220e-04,  3.0973e-01,  3.4330e-01],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.8080, grad_fn=<SumBackward0>)\n",
      "Epoch 877 loss is 0.8079989552497864\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7878, 0.7686, 0.7387, 0.6024, 0.7638, 0.6171, 0.6399, 0.6358, 0.7349,\n",
      "        0.6457, 0.6875], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0164, -0.0618, -0.0016, -0.0405,  0.0626, -0.0427,  0.1962,  0.0098,\n",
      "         0.0862, -0.0158], grad_fn=<AddBackward0>)\n",
      "tensor(0.1760, grad_fn=<SumBackward0>)\n",
      "Epoch 878 loss is 0.17596513032913208\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6214, 0.6694, 0.7402, 0.6046, 0.7382, 0.6645, 0.6673, 0.6565, 0.7067,\n",
      "        0.7135, 0.6210], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1979, -0.0056,  0.1146, -0.0252,  0.1045, -0.0272,  0.0704,  0.0770,\n",
      "        -0.0119, -0.0286], grad_fn=<AddBackward0>)\n",
      "tensor(0.4659, grad_fn=<SumBackward0>)\n",
      "Epoch 879 loss is 0.4659457206726074\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4744, 0.7859, 0.6463, 0.6753, 0.6623, 0.7054, 0.6798, 0.6800, 0.6322,\n",
      "        0.7479, 0.7053], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2865,  0.3350, -0.0412,  0.0986,  0.0074,  0.0295, -0.0244,  0.1135,\n",
      "         0.0421,  0.1218], grad_fn=<AddBackward0>)\n",
      "tensor(0.9688, grad_fn=<SumBackward0>)\n",
      "Epoch 880 loss is 0.9688366651535034\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6888, 0.7514, 0.7417, 0.6848, 0.7432, 0.6793, 0.6998, 0.6837, 0.7454,\n",
      "        0.6465, 0.6954], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0882, -0.0013, -0.0027, -0.0208,  0.0251, -0.0198,  0.1100, -0.0178,\n",
      "         0.0195, -0.0166], grad_fn=<AddBackward0>)\n",
      "tensor(0.1637, grad_fn=<SumBackward0>)\n",
      "Epoch 881 loss is 0.1636652946472168\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7294, 0.6678, 0.7000, 0.7303, 0.6883, 0.6638, 0.6634, 0.7207, 0.6782,\n",
      "        0.6897, 0.6720], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0098,  0.0016,  0.0342, -0.0121, -0.0223,  0.0541,  0.0240,  0.0438,\n",
      "        -0.0162, -0.0021], grad_fn=<AddBackward0>)\n",
      "tensor(0.0952, grad_fn=<SumBackward0>)\n",
      "Epoch 882 loss is 0.09518253803253174\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6114, 0.6561, 0.6713, 0.6742, 0.6771, 0.6845, 0.6946, 0.6679, 0.6894,\n",
      "        0.6863, 0.6876], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0999,  0.1047,  0.0351,  0.0220,  0.0340, -0.0031,  0.0082, -0.0028,\n",
      "         0.0330, -0.0006], grad_fn=<AddBackward0>)\n",
      "tensor(0.3304, grad_fn=<SumBackward0>)\n",
      "Epoch 883 loss is 0.3304203748703003\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7672, 0.6775, 0.6807, 0.6582, 0.6623, 0.7724, 0.6637, 0.6957, 0.6780,\n",
      "        0.6830, 0.6546], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0288, -0.0363, -0.0051,  0.1528,  0.0092,  0.0558, -0.0315,  0.0321,\n",
      "        -0.0137, -0.0078], grad_fn=<AddBackward0>)\n",
      "tensor(0.1266, grad_fn=<SumBackward0>)\n",
      "Epoch 884 loss is 0.12663066387176514\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5903, 0.6500, 0.6543, 0.6811, 0.6976, 0.6789, 0.7028, 0.6905, 0.7200,\n",
      "        0.6438, 0.7180], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1066,  0.1513,  0.0793,  0.0410,  0.0361, -0.0024,  0.0686, -0.0197,\n",
      "         0.0459, -0.0007], grad_fn=<AddBackward0>)\n",
      "tensor(0.5061, grad_fn=<SumBackward0>)\n",
      "Epoch 885 loss is 0.5061219930648804\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7701, 0.5916, 0.7425, 0.6651, 0.6648, 0.6123, 0.6424, 0.6587, 0.7188,\n",
      "        0.7245, 0.6705], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0092, -0.0350,  0.1221, -0.0434, -0.0075, -0.0020,  0.1775,  0.1368,\n",
      "         0.0197, -0.0161], grad_fn=<AddBackward0>)\n",
      "tensor(0.3429, grad_fn=<SumBackward0>)\n",
      "Epoch 886 loss is 0.34285521507263184\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5715, 0.7682, 0.5889, 0.7904, 0.6594, 0.7453, 0.7707, 0.7863, 0.7400,\n",
      "        0.8000, 0.6042], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0290,  0.3649, -0.0363,  0.2607, -0.0066,  0.2115, -0.0018,  0.0488,\n",
      "        -0.0607, -0.0453], grad_fn=<AddBackward0>)\n",
      "tensor(0.7644, grad_fn=<SumBackward0>)\n",
      "Epoch 887 loss is 0.7643557786941528\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8093, 0.7986, 0.8172, 0.7928, 0.8235, 0.6528, 0.7888, 0.7820, 0.7583,\n",
      "        0.7730, 0.7784], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0130, -0.0055,  0.0414, -0.0548, -0.0013, -0.0138,  0.1758, -0.0053,\n",
      "        -0.0012,  0.0336], grad_fn=<AddBackward0>)\n",
      "tensor(0.1819, grad_fn=<SumBackward0>)\n",
      "Epoch 888 loss is 0.1819061040878296\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8215, 0.7576, 0.6163, 0.6175, 0.6180, 0.6037, 0.6074, 0.7212, 0.6677,\n",
      "        0.6519, 0.5933], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0684, -0.0680, -0.0465, -0.0042, -0.0034,  0.1719,  0.1066,  0.0742,\n",
      "        -0.0426, -0.0248], grad_fn=<AddBackward0>)\n",
      "tensor(0.0948, grad_fn=<SumBackward0>)\n",
      "Epoch 889 loss is 0.09482711553573608\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.1368, 0.6614, 0.6982, 0.6278, 0.5947, 0.5591, 0.7767, 0.5952, 0.7504,\n",
      "        0.6416, 0.7599], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1462, -0.1697, -0.0222, -0.0464,  0.2482,  0.0009,  0.3188, -0.0451,\n",
      "         0.2745,  0.0158], grad_fn=<AddBackward0>)\n",
      "tensor(0.4288, grad_fn=<SumBackward0>)\n",
      "Epoch 890 loss is 0.42875564098358154\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5872, 0.6026, 0.6200, 0.6104, 0.5851, 0.5905, 0.5766, 0.5846, 0.6209,\n",
      "        0.7731, 0.7495], grad_fn=<ViewBackward0>)\n",
      "tensor([ 5.4526e-02,  3.8643e-02, -5.8546e-03, -9.8219e-03, -1.1278e-02,\n",
      "        -1.5789e-04,  5.0760e-02,  3.2747e-01,  2.7490e-01,  2.1434e-01],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.9335, grad_fn=<SumBackward0>)\n",
      "Epoch 891 loss is 0.9335253834724426\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8178, 0.6481, 0.6277, 0.8042, 0.5672, 0.7664, 0.6283, 0.8214, 0.8374,\n",
      "        0.5381, 0.6067], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0634, -0.0045, -0.0269,  0.2312, -0.0586,  0.4237,  0.1183, -0.0301,\n",
      "        -0.0716, -0.0769], grad_fn=<AddBackward0>)\n",
      "tensor(0.4412, grad_fn=<SumBackward0>)\n",
      "Epoch 892 loss is 0.4411534070968628\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7827, 0.8075, 0.7957, 0.6335, 0.6053, 0.7790, 0.6264, 0.6382, 0.5985,\n",
      "        0.6234, 0.7668], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0216, -0.0497, -0.0674, -0.0056, -0.0024,  0.0549, -0.0601, -0.0010,\n",
      "         0.2143,  0.2804], grad_fn=<AddBackward0>)\n",
      "tensor(0.3849, grad_fn=<SumBackward0>)\n",
      "Epoch 893 loss is 0.38490504026412964\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8403, 0.7902, 0.7649, 0.5973, 0.7968, 0.7664, 0.7639, 0.6228, 0.6874,\n",
      "        0.6464, 0.6429], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0251, -0.0810,  0.0110,  0.0025,  0.2777, -0.0580, -0.0263, -0.0392,\n",
      "         0.0335, -0.0148], grad_fn=<AddBackward0>)\n",
      "tensor(0.0802, grad_fn=<SumBackward0>)\n",
      "Epoch 894 loss is 0.08022207021713257\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8107, 0.5541, 0.5808, 0.6032, 0.6286, 0.7794, 0.7765, 0.7396, 0.8047,\n",
      "        0.6693, 0.7952], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0766, -0.0692,  0.1243,  0.3309,  0.2889,  0.1850,  0.0422, -0.0357,\n",
      "         0.0925, -0.0032], grad_fn=<AddBackward0>)\n",
      "tensor(0.8790, grad_fn=<SumBackward0>)\n",
      "Epoch 895 loss is 0.8790335655212402\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8249, 0.5977, 0.7713, 0.7683, 0.6410, 0.6559, 0.6887, 0.7673, 0.7541,\n",
      "        0.7540, 0.5866], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0179, -0.0189,  0.0723, -0.0385, -0.0266,  0.2105,  0.1638,  0.1088,\n",
      "        -0.0603, -0.0559], grad_fn=<AddBackward0>)\n",
      "tensor(0.3375, grad_fn=<SumBackward0>)\n",
      "Epoch 896 loss is 0.3374730944633484\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5791, 0.8075, 0.6343, 0.6741, 0.7313, 0.6910, 0.6798, 0.6279, 0.7184,\n",
      "        0.5978, 0.5962], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0919,  0.1583, -0.0254,  0.0945,  0.0095, -0.0345,  0.0456, -0.0273,\n",
      "        -0.0106, -0.0407], grad_fn=<AddBackward0>)\n",
      "tensor(0.2614, grad_fn=<SumBackward0>)\n",
      "Epoch 897 loss is 0.2613820433616638\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7965, 0.7626, 0.7354, 0.6550, 0.6616, 0.6753, 0.6498, 0.6776, 0.7513,\n",
      "        0.6841, 0.7005], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0204, -0.0471, -0.0337, -0.0200, -0.0017,  0.0266,  0.1266,  0.0572,\n",
      "         0.0381, -0.0170], grad_fn=<AddBackward0>)\n",
      "tensor(0.1088, grad_fn=<SumBackward0>)\n",
      "Epoch 898 loss is 0.10875678062438965\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6444, 0.7524, 0.7328, 0.7092, 0.6914, 0.6974, 0.6806, 0.6295, 0.6734,\n",
      "        0.6802, 0.6608], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1473,  0.1079, -0.0203, -0.0118, -0.0095, -0.0206, -0.0080, -0.0002,\n",
      "         0.0520, -0.0042], grad_fn=<AddBackward0>)\n",
      "tensor(0.2326, grad_fn=<SumBackward0>)\n",
      "Epoch 899 loss is 0.2325977087020874\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.0612, 0.7396, 0.6952, 0.6959, 0.6538, 0.6744, 0.7256, 0.6942, 0.7386,\n",
      "        0.6725, 0.6708], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1220, -0.1218, -0.0286, -0.0069,  0.0495,  0.0674,  0.1070, -0.0177,\n",
      "        -0.0078, -0.0226], grad_fn=<AddBackward0>)\n",
      "tensor(-0.1036, grad_fn=<SumBackward0>)\n",
      "Epoch 900 loss is -0.10360616445541382\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7336, 0.6823, 0.6986, 0.7157, 0.6837, 0.6833, 0.6801, 0.6857, 0.7379,\n",
      "        0.6497, 0.7029], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0117, -0.0060,  0.0024, -0.0051, -0.0119,  0.0033,  0.0910, -0.0101,\n",
      "         0.0287, -0.0117], grad_fn=<AddBackward0>)\n",
      "tensor(0.0689, grad_fn=<SumBackward0>)\n",
      "Epoch 901 loss is 0.06893610954284668\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6721, 0.6898, 0.7030, 0.6841, 0.6784, 0.7084, 0.7128, 0.6763, 0.7019,\n",
      "        0.6387, 0.6910], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0515,  0.0200, -0.0038,  0.0090,  0.0477, -0.0007, -0.0022, -0.0247,\n",
      "         0.0245, -0.0036], grad_fn=<AddBackward0>)\n",
      "tensor(0.1177, grad_fn=<SumBackward0>)\n",
      "Epoch 902 loss is 0.11773455142974854\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6257, 0.7585, 0.7142, 0.6995, 0.6650, 0.6595, 0.6942, 0.6486, 0.7315,\n",
      "        0.7654, 0.6929], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1475,  0.1230, -0.0312, -0.0182, -0.0017, -0.0055,  0.1200,  0.1185,\n",
      "         0.0738, -0.0129], grad_fn=<AddBackward0>)\n",
      "tensor(0.5133, grad_fn=<SumBackward0>)\n",
      "Epoch 903 loss is 0.5133373141288757\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6702, 0.6359, 0.7123, 0.7293, 0.7107, 0.6519, 0.6571, 0.6797, 0.7459,\n",
      "        0.6570, 0.7071], grad_fn=<ViewBackward0>)\n",
      "tensor([ 7.0167e-02,  9.8431e-02,  1.2465e-01, -2.0147e-02, -2.4076e-02,\n",
      "        -1.0332e-02,  1.5672e-01, -1.3649e-05,  4.5659e-02, -1.2937e-02],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.4281, grad_fn=<SumBackward0>)\n",
      "Epoch 904 loss is 0.4281209707260132\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6362, 0.7298, 0.6973, 0.7395, 0.6417, 0.7395, 0.6162, 0.6445, 0.6979,\n",
      "        0.7042, 0.6802], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1019,  0.1722, -0.0293,  0.0702, -0.0411,  0.0045, -0.0139,  0.1468,\n",
      "         0.0596, -0.0059], grad_fn=<AddBackward0>)\n",
      "tensor(0.4651, grad_fn=<SumBackward0>)\n",
      "Epoch 905 loss is 0.46511054039001465\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6197, 0.7514, 0.6853, 0.6997, 0.6969, 0.6374, 0.7215, 0.6710, 0.6617,\n",
      "        0.7179, 0.6641], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1094,  0.1333, -0.0182, -0.0159,  0.0363, -0.0086,  0.0404, -0.0012,\n",
      "        -0.0023,  0.0041], grad_fn=<AddBackward0>)\n",
      "tensor(0.2773, grad_fn=<SumBackward0>)\n",
      "Epoch 906 loss is 0.2773440480232239\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6364, 0.6328, 0.7045, 0.7527, 0.6850, 0.6743, 0.6366, 0.7164, 0.6673,\n",
      "        0.6474, 0.6883], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1135,  0.1938,  0.0870, -0.0101, -0.0387,  0.0523, -0.0023,  0.0179,\n",
      "        -0.0094,  0.0349], grad_fn=<AddBackward0>)\n",
      "tensor(0.4390, grad_fn=<SumBackward0>)\n",
      "Epoch 907 loss is 0.4389593005180359\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5913, 0.7767, 0.8036, 0.6280, 0.7405, 0.6384, 0.6120, 0.6105, 0.7446,\n",
      "        0.7597, 0.7598], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.3540,  0.0613, -0.0121, -0.0551, -0.0053, -0.0433,  0.1771,  0.2462,\n",
      "         0.2489,  0.0253], grad_fn=<AddBackward0>)\n",
      "tensor(0.9969, grad_fn=<SumBackward0>)\n",
      "Epoch 908 loss is 0.9969049692153931\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6277, 0.7764, 0.6008, 0.6063, 0.7742, 0.5744, 0.8214, 0.7675, 0.5569,\n",
      "        0.7823, 0.5827], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0090, -0.0071, -0.0007, -0.0088,  0.3585, -0.0022, -0.0058, -0.0130,\n",
      "        -0.0616,  0.0428], grad_fn=<AddBackward0>)\n",
      "tensor(0.2930, grad_fn=<SumBackward0>)\n",
      "Epoch 909 loss is 0.2929784655570984\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.4807, 0.7364, 0.6989, 0.6527, 0.6689, 0.6312, 0.5778, 0.7259, 0.6274,\n",
      "        0.5900, 0.8188], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.3636,  0.2866, -0.0225, -0.0226, -0.0249,  0.0951, -0.0013,  0.0203,\n",
      "         0.1548,  0.3190], grad_fn=<AddBackward0>)\n",
      "tensor(1.1681, grad_fn=<SumBackward0>)\n",
      "Epoch 910 loss is 1.1681463718414307\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8373, 0.8233, 0.7641, 0.5901, 0.8012, 0.7754, 0.7896, 0.5460, 0.5715,\n",
      "        0.5459, 0.5781], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0244, -0.0824, -0.0074,  0.0189,  0.3326, -0.0851, -0.0680, -0.0812,\n",
      "         0.0536,  0.0111], grad_fn=<AddBackward0>)\n",
      "tensor(0.0677, grad_fn=<SumBackward0>)\n",
      "Epoch 911 loss is 0.06767547130584717\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5254, 0.8959, 0.8397, 0.8411, 0.5564, 0.5793, 0.8190, 0.7678, 0.7917,\n",
      "        0.8111, 0.5637], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.5238,  0.5262, -0.1131, -0.0868, -0.0074,  0.3522,  0.3540, -0.0026,\n",
      "        -0.0680, -0.0760], grad_fn=<AddBackward0>)\n",
      "tensor(1.4023, grad_fn=<SumBackward0>)\n",
      "Epoch 912 loss is 1.402282953262329\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5415, 0.7906, 0.7933, 0.5598, 0.8250, 0.8366, 0.5806, 0.6058, 0.5502,\n",
      "        0.6054, 0.6117], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4197,  0.0305,  0.0574,  0.0721,  0.0347, -0.0731, -0.0955,  0.0414,\n",
      "         0.0100,  0.1026], grad_fn=<AddBackward0>)\n",
      "tensor(0.5998, grad_fn=<SumBackward0>)\n",
      "Epoch 913 loss is 0.5997717976570129\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6093, 0.5459, 0.5342, 0.8187, 0.5729, 0.5394, 0.5588, 0.8832, 0.5443,\n",
      "        0.5668, 0.5395], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0250,  0.3491,  0.0450,  0.0087, -0.0866,  0.5172,  0.0082,  0.0132,\n",
      "        -0.1146, -0.0016], grad_fn=<AddBackward0>)\n",
      "tensor(0.7136, grad_fn=<SumBackward0>)\n",
      "Epoch 914 loss is 0.7135674953460693\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9017, 0.8857, 0.7607, 0.8473, 0.8797, 0.8000, 0.8253, 0.8277, 0.5485,\n",
      "        0.7963, 0.8000], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0470, -0.0181, -0.0020,  0.0655, -0.0073, -0.0173, -0.0838, -0.0097,\n",
      "        -0.0092,  0.4192], grad_fn=<AddBackward0>)\n",
      "tensor(0.2902, grad_fn=<SumBackward0>)\n",
      "Epoch 915 loss is 0.290155291557312\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5554, 0.5496, 0.8300, 0.5460, 0.8060, 0.8449, 0.5364, 0.8391, 0.8031,\n",
      "        0.8338, 0.8742], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4577, -0.0031,  0.4274,  0.0248, -0.0032,  0.0553, -0.0139,  0.4957,\n",
      "         0.0584,  0.1184], grad_fn=<AddBackward0>)\n",
      "tensor(1.6174, grad_fn=<SumBackward0>)\n",
      "Epoch 916 loss is 1.6173508167266846\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8406, 0.8077, 0.7967, 0.5929, 0.7971, 0.8220, 0.6005, 0.7553, 0.6126,\n",
      "        0.7924, 0.8102], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0146, -0.0826, -0.0035,  0.0421,  0.0126, -0.0139, -0.0698,  0.3198,\n",
      "         0.0916,  0.3294], grad_fn=<AddBackward0>)\n",
      "tensor(0.6110, grad_fn=<SumBackward0>)\n",
      "Epoch 917 loss is 0.6110073924064636\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5596, 0.8123, 0.7604, 0.6148, 0.6077, 0.6292, 0.5642, 0.8096, 0.5750,\n",
      "        0.5740, 0.5430], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.3346,  0.0920, -0.0682, -0.0437, -0.0169,  0.3364, -0.0181,  0.0164,\n",
      "        -0.0888, -0.0106], grad_fn=<AddBackward0>)\n",
      "tensor(0.5330, grad_fn=<SumBackward0>)\n",
      "Epoch 918 loss is 0.5330342054367065\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8208, 0.6409, 0.6237, 0.6303, 0.6398, 0.7608, 0.7945, 0.7436, 0.7364,\n",
      "        0.6772, 0.7078], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0657, -0.0635, -0.0004,  0.2285,  0.2737,  0.1731, -0.0081, -0.0391,\n",
      "        -0.0120, -0.0096], grad_fn=<AddBackward0>)\n",
      "tensor(0.4770, grad_fn=<SumBackward0>)\n",
      "Epoch 919 loss is 0.4770160913467407\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.0017, 0.6466, 0.7258, 0.7123, 0.6673, 0.7336, 0.7508, 0.7012, 0.6513,\n",
      "        0.7051, 0.6621], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0920, -0.0965,  0.0344,  0.0130,  0.0641,  0.0564, -0.0274, -0.0152,\n",
      "        -0.0130,  0.0179], grad_fn=<AddBackward0>)\n",
      "tensor(-0.0582, grad_fn=<SumBackward0>)\n",
      "Epoch 920 loss is -0.058177173137664795\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6823, 0.7023, 0.6929, 0.6919, 0.6819, 0.6511, 0.7203, 0.6220, 0.6848,\n",
      "        0.6731, 0.6352], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0177,  0.0160, -0.0068, -0.0139,  0.0474, -0.0200,  0.0562, -0.0158,\n",
      "         0.0221, -0.0165], grad_fn=<AddBackward0>)\n",
      "tensor(0.0862, grad_fn=<SumBackward0>)\n",
      "Epoch 921 loss is 0.08623462915420532\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7305, 0.6828, 0.7109, 0.6866, 0.7112, 0.7299, 0.7614, 0.7362, 0.6514,\n",
      "        0.6431, 0.7157], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0065, -0.0147,  0.0472,  0.0317,  0.1247,  0.0417, -0.0262, -0.0394,\n",
      "        -0.0068,  0.1072], grad_fn=<AddBackward0>)\n",
      "tensor(0.2588, grad_fn=<SumBackward0>)\n",
      "Epoch 922 loss is 0.25882571935653687\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7078, 0.7221, 0.7003, 0.7431, 0.7433, 0.6389, 0.5862, 0.6898, 0.6513,\n",
      "        0.7040, 0.6722], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0025,  0.0588,  0.0353, -0.0205, -0.0523, -0.0178,  0.0206,  0.1963,\n",
      "        -0.0059,  0.0349], grad_fn=<AddBackward0>)\n",
      "tensor(0.2469, grad_fn=<SumBackward0>)\n",
      "Epoch 923 loss is 0.24689823389053345\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6833, 0.6912, 0.6688, 0.6703, 0.6385, 0.6856, 0.6161, 0.7124, 0.6552,\n",
      "        0.7095, 0.6403], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0049, -0.0043, -0.0175,  0.0281, -0.0181,  0.1231, -0.0101,  0.1557,\n",
      "        -0.0241, -0.0050], grad_fn=<AddBackward0>)\n",
      "tensor(0.2229, grad_fn=<SumBackward0>)\n",
      "Epoch 924 loss is 0.22291874885559082\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7218, 0.6639, 0.7112, 0.6428, 0.6580, 0.7738, 0.6761, 0.7325, 0.6389,\n",
      "        0.6489, 0.7667], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0035, -0.0263, -0.0019,  0.1044,  0.0555,  0.1241, -0.0450, -0.0091,\n",
      "         0.0571,  0.2130], grad_fn=<AddBackward0>)\n",
      "tensor(0.4682, grad_fn=<SumBackward0>)\n",
      "Epoch 925 loss is 0.4681820869445801\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6582, 0.6865, 0.6660, 0.7392, 0.7445, 0.7147, 0.6364, 0.7706, 0.6325,\n",
      "        0.6283, 0.7125], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0130,  0.1350,  0.0966,  0.0811, -0.0343,  0.0435, -0.0274, -0.0027,\n",
      "        -0.0194,  0.1333], grad_fn=<AddBackward0>)\n",
      "tensor(0.4189, grad_fn=<SumBackward0>)\n",
      "Epoch 926 loss is 0.4189130663871765\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6869, 0.6362, 0.6119, 0.6639, 0.7706, 0.6172, 0.6649, 0.7187, 0.6453,\n",
      "        0.6473, 0.5983], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0250, -0.0076,  0.2239,  0.0088,  0.0017, -0.0173,  0.0470, -0.0059,\n",
      "        -0.0401, -0.0157], grad_fn=<AddBackward0>)\n",
      "tensor(0.1698, grad_fn=<SumBackward0>)\n",
      "Epoch 927 loss is 0.16980904340744019\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7049, 0.6221, 0.7167, 0.6230, 0.6357, 0.7615, 0.7733, 0.6189, 0.8090,\n",
      "        0.6328, 0.7340], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0196, -0.0273,  0.0226,  0.0746,  0.2505, -0.0056,  0.0792, -0.0468,\n",
      "         0.1919, -0.0250], grad_fn=<AddBackward0>)\n",
      "tensor(0.5335, grad_fn=<SumBackward0>)\n",
      "Epoch 928 loss is 0.5335428714752197\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6920, 0.7491, 0.7488, 0.7722, 0.6021, 0.7563, 0.5996, 0.7218, 0.7323,\n",
      "        0.6471, 0.6189], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0946,  0.1337, -0.0490,  0.0124, -0.0575,  0.1994, -0.0080,  0.0791,\n",
      "        -0.0343, -0.0378], grad_fn=<AddBackward0>)\n",
      "tensor(0.3327, grad_fn=<SumBackward0>)\n",
      "Epoch 929 loss is 0.33265966176986694\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.9769, 0.9260, 0.5467, 0.6226, 0.7583, 0.6031, 0.6385, 0.5968, 0.6531,\n",
      "        0.7158, 0.5936], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1434, -0.1181, -0.0559,  0.0940,  0.0264, -0.0538,  0.0834,  0.1288,\n",
      "        -0.0011, -0.0199], grad_fn=<AddBackward0>)\n",
      "tensor(-0.0596, grad_fn=<SumBackward0>)\n",
      "Epoch 930 loss is -0.05957973003387451\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7058, 0.8197, 0.6281, 0.6538, 0.6547, 0.6692, 0.6929, 0.7278, 0.6336,\n",
      "        0.7117, 0.6788], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0259, -0.0173, -0.0550,  0.0684,  0.0652,  0.1219, -0.0119,  0.0314,\n",
      "        -0.0164,  0.0753], grad_fn=<AddBackward0>)\n",
      "tensor(0.2358, grad_fn=<SumBackward0>)\n",
      "Epoch 931 loss is 0.2357751727104187\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7350, 0.7734, 0.7857, 0.5803, 0.8689, 0.7422, 0.7538, 0.6307, 0.6196,\n",
      "        0.7474, 0.6987], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0844, -0.0516,  0.1592, -0.0145,  0.2892, -0.0794, -0.0409, -0.0021,\n",
      "         0.1132,  0.1317], grad_fn=<AddBackward0>)\n",
      "tensor(0.5893, grad_fn=<SumBackward0>)\n",
      "Epoch 932 loss is 0.5893000364303589\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6737, 0.6660, 0.7671, 0.7363, 0.7754, 0.7685, 0.6476, 0.7058, 0.6230,\n",
      "        0.7682, 0.6109], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1557,  0.1044,  0.1823,  0.0024, -0.0296, -0.0232, -0.0485,  0.2010,\n",
      "        -0.0316, -0.0040], grad_fn=<AddBackward0>)\n",
      "tensor(0.5089, grad_fn=<SumBackward0>)\n",
      "Epoch 933 loss is 0.5088728070259094\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6653, 0.6403, 0.7547, 0.6683, 0.6378, 0.7620, 0.7220, 0.6534, 0.6615,\n",
      "        0.7605, 0.6609], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1489,  0.0050, -0.0008,  0.0123,  0.0895,  0.0259, -0.0335,  0.0641,\n",
      "         0.0126, -0.0002], grad_fn=<AddBackward0>)\n",
      "tensor(0.3238, grad_fn=<SumBackward0>)\n",
      "Epoch 934 loss is 0.3237863779067993\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7027, 0.7099, 0.6708, 0.7424, 0.6675, 0.6798, 0.6828, 0.6917, 0.6906,\n",
      "        0.6535, 0.6590], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0106,  0.0663, -0.0141,  0.0150, -0.0199,  0.0404,  0.0180, -0.0098,\n",
      "        -0.0109, -0.0106], grad_fn=<AddBackward0>)\n",
      "tensor(0.0639, grad_fn=<SumBackward0>)\n",
      "Epoch 935 loss is 0.06385374069213867\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6533, 0.7487, 0.7194, 0.6848, 0.6581, 0.6750, 0.6611, 0.6472, 0.6795,\n",
      "        0.6600, 0.6792], grad_fn=<ViewBackward0>)\n",
      "tensor([ 1.1017e-01,  5.2522e-02, -3.0183e-02, -1.4786e-02, -7.9077e-03,\n",
      "        -3.6515e-03,  7.3624e-03, -3.5179e-04,  5.3347e-02, -9.3818e-05],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.1664, grad_fn=<SumBackward0>)\n",
      "Epoch 936 loss is 0.16642975807189941\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7621, 0.6651, 0.6637, 0.6707, 0.7482, 0.6958, 0.6871, 0.6722, 0.7203,\n",
      "        0.7375, 0.7346], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0328, -0.0305,  0.1384,  0.0535,  0.0273, -0.0253,  0.0408,  0.0841,\n",
      "         0.1039,  0.0238], grad_fn=<AddBackward0>)\n",
      "tensor(0.3831, grad_fn=<SumBackward0>)\n",
      "Epoch 937 loss is 0.3831414580345154\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7612, 0.6463, 0.6675, 0.6893, 0.6257, 0.6901, 0.6582, 0.6288, 0.7546,\n",
      "        0.6348, 0.7914], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0312, -0.0240, -0.0069,  0.0377, -0.0103,  0.0052,  0.1076, -0.0078,\n",
      "         0.2710,  0.0613], grad_fn=<AddBackward0>)\n",
      "tensor(0.4025, grad_fn=<SumBackward0>)\n",
      "Epoch 938 loss is 0.4024742841720581\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5823, 0.7558, 0.7466, 0.6217, 0.6223, 0.7181, 0.6565, 0.7194, 0.7613,\n",
      "        0.6287, 0.6718], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2737,  0.0655, -0.0445, -0.0095,  0.0581,  0.1619,  0.0720, -0.0093,\n",
      "        -0.0159, -0.0298], grad_fn=<AddBackward0>)\n",
      "tensor(0.5223, grad_fn=<SumBackward0>)\n",
      "Epoch 939 loss is 0.5223357677459717\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.3816, 0.6247, 0.7104, 0.6682, 0.7538, 0.7846, 0.7696, 0.6498, 0.6482,\n",
      "        0.7247, 0.6710], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.5480,  0.4777,  0.2152,  0.1237,  0.1690, -0.0347, -0.0455, -0.0150,\n",
      "         0.0354,  0.0380], grad_fn=<AddBackward0>)\n",
      "tensor(1.5118, grad_fn=<SumBackward0>)\n",
      "Epoch 940 loss is 1.5118364095687866\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7975, 0.5759, 0.6270, 0.7227, 0.7791, 0.7697, 0.6294, 0.7731, 0.6158,\n",
      "        0.6455, 0.6356], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0568, -0.0249,  0.3388,  0.2378, -0.0311, -0.0020, -0.0513,  0.0269,\n",
      "        -0.0458,  0.0331], grad_fn=<AddBackward0>)\n",
      "tensor(0.4246, grad_fn=<SumBackward0>)\n",
      "Epoch 941 loss is 0.4245713949203491\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5669, 0.5825, 0.7121, 0.6565, 0.7318, 0.7081, 0.7030, 0.6352, 0.7311,\n",
      "        0.6354, 0.7545], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2419,  0.1493,  0.2488, -0.0013,  0.0774, -0.0322,  0.0383, -0.0225,\n",
      "         0.1988,  0.0390], grad_fn=<AddBackward0>)\n",
      "tensor(0.9375, grad_fn=<SumBackward0>)\n",
      "Epoch 942 loss is 0.9375330805778503\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7986, 0.7034, 0.6162, 0.7213, 0.7145, 0.7159, 0.7286, 0.7073, 0.7431,\n",
      "        0.7450, 0.6438], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0608, -0.0258,  0.0184,  0.1663,  0.0121, -0.0024,  0.0453,  0.0273,\n",
      "        -0.0212, -0.0331], grad_fn=<AddBackward0>)\n",
      "tensor(0.1261, grad_fn=<SumBackward0>)\n",
      "Epoch 943 loss is 0.12609750032424927\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7403, 0.6501, 0.6930, 0.6814, 0.7296, 0.6589, 0.6636, 0.6958, 0.7005,\n",
      "        0.6316, 0.6287], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0157, -0.0196,  0.1326, -0.0114, -0.0059, -0.0113,  0.0692, -0.0107,\n",
      "        -0.0224, -0.0239], grad_fn=<AddBackward0>)\n",
      "tensor(0.0809, grad_fn=<SumBackward0>)\n",
      "Epoch 944 loss is 0.08093857765197754\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7663, 0.7057, 0.7137, 0.6733, 0.7292, 0.6569, 0.6620, 0.6640, 0.6789,\n",
      "        0.6994, 0.6573], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0176, -0.0310,  0.0391, -0.0189, -0.0037, -0.0217,  0.0368,  0.0623,\n",
      "        -0.0022, -0.0072], grad_fn=<AddBackward0>)\n",
      "tensor(0.0357, grad_fn=<SumBackward0>)\n",
      "Epoch 945 loss is 0.03572505712509155\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6762, 0.7111, 0.6344, 0.6245, 0.6995, 0.6573, 0.6706, 0.6207, 0.6578,\n",
      "        0.6865, 0.6908], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0139, -0.0172, -0.0038,  0.0382,  0.0768, -0.0263,  0.0008,  0.0265,\n",
      "         0.1168,  0.0551], grad_fn=<AddBackward0>)\n",
      "tensor(0.2529, grad_fn=<SumBackward0>)\n",
      "Epoch 946 loss is 0.2528676986694336\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7057, 0.7351, 0.6559, 0.7207, 0.7718, 0.6126, 0.5870, 0.8082, 0.5773,\n",
      "        0.6379, 0.6138], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0166,  0.0250,  0.0612, -0.0144, -0.0446,  0.0607, -0.0118,  0.0849,\n",
      "        -0.0648,  0.0608], grad_fn=<AddBackward0>)\n",
      "tensor(0.1404, grad_fn=<SumBackward0>)\n",
      "Epoch 947 loss is 0.1404033899307251\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6531, 0.7930, 0.8753, 0.7541, 0.6316, 0.5849, 0.5980, 0.7957, 0.5747,\n",
      "        0.8114, 0.8071], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.3703,  0.1683, -0.0538, -0.0968, -0.0520,  0.2735, -0.0034,  0.3557,\n",
      "         0.0189,  0.3874], grad_fn=<AddBackward0>)\n",
      "tensor(1.3682, grad_fn=<SumBackward0>)\n",
      "Epoch 948 loss is 1.3681674003601074\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7529, 0.8436, 0.5420, 0.5822, 0.8478, 0.8329, 0.5945, 0.5626, 0.7883,\n",
      "        0.8508, 0.5650], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0703, -0.0569,  0.0070,  0.4849,  0.0205, -0.0951, -0.0149,  0.4271,\n",
      "         0.0040, -0.0744], grad_fn=<AddBackward0>)\n",
      "tensor(0.6319, grad_fn=<SumBackward0>)\n",
      "Epoch 949 loss is 0.6319100856781006\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5998, 0.4575, 0.4945, 0.5278, 0.8556, 0.5350, 0.5263, 0.5687, 0.5261,\n",
      "        0.5514, 0.5545], grad_fn=<ViewBackward0>)\n",
      "tensor([-3.5127e-02, -2.4018e-02,  6.6342e-01,  6.7553e-02, -4.9257e-04,\n",
      "        -9.5616e-02, -2.9542e-03,  4.1891e-02, -4.7483e-03,  4.7239e-02],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.6571, grad_fn=<SumBackward0>)\n",
      "Epoch 950 loss is 0.657149076461792\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8664, 0.5602, 0.5156, 0.9340, 0.8111, 0.8694, 0.8463, 0.8147, 0.8912,\n",
      "        0.5258, 0.8227], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1169,  0.1127,  0.4182,  0.5896, -0.0292,  0.0059,  0.0364, -0.1068,\n",
      "         0.0134, -0.0228], grad_fn=<AddBackward0>)\n",
      "tensor(0.9003, grad_fn=<SumBackward0>)\n",
      "Epoch 951 loss is 0.9003379940986633\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7662, 0.8173, 0.8474, 0.8515, 0.7994, 0.8671, 0.4937, 0.5227, 0.8604,\n",
      "        0.5269, 0.8576], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1353,  0.1421, -0.0060,  0.0327, -0.1193, -0.0922, -0.0022,  0.0553,\n",
      "         0.5582, -0.0009], grad_fn=<AddBackward0>)\n",
      "tensor(0.7030, grad_fn=<SumBackward0>)\n",
      "Epoch 952 loss is 0.7030431032180786\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7844, 0.8595, 0.5201, 0.9520, 0.5008, 0.5245, 0.5024, 0.5396, 0.5131,\n",
      "        0.5298, 0.8727], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0881,  0.2793, -0.1196,  0.0072, -0.1498,  0.0646, -0.0038,  0.0456,\n",
      "         0.5553,  0.5993], grad_fn=<AddBackward0>)\n",
      "tensor(1.1900, grad_fn=<SumBackward0>)\n",
      "Epoch 953 loss is 1.1900098323822021\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8140, 0.8402, 0.5334, 0.8312, 0.7758, 0.5409, 0.5266, 0.9221, 0.5426,\n",
      "        0.5431, 0.8770], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0935,  0.0287, -0.0214,  0.0125, -0.1015,  0.2438,  0.0028,  0.0274,\n",
      "        -0.0150,  0.5574], grad_fn=<AddBackward0>)\n",
      "tensor(0.6410, grad_fn=<SumBackward0>)\n",
      "Epoch 954 loss is 0.6410391926765442\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6277, 0.7446, 0.8129, 0.5493, 0.5491, 0.5427, 0.5444, 0.8466, 0.8876,\n",
      "        0.9059, 0.9166], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.3086, -0.0261, -0.0651, -0.0901, -0.0016,  0.4957,  0.5748,  0.6025,\n",
      "         0.1167,  0.0483], grad_fn=<AddBackward0>)\n",
      "tensor(1.9635, grad_fn=<SumBackward0>)\n",
      "Epoch 955 loss is 1.9635496139526367\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8179, 0.7913, 0.8187, 0.5559, 0.8365, 0.5558, 0.8595, 0.8402, 0.7783,\n",
      "        0.8329, 0.5370], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0014, -0.0873,  0.0755, -0.0876,  0.5059,  0.0060,  0.3709, -0.0088,\n",
      "        -0.1011, -0.0805], grad_fn=<AddBackward0>)\n",
      "tensor(0.5945, grad_fn=<SumBackward0>)\n",
      "Epoch 956 loss is 0.594474196434021\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6714, 0.6080, 0.6211, 0.7919, 0.7463, 0.8376, 0.5807, 0.8308, 0.7284,\n",
      "        0.6031, 0.7993], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0168,  0.2008,  0.2306,  0.3609, -0.0704,  0.1407, -0.0364,  0.0373,\n",
      "        -0.0105,  0.1181], grad_fn=<AddBackward0>)\n",
      "tensor(0.9544, grad_fn=<SumBackward0>)\n",
      "Epoch 957 loss is 0.9544413089752197\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6971, 0.7441, 0.8462, 0.5569, 0.6335, 0.6412, 0.7329, 0.6432, 0.6120,\n",
      "        0.7837, 0.6343], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2485, -0.0467, -0.0369, -0.0683,  0.2934,  0.0161, -0.0098,  0.0847,\n",
      "        -0.0030,  0.0372], grad_fn=<AddBackward0>)\n",
      "tensor(0.5153, grad_fn=<SumBackward0>)\n",
      "Epoch 958 loss is 0.5153427720069885\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6742, 0.6858, 0.6724, 0.6674, 0.7207, 0.7320, 0.7295, 0.6548, 0.6383,\n",
      "        0.6451, 0.6394], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0006, -0.0023,  0.0583,  0.0993,  0.1036, -0.0220, -0.0312, -0.0281,\n",
      "        -0.0051,  0.0019], grad_fn=<AddBackward0>)\n",
      "tensor(0.1736, grad_fn=<SumBackward0>)\n",
      "Epoch 959 loss is 0.1736215353012085\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.0601, 0.8450, 0.5818, 0.7605, 0.6497, 0.7330, 0.7077, 0.6853, 0.6638,\n",
      "        0.6584, 0.6817], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1594, -0.0999, -0.0651,  0.2519, -0.0176,  0.0593, -0.0231, -0.0164,\n",
      "        -0.0012,  0.0298], grad_fn=<AddBackward0>)\n",
      "tensor(-0.0417, grad_fn=<SumBackward0>)\n",
      "Epoch 960 loss is -0.041706740856170654\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7692, 0.6581, 0.6633, 0.7256, 0.6629, 0.7299, 0.6677, 0.7124, 0.7475,\n",
      "        0.7718, 0.7799], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0353, -0.0145,  0.0081,  0.1111, -0.0193,  0.0824,  0.0293,  0.1736,\n",
      "         0.1125,  0.0540], grad_fn=<AddBackward0>)\n",
      "tensor(0.5018, grad_fn=<SumBackward0>)\n",
      "Epoch 961 loss is 0.5017951130867004\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5807, 0.6086, 0.7128, 0.6645, 0.7579, 0.8101, 0.7230, 0.6877, 0.7357,\n",
      "        0.6087, 0.5489], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2201,  0.1396,  0.2489,  0.1623,  0.0975, -0.0234, -0.0248, -0.0381,\n",
      "        -0.0463, -0.0622], grad_fn=<AddBackward0>)\n",
      "tensor(0.6736, grad_fn=<SumBackward0>)\n",
      "Epoch 962 loss is 0.6735706329345703\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5837, 0.6304, 0.7928, 0.6384, 0.7555, 0.6258, 0.6397, 0.5704, 0.6247,\n",
      "        0.6650, 0.7961], grad_fn=<ViewBackward0>)\n",
      "tensor([ 3.4862e-01,  9.1236e-02,  2.0849e-01, -5.5665e-02,  2.1237e-03,\n",
      "        -6.1692e-02, -3.6585e-04,  4.2268e-02,  3.7628e-01,  2.8567e-01],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(1.2370, grad_fn=<SumBackward0>)\n",
      "Epoch 963 loss is 1.2369728088378906\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8356, 0.7662, 0.5915, 0.7778, 0.6175, 0.6142, 0.7193, 0.5808, 0.6064,\n",
      "        0.5711, 0.7680], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0814, -0.0193, -0.0496,  0.0377, -0.0195, -0.0122, -0.0026, -0.0494,\n",
      "         0.3120,  0.2694], grad_fn=<AddBackward0>)\n",
      "tensor(0.3852, grad_fn=<SumBackward0>)\n",
      "Epoch 964 loss is 0.385181725025177\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5244, 0.8435, 0.7821, 0.6053, 0.7913, 0.8117, 0.8152, 0.7980, 0.8090,\n",
      "        0.5769, 0.6483], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.4295,  0.1348, -0.0174,  0.0493,  0.3498,  0.0112, -0.0009, -0.0794,\n",
      "        -0.0499, -0.0536], grad_fn=<AddBackward0>)\n",
      "tensor(0.7734, grad_fn=<SumBackward0>)\n",
      "Epoch 965 loss is 0.7734243869781494\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8407, 0.5847, 0.8688, 0.5975, 0.6065, 0.8140, 0.5814, 0.7786, 0.8075,\n",
      "        0.5431, 0.5600], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0468, -0.0811,  0.0364, -0.0183, -0.0054,  0.2868, -0.0022, -0.0128,\n",
      "        -0.0729, -0.0825], grad_fn=<AddBackward0>)\n",
      "tensor(0.0949, grad_fn=<SumBackward0>)\n",
      "Epoch 966 loss is 0.09492522478103638\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8737, 0.8039, 0.5710, 0.8515, 0.8380, 0.5799, 0.7697, 0.7444, 0.7782,\n",
      "        0.6188, 0.6519], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1009, -0.0074,  0.0569,  0.0149, -0.0273, -0.0312,  0.3305, -0.0503,\n",
      "        -0.0308, -0.0421], grad_fn=<AddBackward0>)\n",
      "tensor(0.1123, grad_fn=<SumBackward0>)\n",
      "Epoch 967 loss is 0.1122671365737915\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8026, 0.7900, 0.5899, 0.7728, 0.5952, 0.7934, 0.8132, 0.8223, 0.6066,\n",
      "        0.6148, 0.6514], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0709, -0.0099, -0.0649,  0.3391,  0.0673,  0.3784, -0.0623, -0.0662,\n",
      "        -0.0570,  0.0746], grad_fn=<AddBackward0>)\n",
      "tensor(0.5282, grad_fn=<SumBackward0>)\n",
      "Epoch 968 loss is 0.5282449722290039\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5533, 0.7936, 0.5932, 0.8122, 0.5770, 0.7864, 0.7749, 0.6181, 0.7946,\n",
      "        0.6231, 0.6276], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0666,  0.4315, -0.0722,  0.3220, -0.0124,  0.0686,  0.0137, -0.0506,\n",
      "         0.0158, -0.0557], grad_fn=<AddBackward0>)\n",
      "tensor(0.7273, grad_fn=<SumBackward0>)\n",
      "Epoch 969 loss is 0.7272985577583313\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.1153, 0.7106, 0.6866, 0.7640, 0.7495, 0.6412, 0.7158, 0.6642, 0.7275,\n",
      "        0.6271, 0.7510], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1429, -0.1171,  0.0648, -0.0151, -0.0161, -0.0284,  0.1439, -0.0296,\n",
      "         0.1447,  0.0391], grad_fn=<AddBackward0>)\n",
      "tensor(0.0434, grad_fn=<SumBackward0>)\n",
      "Epoch 970 loss is 0.04336881637573242\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5939, 0.6878, 0.7550, 0.7523, 0.7057, 0.6947, 0.7061, 0.6516, 0.7093,\n",
      "        0.7530, 0.7763], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2685,  0.2639,  0.0299, -0.0201, -0.0154, -0.0180,  0.0243,  0.0781,\n",
      "         0.2079,  0.1118], grad_fn=<AddBackward0>)\n",
      "tensor(0.9309, grad_fn=<SumBackward0>)\n",
      "Epoch 971 loss is 0.9308571219444275\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7777, 0.6591, 0.7004, 0.7119, 0.6712, 0.6906, 0.6665, 0.7066, 0.6572,\n",
      "        0.6423, 0.6431], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0258, -0.0219,  0.0200, -0.0033, -0.0151,  0.0590, -0.0112, -0.0081,\n",
      "        -0.0211, -0.0047], grad_fn=<AddBackward0>)\n",
      "tensor(-0.0321, grad_fn=<SumBackward0>)\n",
      "Epoch 972 loss is -0.0320737361907959\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7349, 0.6646, 0.6708, 0.7664, 0.6788, 0.7232, 0.6845, 0.6638, 0.6836,\n",
      "        0.7574, 0.6739], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0214,  0.0524,  0.0235,  0.0874, -0.0273, -0.0050, -0.0132,  0.1215,\n",
      "         0.0168, -0.0032], grad_fn=<AddBackward0>)\n",
      "tensor(0.2316, grad_fn=<SumBackward0>)\n",
      "Epoch 973 loss is 0.2315865159034729\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6896, 0.6657, 0.7069, 0.6720, 0.6186, 0.6639, 0.7653, 0.6826, 0.7668,\n",
      "        0.6571, 0.7163], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0289, -0.0059, -0.0157, -0.0143,  0.1555,  0.1065,  0.1715, -0.0361,\n",
      "         0.0562, -0.0168], grad_fn=<AddBackward0>)\n",
      "tensor(0.4299, grad_fn=<SumBackward0>)\n",
      "Epoch 974 loss is 0.42990875244140625\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6593, 0.7340, 0.6710, 0.7091, 0.6757, 0.6738, 0.6297, 0.6309, 0.6547,\n",
      "        0.7517, 0.6145], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0195,  0.0829, -0.0194,  0.0046, -0.0264, -0.0149, -0.0064,  0.2032,\n",
      "        -0.0055, -0.0134], grad_fn=<AddBackward0>)\n",
      "tensor(0.2242, grad_fn=<SumBackward0>)\n",
      "Epoch 975 loss is 0.2242487668991089\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7486, 0.5961, 0.7897, 0.6067, 0.5955, 0.7281, 0.6258, 0.7762, 0.5652,\n",
      "        0.5802, 0.6204], grad_fn=<ViewBackward0>)\n",
      "tensor([ 6.8566e-02, -4.7305e-02, -1.9294e-04, -2.0544e-02,  3.1944e-02,\n",
      "         3.0116e-01, -5.4298e-02, -1.5222e-02, -5.1932e-02,  9.2080e-02],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(0.3043, grad_fn=<SumBackward0>)\n",
      "Epoch 976 loss is 0.3042551279067993\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6159, 0.6296, 0.5903, 0.8290, 0.5748, 0.7795, 0.8172, 0.6189, 0.5659,\n",
      "        0.5815, 0.5872], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0085,  0.3552, -0.0183,  0.3154, -0.0039,  0.0734, -0.0712, -0.0786,\n",
      "        -0.0106,  0.0355], grad_fn=<AddBackward0>)\n",
      "tensor(0.5884, grad_fn=<SumBackward0>)\n",
      "Epoch 977 loss is 0.5883801579475403\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6205, 0.6253, 0.5975, 0.5924, 0.7308, 0.5712, 0.5942, 0.7850, 0.5537,\n",
      "        0.5682, 0.5892], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0077, -0.0094,  0.1757, -0.0088,  0.0030,  0.0904, -0.0058, -0.0087,\n",
      "        -0.0653,  0.0593], grad_fn=<AddBackward0>)\n",
      "tensor(0.2228, grad_fn=<SumBackward0>)\n",
      "Epoch 978 loss is 0.22283989191055298\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7330, 0.5710, 0.8690, 0.5567, 0.5535, 0.8114, 0.6157, 0.7924, 0.5800,\n",
      "        0.8768, 0.8760], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2266, -0.0588, -0.0058, -0.0192,  0.0984,  0.3982, -0.0771,  0.4352,\n",
      "         0.1394,  0.4933], grad_fn=<AddBackward0>)\n",
      "tensor(1.6300, grad_fn=<SumBackward0>)\n",
      "Epoch 979 loss is 1.6300219297409058\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6035, 0.9242, 0.5074, 0.7983, 0.8654, 0.5168, 0.5190, 0.9056, 0.8418,\n",
      "        0.8638, 0.8484], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0320,  0.3247, -0.0196,  0.0156, -0.0931,  0.0671,  0.5418,  0.5747,\n",
      "        -0.0191,  0.0110], grad_fn=<AddBackward0>)\n",
      "tensor(1.3711, grad_fn=<SumBackward0>)\n",
      "Epoch 980 loss is 1.3711106777191162\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6149, 0.8092, 0.8181, 0.8385, 0.5832, 0.5392, 0.5514, 0.8921, 0.8231,\n",
      "        0.5330, 0.5390], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.3386,  0.3727, -0.0753, -0.0929, -0.0957,  0.5149,  0.4732, -0.0061,\n",
      "        -0.1177, -0.0947], grad_fn=<AddBackward0>)\n",
      "tensor(1.2168, grad_fn=<SumBackward0>)\n",
      "Epoch 981 loss is 1.216836929321289\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7802, 0.8617, 0.8938, 0.5306, 0.8413, 0.8667, 0.5626, 0.5445, 0.8728,\n",
      "        0.8310, 0.8760], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.1894, -0.0832, -0.0068, -0.0090,  0.0534, -0.0989,  0.0100,  0.4473,\n",
      "         0.5526,  0.0055], grad_fn=<AddBackward0>)\n",
      "tensor(1.0601, grad_fn=<SumBackward0>)\n",
      "Epoch 982 loss is 1.0601301193237305\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7433, 0.7792, 0.7870, 0.8422, 0.5495, 0.5459, 0.8792, 0.5967, 0.7872,\n",
      "        0.6135, 0.5654], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0728,  0.1648, -0.0766, -0.0804,  0.0616,  0.0788,  0.4021, -0.0886,\n",
      "        -0.0104, -0.0739], grad_fn=<AddBackward0>)\n",
      "tensor(0.4502, grad_fn=<SumBackward0>)\n",
      "Epoch 983 loss is 0.45020806789398193\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7145, 0.6143, 0.7650, 0.6206, 0.7538, 0.8172, 0.5781, 0.6253, 0.5989,\n",
      "        0.8012, 0.5944], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0841, -0.0313,  0.2325,  0.0870, -0.0142, -0.0429, -0.0728,  0.3717,\n",
      "        -0.0103, -0.0015], grad_fn=<AddBackward0>)\n",
      "tensor(0.6025, grad_fn=<SumBackward0>)\n",
      "Epoch 984 loss is 0.60245281457901\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7661, 0.7849, 0.5990, 0.6403, 0.6179, 0.6019, 0.6147, 0.6551, 0.7742,\n",
      "        0.8289, 0.7330], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0557, -0.0419, -0.0557,  0.0048, -0.0085,  0.0620,  0.2872,  0.3570,\n",
      "         0.1298, -0.0138], grad_fn=<AddBackward0>)\n",
      "tensor(0.6653, grad_fn=<SumBackward0>)\n",
      "Epoch 985 loss is 0.6652641892433167\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6371, 0.6885, 0.6379, 0.6984, 0.6236, 0.7656, 0.6815, 0.6901, 0.6647,\n",
      "        0.6525, 0.7630], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.0014,  0.1023, -0.0216,  0.2129, -0.0057,  0.1107, -0.0337, -0.0097,\n",
      "         0.1215,  0.1638], grad_fn=<AddBackward0>)\n",
      "tensor(0.6419, grad_fn=<SumBackward0>)\n",
      "Epoch 986 loss is 0.6418945789337158\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7158, 0.6617, 0.6943, 0.7187, 0.6761, 0.6916, 0.6837, 0.6732, 0.6281,\n",
      "        0.6485, 0.6925], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0072,  0.0048,  0.0240, -0.0009, -0.0117, -0.0009, -0.0211, -0.0117,\n",
      "         0.0320,  0.1072], grad_fn=<AddBackward0>)\n",
      "tensor(0.1145, grad_fn=<SumBackward0>)\n",
      "Epoch 987 loss is 0.11445873975753784\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.7457, 0.6944, 0.6704, 0.7100, 0.6414, 0.6115, 0.6727, 0.6805, 0.6418,\n",
      "        0.6228, 0.6836], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0251, -0.0119, -0.0176, -0.0196, -0.0125,  0.0651,  0.0505, -0.0166,\n",
      "         0.0052,  0.0697], grad_fn=<AddBackward0>)\n",
      "tensor(0.0870, grad_fn=<SumBackward0>)\n",
      "Epoch 988 loss is 0.0870087742805481\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.6196, 0.6314, 0.7497, 0.7786, 0.6090, 0.7430, 0.7458, 0.7593, 0.6522,\n",
      "        0.7437, 0.7505], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.2168,  0.2649, -0.0075, -0.0022, -0.0109,  0.2504, -0.0303, -0.0007,\n",
      "        -0.0029,  0.1639], grad_fn=<AddBackward0>)\n",
      "tensor(0.8415, grad_fn=<SumBackward0>)\n",
      "Epoch 989 loss is 0.8414787650108337\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([1.0981, 0.7699, 0.6856, 0.6172, 0.6067, 0.6855, 0.6260, 0.6140, 0.7571,\n",
      "        0.6337, 0.7335], grad_fn=<ViewBackward0>)\n",
      "tensor([-1.3751e-01, -1.6031e-01, -5.4370e-02, -2.4915e-05,  1.4639e-02,\n",
      "         1.2065e-02,  1.1930e-01,  1.2894e-02,  1.9918e-01, -7.8779e-03],\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor(-0.0020, grad_fn=<SumBackward0>)\n",
      "Epoch 990 loss is -0.0020061731338500977\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8162, 0.6412, 0.5738, 0.6002, 0.7777, 0.6454, 0.7618, 0.7868, 0.8176,\n",
      "        0.5830, 0.7966], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0808, -0.0720,  0.2275,  0.1193,  0.2694,  0.0151,  0.2869, -0.0596,\n",
      "         0.0164, -0.0070], grad_fn=<AddBackward0>)\n",
      "tensor(0.7152, grad_fn=<SumBackward0>)\n",
      "Epoch 991 loss is 0.7152325510978699\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8269, 0.5404, 0.8046, 0.8009, 0.8440, 0.7980, 0.8078, 0.5686, 0.7804,\n",
      "        0.6016, 0.5844], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0074, -0.0087,  0.5060, -0.0022,  0.0116, -0.0918, -0.0059, -0.0687,\n",
      "         0.0264, -0.0653], grad_fn=<AddBackward0>)\n",
      "tensor(0.2939, grad_fn=<SumBackward0>)\n",
      "Epoch 992 loss is 0.2939409017562866\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8335, 0.5207, 0.8174, 0.7591, 0.7885, 0.5643, 0.5724, 0.8245, 0.5736,\n",
      "        0.5934, 0.5957], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0054, -0.0248,  0.4464, -0.0844, -0.0622,  0.0600,  0.0154,  0.0350,\n",
      "        -0.0763,  0.0369], grad_fn=<AddBackward0>)\n",
      "tensor(0.3407, grad_fn=<SumBackward0>)\n",
      "Epoch 993 loss is 0.3406643867492676\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8565, 0.7898, 0.8001, 0.8089, 0.7824, 0.5307, 0.8073, 0.5972, 0.8352,\n",
      "        0.5597, 0.8472], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0188, -0.0159, -0.0025, -0.0898, -0.0006, -0.0617,  0.5074, -0.0825,\n",
      "         0.4166,  0.0200], grad_fn=<AddBackward0>)\n",
      "tensor(0.6723, grad_fn=<SumBackward0>)\n",
      "Epoch 994 loss is 0.6723261475563049\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8593, 0.5652, 0.5477, 0.7941, 0.7849, 0.5830, 0.5757, 0.5771, 0.5991,\n",
      "        0.6128, 0.7619], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1039, -0.0218,  0.3662,  0.0587, -0.0728, -0.0693,  0.0269,  0.0618,\n",
      "         0.3081,  0.2714], grad_fn=<AddBackward0>)\n",
      "tensor(0.8254, grad_fn=<SumBackward0>)\n",
      "Epoch 995 loss is 0.8254097104072571\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8412, 0.5868, 0.6021, 0.5816, 0.5503, 0.6133, 0.6017, 0.6057, 0.7637,\n",
      "        0.8364, 0.5757], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.0797, -0.0866, -0.0122,  0.0186,  0.0336,  0.0924,  0.2507,  0.3911,\n",
      "        -0.0100, -0.0627], grad_fn=<AddBackward0>)\n",
      "tensor(0.5353, grad_fn=<SumBackward0>)\n",
      "Epoch 996 loss is 0.5352794528007507\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.8657, 0.8595, 0.5559, 0.5154, 0.5476, 0.5487, 0.5104, 0.5669, 0.8024,\n",
      "        0.5268, 0.8296], grad_fn=<ViewBackward0>)\n",
      "tensor([-0.1033, -0.1168, -0.1040, -0.0024, -0.0017,  0.0320,  0.4229,  0.0272,\n",
      "         0.4379,  0.0453], grad_fn=<AddBackward0>)\n",
      "tensor(0.6374, grad_fn=<SumBackward0>)\n",
      "Epoch 997 loss is 0.6373509764671326\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5385, 0.5494, 0.8402, 0.5898, 0.7888, 0.8103, 0.5783, 0.5647, 0.5750,\n",
      "        0.8212, 0.7998], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.5028,  0.0855,  0.3990, -0.0099, -0.0038, -0.0747, -0.0785,  0.4048,\n",
      "         0.3919,  0.3748], grad_fn=<AddBackward0>)\n",
      "tensor(1.9918, grad_fn=<SumBackward0>)\n",
      "Epoch 998 loss is 1.9918336868286133\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n",
      "tensor([0.5327, 0.8618, 0.8723, 0.5627, 0.5664, 0.8670, 0.5042, 0.8397, 0.8315,\n",
      "        0.5410, 0.5353], grad_fn=<ViewBackward0>)\n",
      "tensor([ 0.5661,  0.0502, -0.0984, -0.0018, -0.0195,  0.4554, -0.0118,  0.0613,\n",
      "        -0.1014, -0.0987], grad_fn=<AddBackward0>)\n",
      "tensor(0.8012, grad_fn=<SumBackward0>)\n",
      "Epoch 999 loss is 0.8012052774429321\n",
      "REG tensor(0.0249, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# decoder.forward = Decoder().forward\n",
    "# decoder = Decoder()\n",
    "decoder.l2l_fit(dataset, 1000, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T15:08:23.968991Z",
     "start_time": "2024-05-02T14:20:46.760388Z"
    }
   },
   "id": "4841063bbded040e"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.ndimage import uniform_filter1d\n",
    "plt.plot(uniform_filter1d(decoder.history, size=50))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T15:13:28.775444Z",
     "start_time": "2024-05-02T15:13:28.720844Z"
    }
   },
   "id": "bba5ff0cceac9166"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "97598f6f4887edb1"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"/Users/loggiasr/Projects/ReIntAI/models/mnist_models/new_pool3_l2l.pkl\", \"wb\") as f:\n",
    "    pickle.dump(decoder, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T05:20:47.682600Z",
     "start_time": "2024-05-02T05:20:47.632222Z"
    }
   },
   "id": "88c61839cca86346"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Evaluate preformance on train labels (3, 7)\n",
    "decoder.forward_fit(dataset, 2000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T14:10:59.306041Z",
     "start_time": "2024-05-02T14:08:33.326110Z"
    }
   },
   "id": "afa71757ae38e6a"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 Iterations, avg CE: 0.6906278133392334 acc: 0.5354645252227783\n"
     ]
    }
   ],
   "source": [
    "decoder.evaluate(dataset, 1000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T14:12:04.314830Z",
     "start_time": "2024-05-02T14:10:59.307888Z"
    }
   },
   "id": "4cb7e8ff3c340115"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# Evaluate preformance on test held out labels (2, 6)\n",
    "decoder.forward_fit(dataset, 200, use_labels=[7, 3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T15:14:24.288033Z",
     "start_time": "2024-05-02T15:14:02.039282Z"
    }
   },
   "id": "ce4aeadf6495cc26"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 Iterations, avg CE: 0.7091808319091797 acc: 0.5074626803398132\n"
     ]
    }
   ],
   "source": [
    "#decoder.model.edge.plasticity = torch.nn.Parameter(torch.zeros_like(decoder.model.edge.plasticity))\n",
    "decoder.evaluate(dataset, 200, use_labels=[7, 3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T15:14:45.985353Z",
     "start_time": "2024-05-02T15:14:24.291093Z"
    }
   },
   "id": "2294db9d4d64d66"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "13c08d016ebb8e98"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
