{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T13:20:17.686392Z",
     "start_time": "2024-05-02T13:20:16.417124Z"
    }
   },
   "source": [
    "import torch\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torchvision.transforms import PILToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pickle"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "try:\n",
    "    dataset = MNIST(root=\"/Users/loggiasr/Projects/ReIntAI/tmp\", transform=PILToTensor())\n",
    "except RuntimeError:\n",
    "    dataset = MNIST(root=\"/Users/loggiasr/Projects/ReIntAI/tmp\", download=True, transform=PILToTensor())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T13:20:17.704376Z",
     "start_time": "2024-05-02T13:20:17.687247Z"
    }
   },
   "id": "5c4a280b5a2a55ba",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "pool = torch.nn.MaxPool2d(3)\n",
    "data_load = DataLoader(dataset, shuffle=True, batch_size=1)\n",
    "for i, (batch, labels) in enumerate(data_load):\n",
    "    if i < 20:\n",
    "        continue\n",
    "    if i > 40:\n",
    "        break\n",
    "    if labels in [3, 7]:\n",
    "        batch = torch.from_numpy(np.array(batch)).float()\n",
    "        batch = pool(batch.reshape((1, 1, batch.shape[-1], -1))).squeeze()\n",
    "        batch = (batch - batch.mean()) / batch.std()\n",
    "        plt.imshow(batch)\n",
    "        print(batch.shape)\n",
    "        plt.pause(.05)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T13:20:18.499926Z",
     "start_time": "2024-05-02T13:20:17.908631Z"
    }
   },
   "id": "f7d7664d2735f93f",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# loss function that just wants each step better than the discounted average of the last few. \n",
    "def l2l_loss(logits, targets, lfxn, classes=3, power=2, window=3):\n",
    "    \"\"\"\n",
    "    :param logits: (examples, classes)\n",
    "    :param targets: (examples)\n",
    "    :param classes: num classes\n",
    "    :param power: higher powers encourage larger step changes\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    targets = torch.Tensor(targets).long()\n",
    "    conv_1d = torch.nn.Conv1d(in_channels=1, out_channels=1, kernel_size=window, padding=1, padding_mode=\"replicate\")\n",
    "    conv_1d.weight = torch.nn.Parameter(torch.ones_like(conv_1d.weight) / window)\n",
    "    conv_1d.bias = torch.nn.Parameter(torch.zeros_like(conv_1d.bias))\n",
    "    ce_loss = lfxn(logits, targets).view((-1,)) #\n",
    "    print(ce_loss)\n",
    "    filt_ce_loss = conv_1d(ce_loss.view((1, 1, -1))).flatten()\n",
    "    ce_loss = filt_ce_loss[1:] - filt_ce_loss[:-1].detach()\n",
    "    ce_loss = ce_loss + torch.relu(ce_loss) * 4\n",
    "    print(ce_loss)\n",
    "    loss = torch.sum(ce_loss) #+ torch.pow(chance_ce - ce_loss[0], 2)\n",
    "    print(loss)\n",
    "    return loss\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T13:20:18.911542Z",
     "start_time": "2024-05-02T13:20:18.892118Z"
    }
   },
   "id": "69f2add186b3ea77",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "from intrinsic.model import Intrinsic\n",
    "class Decoder:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = Intrinsic(num_nodes=5, node_shape=(1, 3, 9, 9), kernel_size=6, input_mode=\"overwrite\")\n",
    "        self.train_labels = [3, 7]\n",
    "        self.decoder = torch.nn.Linear(in_features=9**2, out_features=len(self.train_labels))\n",
    "        self.optim = torch.optim.Adam(params=[self.model.resistance,\n",
    "                                              self.model.edge.init_weight,\n",
    "                                              self.model.edge.plasticity,\n",
    "                                              self.model.edge.chan_map] + list(self.decoder.parameters()), lr=1e-5)\n",
    "\n",
    "        self.history = []\n",
    "        \n",
    "    def forward(self, X, y):\n",
    "        pool = torch.nn.MaxPool2d(3)\n",
    "        img = X.float()\n",
    "        img = pool(img.reshape((1, 1, img.shape[-1], -1))).squeeze()\n",
    "        img = (img - img.mean()) / img.std()\n",
    "        in_states = torch.zeros_like(self.model.states)\n",
    "        mask = in_states.bool()\n",
    "        for i in range(4):\n",
    "            with torch.no_grad():\n",
    "                in_states[0, 0, :, :] = img.detach()\n",
    "                mask[0, 0, :, :] = True\n",
    "            self.model(in_states.detach(), mask.detach())\n",
    "        in_features = self.model.states[2, 0, :, :]\n",
    "        logits = self.decoder(in_features.view(1, 1, -1)).flatten()\n",
    "        correct = (torch.argmax(logits) == y).float() * .2 - .1\n",
    "        for i in range(2):\n",
    "            # in_states = torch.zeros_like(self.model.states)\n",
    "            # mask = in_states.bool()\n",
    "            in_states[1, 0, :, :] = correct\n",
    "            mask[1, 0, :, :] = True\n",
    "            self.model(in_states, mask.detach())\n",
    "        for i in range(1):\n",
    "            self.model()\n",
    "        return logits\n",
    "    \n",
    "    def _fit(self, data, label_map, iter=100):\n",
    "        all_logits = []\n",
    "        all_labels = []\n",
    "        count = 0\n",
    "        for img, label in data:\n",
    "            if label not in label_map:\n",
    "                continue\n",
    "            if count > iter:\n",
    "                break\n",
    "            label = label_map.index(label)\n",
    "            logits = self.forward(img, label)\n",
    "            all_logits.append(logits.clone())\n",
    "            all_labels.append(label)\n",
    "            count += 1\n",
    "        return torch.stack(all_logits, dim=0), torch.Tensor(all_labels).long()\n",
    "        \n",
    "            \n",
    "    def l2l_fit(self, data, epochs=1000, batch_size=100):\n",
    "        l_fxn = torch.nn.CrossEntropyLoss(reduce=False)\n",
    "        data = DataLoader(data, shuffle=True, batch_size=1)\n",
    "        for epoch in range(epochs):\n",
    "            self.optim.zero_grad()\n",
    "            if (epoch % 10) == 0:\n",
    "                self.model.detach(reset_intrinsic=True)\n",
    "            else:\n",
    "                self.model.detach(reset_intrinsic=False)\n",
    "            logits, labels = self._fit(data, self.train_labels, batch_size)\n",
    "            # loss = torch.sum(logits)\n",
    "            loss = l2l_loss(logits, labels, l_fxn) # + .33 * torch.mean(l_fxn(logits, labels)) # \n",
    "            reg = torch.sum(torch.abs(self.model.edge.chan_map))\n",
    "            self.history.append(loss.detach().cpu().item())\n",
    "            print(\"Epoch\", epoch, \"loss is\", self.history[-1])\n",
    "            loss = loss + .001 * reg\n",
    "            print('REG', .001 * reg)\n",
    "            #init_plast = self.model.edge.chan_map.clone()\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "            #print(\"change:\", init_plast - self.model.edge.chan_map.clone())\n",
    "\n",
    "            \n",
    "    def forward_fit(self, data, iter, use_labels=None):\n",
    "        self.model.detach(reset_intrinsic=True)\n",
    "        if use_labels is None:\n",
    "            use_labels = self.train_labels\n",
    "        l_fxn = torch.nn.CrossEntropyLoss()\n",
    "        data = DataLoader(data, shuffle=True, batch_size=1)\n",
    "        with torch.no_grad():\n",
    "            logits, labels = self._fit(data, use_labels, iter)\n",
    "            # loss = l2l_loss(logits, labels, l_fxn)\n",
    "        #print(\"Self Learn Loss:\", loss.detach().item())\n",
    "        \n",
    "    def evaluate(self, data, iter, use_labels=None):\n",
    "        if use_labels is None:\n",
    "            use_labels = self.train_labels\n",
    "        l_fxn = torch.nn.CrossEntropyLoss()\n",
    "        data = DataLoader(data, shuffle=True, batch_size=1)\n",
    "        with torch.no_grad():\n",
    "            logits, labels = self._fit(data, use_labels, iter)\n",
    "        labels = torch.Tensor(labels).long()\n",
    "        avg_loss = l_fxn(logits, labels)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = torch.count_nonzero(preds == labels) / len(labels)\n",
    "        print(iter, \"Iterations, avg CE:\", avg_loss.detach().item(), \"acc:\", acc.detach().item())\n",
    "        \n",
    "                "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T14:19:27.997200Z",
     "start_time": "2024-05-02T14:19:27.958132Z"
    }
   },
   "id": "33c39960fbf4a297",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "with open(\"/Users/loggiasr/Projects/ReIntAI/models/mnist_models/new_pool3_l2l.pkl\", \"rb\") as f:\n",
    "    decoder = pickle.load(f)\n",
    "decoder.optim = torch.optim.Adam(params=[decoder.model.resistance,\n",
    "                                              decoder.model.edge.init_weight,\n",
    "                                              decoder.model.edge.plasticity,\n",
    "                                              decoder.model.edge.chan_map] + list(decoder.decoder.parameters()), lr=1e-4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T14:20:46.606852Z",
     "start_time": "2024-05-02T14:20:46.555837Z"
    }
   },
   "id": "87224d55b0bf5f76",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# decoder.forward = Decoder().forward\n",
    "# decoder = Decoder()\n",
    "decoder.l2l_fit(dataset, 1000, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T15:08:23.968991Z",
     "start_time": "2024-05-02T14:20:46.760388Z"
    }
   },
   "id": "4841063bbded040e",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "from scipy.ndimage import uniform_filter1d\n",
    "plt.plot(uniform_filter1d(decoder.history, size=50))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T15:13:28.775444Z",
     "start_time": "2024-05-02T15:13:28.720844Z"
    }
   },
   "id": "bba5ff0cceac9166",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "97598f6f4887edb1"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "import pickle\n",
    "with open(\"/Users/loggiasr/Projects/ReIntAI/models/mnist_models/new_pool3_l2l.pkl\", \"wb\") as f:\n",
    "    pickle.dump(decoder, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T05:20:47.682600Z",
     "start_time": "2024-05-02T05:20:47.632222Z"
    }
   },
   "id": "88c61839cca86346",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Evaluate preformance on train labels (3, 7)\n",
    "decoder.forward_fit(dataset, 2000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T14:10:59.306041Z",
     "start_time": "2024-05-02T14:08:33.326110Z"
    }
   },
   "id": "afa71757ae38e6a",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "decoder.evaluate(dataset, 1000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T14:12:04.314830Z",
     "start_time": "2024-05-02T14:10:59.307888Z"
    }
   },
   "id": "4cb7e8ff3c340115",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Evaluate preformance on test held out labels (2, 6)\n",
    "decoder.forward_fit(dataset, 200, use_labels=[7, 3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T15:14:24.288033Z",
     "start_time": "2024-05-02T15:14:02.039282Z"
    }
   },
   "id": "ce4aeadf6495cc26",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "#decoder.model.edge.plasticity = torch.nn.Parameter(torch.zeros_like(decoder.model.edge.plasticity))\n",
    "decoder.evaluate(dataset, 200, use_labels=[7, 3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T15:14:45.985353Z",
     "start_time": "2024-05-02T15:14:24.291093Z"
    }
   },
   "id": "2294db9d4d64d66",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "13c08d016ebb8e98"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
